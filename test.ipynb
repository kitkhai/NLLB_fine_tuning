{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\wong.kk\\AppData\\Local\\anaconda3\\envs\\nllb_env\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\wong.kk\\AppData\\Local\\anaconda3\\envs\\nllb_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# !pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('nllb-200-600M-onmt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'generator', 'vocab', 'opt'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder.embeddings.make_embedding.emb_luts.0.weight': tensor([[-0.0321,  0.0348,  0.0181,  ...,  0.0312, -0.0099, -0.0133],\n",
       "         [-0.0039,  0.0104, -0.0156,  ...,  0.0290, -0.0138, -0.0134],\n",
       "         [-0.0245, -0.0283, -0.0295,  ...,  0.9712, -0.0255, -0.0273],\n",
       "         ...,\n",
       "         [-0.0123, -0.0031, -0.0089,  ...,  0.0645, -0.0182, -0.0740],\n",
       "         [ 0.0085, -0.0088, -0.0091,  ...,  0.0571, -0.0035, -0.1298],\n",
       "         [-0.0076, -0.0107, -0.0051,  ...,  1.0264, -0.0338, -0.1175]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.embeddings.make_embedding.pe.pe': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.8415,  0.8317,  0.8218,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.9093,  0.9236,  0.9365,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.9563,  0.5417,  0.7653,  ...,  0.8688,  0.8733,  0.8777]],\n",
       " \n",
       "         [[ 0.2705,  0.9999,  0.9649,  ...,  0.8687,  0.8733,  0.8777]],\n",
       " \n",
       "         [[-0.6639,  0.5685,  0.3343,  ...,  0.8687,  0.8732,  0.8776]]]),\n",
       " 'encoder.transformer.0.self_attn.linear_keys.weight': tensor([[ 5.9570e-01,  6.5479e-01,  5.9863e-01,  ...,  1.2024e-01,\n",
       "          -1.4905e-01, -1.1023e-01],\n",
       "         [ 3.1909e-01, -1.8079e-01, -2.6294e-01,  ..., -2.0264e-01,\n",
       "           1.9861e-01,  4.2529e-01],\n",
       "         [ 5.2148e-01,  8.4229e-01,  9.9951e-01,  ...,  2.0679e-01,\n",
       "           2.0203e-01, -5.2261e-03],\n",
       "         ...,\n",
       "         [ 1.3794e-01, -1.1102e-01, -5.5176e-01,  ..., -3.5400e-03,\n",
       "           4.2267e-02, -3.9399e-05],\n",
       "         [-1.5588e-01,  6.3293e-02,  1.2901e-02,  ..., -3.8452e-01,\n",
       "           1.5308e-01,  2.8540e-01],\n",
       "         [-2.2595e-01, -9.3994e-02,  3.0981e-01,  ..., -1.6748e-01,\n",
       "          -7.5378e-02, -1.4185e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_keys.bias': tensor([ 0.0179,  0.0283,  0.0196,  ..., -0.0025, -0.0250,  0.0193],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_values.weight': tensor([[ 0.0630,  0.0343, -0.0231,  ..., -0.0668, -0.1157, -0.0081],\n",
       "         [ 0.0947,  0.0685,  0.0461,  ..., -0.0442, -0.1248, -0.0464],\n",
       "         [ 0.0397,  0.0829,  0.0338,  ...,  0.0314, -0.0782, -0.1476],\n",
       "         ...,\n",
       "         [-0.2808, -0.0279,  0.0878,  ...,  0.0007, -0.0660, -0.0214],\n",
       "         [ 0.0296,  0.0190, -0.0400,  ...,  0.0379, -0.0027, -0.2717],\n",
       "         [-0.0427, -0.0203, -0.0764,  ...,  0.0536, -0.0583,  0.1981]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_values.bias': tensor([-0.0758, -0.1368, -0.0085,  ..., -0.0319,  0.0159, -0.0054],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_query.weight': tensor([[ 0.1394, -0.0477, -0.5269,  ..., -0.0635,  0.2659,  0.1715],\n",
       "         [-0.2218, -0.3704, -0.5278,  ..., -0.2737, -0.0536, -0.3032],\n",
       "         [ 1.0117,  1.0215,  0.9995,  ..., -0.0361, -0.1837,  0.1039],\n",
       "         ...,\n",
       "         [-0.1182, -0.1311, -0.4141,  ...,  0.3547, -0.1899,  0.1781],\n",
       "         [-0.1536,  0.0272,  0.0038,  ...,  0.2732, -0.1216,  0.3218],\n",
       "         [-0.2279, -0.1813,  0.2534,  ...,  0.2791, -0.2869, -0.0817]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_query.bias': tensor([ 0.0445, -0.6504,  0.0458,  ..., -0.0200, -0.2649, -0.0813],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.final_linear.weight': tensor([[-0.0432, -0.1025, -0.0201,  ...,  0.0115, -0.0321, -0.1892],\n",
       "         [-0.0038, -0.0169, -0.0073,  ...,  0.0214,  0.0050,  0.0173],\n",
       "         [ 0.0013, -0.0362,  0.0130,  ..., -0.0028, -0.0018,  0.0048],\n",
       "         ...,\n",
       "         [-0.0644,  0.3677,  0.1345,  ...,  0.2361, -0.3904,  0.1660],\n",
       "         [ 0.0199, -0.1136, -0.2612,  ..., -0.1603,  0.0699, -0.0349],\n",
       "         [-0.1918, -0.1236, -0.0550,  ...,  0.0294,  0.1755,  0.0011]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.final_linear.bias': tensor([-1.2274e-01, -5.3802e-02, -8.2552e-05,  ..., -1.1182e-01,\n",
       "          1.1978e-02, -4.8340e-02], dtype=torch.float16),\n",
       " 'encoder.transformer.0.layer_norm.weight': tensor([0.1989, 0.7793, 1.0020,  ..., 0.0681, 0.1104, 0.1191],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.layer_norm.bias': tensor([ 0.0027,  0.0109,  0.0106,  ..., -0.0605,  0.0066,  0.0079],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_1.weight': tensor([[-0.0822, -0.0664, -0.0421,  ..., -0.2252, -0.0174, -0.0901],\n",
       "         [-0.2766,  0.0712, -0.0408,  ...,  0.0138,  0.1761,  0.0470],\n",
       "         [-0.0440,  0.0100, -0.1147,  ...,  0.3438, -0.1202, -0.3132],\n",
       "         ...,\n",
       "         [-0.0398, -0.0275, -0.0571,  ..., -0.1705, -0.0421,  0.1415],\n",
       "         [-0.0609, -0.7812, -1.0000,  ..., -0.1626,  0.0497,  0.0238],\n",
       "         [ 0.0217, -0.0949,  0.0983,  ...,  0.0842,  0.1940, -0.0874]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_1.bias': tensor([-0.3264, -0.1189, -0.1158,  ..., -0.1076, -0.3582,  0.1184],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_2.weight': tensor([[ 5.4474e-02, -3.5706e-02,  7.3608e-02,  ..., -6.0089e-02,\n",
       "          -4.7217e-01,  1.3208e-01],\n",
       "         [ 1.6308e-04,  2.6016e-02, -9.5901e-03,  ..., -2.8137e-02,\n",
       "          -1.6527e-03, -2.5024e-02],\n",
       "         [-5.9280e-03,  3.3844e-02, -2.1988e-02,  ...,  1.0384e-02,\n",
       "          -3.5498e-01,  1.5053e-02],\n",
       "         ...,\n",
       "         [-3.8116e-02, -2.1011e-02,  9.9854e-02,  ..., -1.0352e-01,\n",
       "           7.6103e-04, -2.3364e-01],\n",
       "         [ 2.1960e-01,  2.2803e-01, -4.5837e-02,  ..., -3.4943e-02,\n",
       "          -1.2585e-01,  8.1848e-02],\n",
       "         [-8.0322e-02, -2.6505e-02, -3.4448e-01,  ..., -8.9417e-02,\n",
       "          -2.1942e-02, -1.9287e-02]], dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_2.bias': tensor([-0.0136, -0.3655,  0.3784,  ..., -0.4990, -0.1392, -0.7456],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.layer_norm.weight': tensor([0.3259, 1.1016, 1.6602,  ..., 0.3540, 0.1896, 0.2242],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.layer_norm.bias': tensor([ 0.0026, -0.0082, -0.0087,  ...,  0.1504,  0.0718,  0.1245],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_keys.weight': tensor([[ 0.3132,  0.0303,  0.0594,  ..., -0.1047,  0.2419, -0.0555],\n",
       "         [-0.0422,  0.0921,  0.0128,  ..., -0.0507,  0.2769,  0.0223],\n",
       "         [ 0.4136,  0.1260, -0.0191,  ...,  0.1329, -0.0108, -0.2230],\n",
       "         ...,\n",
       "         [-0.1825,  0.0161, -0.1770,  ..., -0.0454,  0.0595, -0.0764],\n",
       "         [-0.0319, -0.1340,  0.1174,  ...,  0.0326,  0.0575, -0.1683],\n",
       "         [-0.1371, -0.0249,  0.2296,  ..., -0.0196,  0.2529,  0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_keys.bias': tensor([ 0.0179,  0.0086, -0.0042,  ..., -0.0084, -0.0040, -0.0065],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_values.weight': tensor([[-0.0923, -0.0101, -0.0208,  ..., -0.2000,  0.0222,  0.2756],\n",
       "         [ 0.0516, -0.0055,  0.0196,  ...,  0.0775,  0.0753,  0.2461],\n",
       "         [-0.0670, -0.0357, -0.0576,  ...,  0.0538, -0.1516, -0.2198],\n",
       "         ...,\n",
       "         [-0.3870,  0.1213, -0.1592,  ...,  0.2500,  0.0792, -0.0464],\n",
       "         [ 0.0688,  0.0403,  0.0655,  ...,  0.2209,  0.2373,  0.0286],\n",
       "         [-0.0528, -0.0808,  0.0141,  ...,  0.0310,  0.0302,  0.0488]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_values.bias': tensor([ 0.0793, -0.0319,  0.0125,  ...,  0.0307, -0.0509, -0.0137],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_query.weight': tensor([[ 0.2812,  0.1462,  0.0362,  ..., -0.0667,  0.0091,  0.1052],\n",
       "         [-0.1653,  0.0444, -0.0217,  ..., -0.1318, -0.0861, -0.2842],\n",
       "         [ 0.2281, -0.0016,  0.1289,  ...,  0.1704, -0.0197,  0.5918],\n",
       "         ...,\n",
       "         [-0.2090,  0.0235, -0.0010,  ..., -0.0251, -0.0866,  0.5020],\n",
       "         [-0.0695,  0.1296, -0.1885,  ..., -0.3889, -0.0210,  0.4143],\n",
       "         [ 0.3230, -0.0293, -0.0364,  ..., -0.0184,  0.3271,  0.4307]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_query.bias': tensor([ 0.1562, -0.1987,  0.2474,  ..., -0.0505, -0.3267,  0.2563],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.final_linear.weight': tensor([[-0.1606,  0.1558, -0.1584,  ..., -0.0085,  0.0523, -0.3730],\n",
       "         [-0.0123,  0.0967,  0.0272,  ...,  0.0414,  0.1367,  0.1249],\n",
       "         [ 0.0454, -0.0834, -0.0182,  ...,  0.0917, -0.2466,  0.0072],\n",
       "         ...,\n",
       "         [-0.1824, -0.0740,  0.1194,  ...,  0.0551, -0.1820, -0.1041],\n",
       "         [ 0.2206, -0.1924,  0.2886,  ..., -0.0296, -0.3135, -0.0388],\n",
       "         [ 0.0279,  0.1779, -0.1296,  ..., -0.4524,  0.0889, -0.1515]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.final_linear.bias': tensor([-0.5601, -0.4797,  0.5430,  ..., -0.7354, -0.2346, -0.3242],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.layer_norm.weight': tensor([0.2800, 0.6963, 1.0000,  ..., 0.1310, 0.1289, 0.0534],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.layer_norm.bias': tensor([-0.0067, -0.0167,  0.0038,  ..., -0.0364,  0.0032,  0.0068],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_1.weight': tensor([[ 0.0288,  0.0228, -0.0608,  ..., -0.0198, -0.1741,  0.0707],\n",
       "         [ 0.1438,  0.0527,  0.0828,  ..., -0.2949, -0.1907, -0.1910],\n",
       "         [ 0.0360,  0.2744,  0.0928,  ..., -0.1534,  0.1022, -0.0169],\n",
       "         ...,\n",
       "         [ 0.1482,  0.1733, -0.1611,  ..., -0.0764,  0.1055, -0.1361],\n",
       "         [ 0.2598,  0.2203,  0.1808,  ..., -0.0300,  0.2542,  0.1102],\n",
       "         [ 0.2976,  0.0646,  0.2065,  ..., -0.0663, -0.1564, -0.0345]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_1.bias': tensor([-0.0112, -0.2332, -0.1604,  ..., -0.1494, -0.0759, -0.0137],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_2.weight': tensor([[ 0.0429,  0.0976,  0.2073,  ..., -0.2070,  0.0483, -0.0598],\n",
       "         [ 0.0475,  0.0685, -0.1361,  ..., -0.0488,  0.0395,  0.2761],\n",
       "         [-0.0568, -0.0254,  0.1608,  ...,  0.1666,  0.0410,  0.0114],\n",
       "         ...,\n",
       "         [ 0.1724,  0.2063,  0.0209,  ...,  0.3467,  0.2316,  0.0891],\n",
       "         [ 0.1193,  0.0363, -0.2162,  ..., -0.0956,  0.0388,  0.0544],\n",
       "         [-0.1222,  0.2642, -0.2076,  ..., -0.0162, -0.0597, -0.1100]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_2.bias': tensor([-0.4980, -0.6235,  0.3506,  ..., -0.8696,  0.0837,  0.0706],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.layer_norm.weight': tensor([0.3640, 0.5825, 0.7876,  ..., 0.3674, 0.2639, 0.7192],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.layer_norm.bias': tensor([-0.0160, -0.1505,  0.0006,  ...,  0.2961,  0.1514,  0.3875],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_keys.weight': tensor([[-0.3447, -0.4392, -0.2729,  ...,  0.1851,  0.1113, -0.1281],\n",
       "         [-0.5283, -0.3757, -0.2126,  ...,  0.0692, -0.0856,  0.1705],\n",
       "         [ 0.0643, -0.1009,  0.0264,  ..., -0.1879, -0.1941, -0.0309],\n",
       "         ...,\n",
       "         [ 0.1146, -0.1388,  0.0802,  ...,  0.0249, -0.2125, -0.0556],\n",
       "         [ 0.0025,  0.0030,  0.4084,  ...,  0.2128,  0.1897,  0.1888],\n",
       "         [-0.2020, -0.0406, -0.2024,  ...,  0.0584,  0.1917,  0.2167]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_keys.bias': tensor([-0.0259, -0.0300,  0.0098,  ...,  0.0023,  0.0161, -0.0312],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_values.weight': tensor([[ 0.0021,  0.0291,  0.2048,  ...,  0.3103, -0.0507, -0.1099],\n",
       "         [ 0.0806,  0.0523, -0.0200,  ...,  0.1108, -0.0761,  0.0262],\n",
       "         [-0.0192,  0.1956,  0.0440,  ..., -0.2407, -0.1000, -0.0016],\n",
       "         ...,\n",
       "         [ 0.0179,  0.0394, -0.0177,  ...,  0.1243,  0.0283,  0.0198],\n",
       "         [ 0.0754, -0.0627, -0.0371,  ...,  0.2119, -0.3503,  0.0305],\n",
       "         [ 0.1018,  0.2954,  0.0267,  ...,  0.0017,  0.0053, -0.0506]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_values.bias': tensor([ 0.1757, -0.1736,  0.0048,  ...,  0.0027, -0.0123,  0.0012],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_query.weight': tensor([[-0.2394, -0.2335, -0.0950,  ...,  0.1547,  0.1436,  0.1914],\n",
       "         [-0.0340, -0.1176, -0.3926,  ...,  0.1010, -0.0010, -0.0776],\n",
       "         [ 0.1042, -0.2820,  0.0054,  ..., -0.1914,  0.0817,  0.1759],\n",
       "         ...,\n",
       "         [-0.0563, -0.0400,  0.0502,  ..., -0.0404,  0.2847,  0.0385],\n",
       "         [ 0.1459, -0.0163,  0.0189,  ...,  0.0794,  0.2352,  0.1910],\n",
       "         [ 0.1403,  0.0652,  0.1050,  ..., -0.0582, -0.0510, -0.1772]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_query.bias': tensor([-0.1339,  0.7612,  0.0226,  ...,  0.0240,  0.1281,  0.1191],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.final_linear.weight': tensor([[ 0.3418, -0.0677,  0.2137,  ...,  0.0499,  0.2649,  0.1776],\n",
       "         [-0.3020, -0.0951,  0.0147,  ...,  0.0165,  0.0594,  0.0526],\n",
       "         [-0.2974,  0.2010,  0.0136,  ...,  0.1761,  0.2007, -0.0710],\n",
       "         ...,\n",
       "         [ 0.0853,  0.2075,  0.0961,  ..., -0.2235, -0.2292,  0.0688],\n",
       "         [-0.0068, -0.0393, -0.1675,  ..., -0.1058, -0.2266, -0.1720],\n",
       "         [ 0.2888,  0.1907,  0.2939,  ...,  0.1801,  0.4055,  0.1396]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.final_linear.bias': tensor([-0.3291,  0.1842, -0.0803,  ..., -0.4951, -0.2440, -0.1320],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.layer_norm.weight': tensor([0.2551, 0.3916, 0.4587,  ..., 0.1593, 0.1455, 0.0640],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.layer_norm.bias': tensor([ 0.0016, -0.0094,  0.0044,  ..., -0.0253,  0.0004, -0.1724],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_1.weight': tensor([[-0.0267, -0.2546, -0.1114,  ...,  0.0208, -0.4014, -0.0889],\n",
       "         [ 0.1504,  0.1133, -0.3638,  ..., -0.0380, -0.0839, -0.0189],\n",
       "         [-0.3149,  0.2098, -0.0369,  ..., -0.0750,  0.1387, -0.1759],\n",
       "         ...,\n",
       "         [ 0.1409,  0.0983,  0.0416,  ...,  0.1759, -0.0855,  0.1470],\n",
       "         [-0.1570,  0.0397, -0.2314,  ..., -0.1272,  0.0359,  0.0133],\n",
       "         [-0.1584, -0.0536, -0.2089,  ..., -0.1642, -0.5425, -0.1512]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_1.bias': tensor([-0.0205, -0.1761, -0.1024,  ..., -0.1119, -0.2397, -0.1015],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_2.weight': tensor([[ 0.2343,  0.1005, -0.0427,  ..., -0.0775, -0.1626, -0.0025],\n",
       "         [-0.2034, -0.2035, -0.0301,  ..., -0.2466,  0.1137,  0.2327],\n",
       "         [ 0.0221,  0.0497,  0.0061,  ...,  0.0156,  0.4207,  0.0813],\n",
       "         ...,\n",
       "         [ 0.0395,  0.2274,  0.0329,  ...,  0.0589,  0.1022, -0.2118],\n",
       "         [-0.0251, -0.1895,  0.0290,  ...,  0.5098,  0.1008, -0.3828],\n",
       "         [ 0.3801,  0.1416, -0.0853,  ...,  0.0865,  0.0880, -0.0945]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_2.bias': tensor([-0.2042, -0.3538,  0.0340,  ..., -0.5020, -0.2240, -0.4961],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.layer_norm.weight': tensor([0.4373, 0.5439, 0.6646,  ..., 0.4412, 0.3557, 0.5312],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.layer_norm.bias': tensor([ 0.0157, -0.1758,  0.0136,  ...,  0.3103,  0.2247,  0.3567],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_keys.weight': tensor([[ 0.1273,  0.2241, -0.0561,  ..., -0.1205,  0.2671,  0.1118],\n",
       "         [-0.1213,  0.0095, -0.0512,  ..., -0.0240,  0.2441,  0.0936],\n",
       "         [-0.1697, -0.1659,  0.1774,  ...,  0.1174, -0.1907,  0.1812],\n",
       "         ...,\n",
       "         [-0.2524, -0.0491, -0.2900,  ..., -0.0951,  0.3584,  0.0298],\n",
       "         [ 0.3196, -0.3335,  0.0198,  ..., -0.2542,  0.2593, -0.2198],\n",
       "         [-0.2167, -0.0964, -0.0109,  ...,  0.1262,  0.2217,  0.2588]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_keys.bias': tensor([ 0.0045, -0.0249,  0.0055,  ...,  0.0129,  0.0192, -0.0107],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_values.weight': tensor([[-0.1000, -0.0194, -0.0435,  ..., -0.2358,  0.0946,  0.0695],\n",
       "         [ 0.0120,  0.0917, -0.1650,  ...,  0.1097, -0.0242, -0.0247],\n",
       "         [ 0.0066, -0.0302,  0.0870,  ..., -0.0209,  0.4578, -0.0189],\n",
       "         ...,\n",
       "         [ 0.3220, -0.0787, -0.2520,  ...,  0.1698,  0.2107,  0.0212],\n",
       "         [ 0.0778,  0.0969,  0.0474,  ...,  0.1864, -0.0052, -0.0772],\n",
       "         [-0.0798,  0.2871,  0.1097,  ..., -0.0649,  0.0545,  0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_values.bias': tensor([-0.0052,  0.1276, -0.0572,  ..., -0.1461, -0.2104, -0.0482],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_query.weight': tensor([[ 0.1786, -0.3074, -0.1509,  ...,  0.1709, -0.3638, -0.1603],\n",
       "         [-0.1456, -0.0075, -0.0852,  ..., -0.1757,  0.4004,  0.3643],\n",
       "         [ 0.1526,  0.0436, -0.1224,  ...,  0.0580,  0.4180, -0.2462],\n",
       "         ...,\n",
       "         [-0.2957, -0.0009, -0.4045,  ...,  0.2405, -0.2418,  0.0562],\n",
       "         [-0.1401, -0.1481, -0.1549,  ..., -0.3357,  0.0062, -0.2097],\n",
       "         [ 0.1744, -0.2991, -0.4023,  ...,  0.0531, -0.3079,  0.1447]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_query.bias': tensor([ 0.3250,  0.2773,  0.2637,  ...,  0.4526, -0.1826,  0.5928],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.final_linear.weight': tensor([[ 0.2375,  0.4453, -0.1666,  ..., -0.0097, -0.2749,  0.2230],\n",
       "         [-0.1320,  0.1287, -0.1155,  ..., -0.0981, -0.1682,  0.0881],\n",
       "         [ 0.2158, -0.1592,  0.2389,  ..., -0.2021,  0.0601,  0.0741],\n",
       "         ...,\n",
       "         [-0.2094,  0.2705,  0.3247,  ..., -0.3774, -0.0038,  0.0504],\n",
       "         [ 0.1333, -0.0093,  0.0922,  ..., -0.2559, -0.2120, -0.0821],\n",
       "         [ 0.1238, -0.1958, -0.2073,  ...,  0.0613,  0.0382, -0.0040]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.final_linear.bias': tensor([-0.1768,  0.0324, -0.4902,  ..., -0.1864, -0.1381, -0.0352],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.layer_norm.weight': tensor([0.2632, 0.3484, 0.3823,  ..., 0.1754, 0.1694, 0.0759],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.layer_norm.bias': tensor([-0.0017, -0.0178,  0.0143,  ..., -0.0205, -0.0016, -0.1876],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_1.weight': tensor([[ 0.2700,  0.1938,  0.2998,  ...,  0.1562,  0.1998,  0.3589],\n",
       "         [ 0.1078,  0.3862,  0.1381,  ..., -0.1604, -0.1088,  0.1871],\n",
       "         [-0.0421,  0.3840, -0.1287,  ...,  0.0122,  0.1149, -0.0363],\n",
       "         ...,\n",
       "         [ 0.0747,  0.2203, -0.2174,  ..., -0.3176, -0.0036, -0.1372],\n",
       "         [ 0.1874,  0.1069, -0.1216,  ..., -0.2939,  0.4365,  0.1703],\n",
       "         [ 0.1702,  0.2842,  0.0290,  ...,  0.0687, -0.0826,  0.0793]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_1.bias': tensor([-0.0987, -0.1757, -0.0022,  ..., -0.2773, -0.2390, -0.1774],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_2.weight': tensor([[-0.0603, -0.1033,  0.0816,  ..., -0.3188, -0.2788, -0.1556],\n",
       "         [ 0.0388,  0.0523, -0.2107,  ..., -0.2145,  0.0859,  0.1127],\n",
       "         [-0.0334, -0.1051, -0.0261,  ...,  0.1476, -0.2554, -0.1295],\n",
       "         ...,\n",
       "         [-0.0571, -0.1379, -0.1825,  ..., -0.0071, -0.1080, -0.2607],\n",
       "         [-0.2651, -0.1130,  0.1184,  ..., -0.3130,  0.2365, -0.1627],\n",
       "         [-0.2324, -0.0607,  0.2191,  ...,  0.4524,  0.0908,  0.0570]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_2.bias': tensor([-0.1322, -0.2524, -0.2625,  ..., -0.6270, -0.4980,  0.1598],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.layer_norm.weight': tensor([0.5571, 0.6401, 0.6841,  ..., 0.5356, 0.4375, 0.5571],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.layer_norm.bias': tensor([ 0.0726, -0.2047,  0.0892,  ...,  0.3430,  0.1608,  0.3596],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_keys.weight': tensor([[-0.1092, -0.0028, -0.1350,  ..., -0.1427,  0.2861, -0.0529],\n",
       "         [ 0.1046,  0.1780, -0.0298,  ..., -0.0937,  0.0679, -0.0216],\n",
       "         [-0.1721, -0.1276,  0.2137,  ...,  0.0411, -0.0165, -0.1064],\n",
       "         ...,\n",
       "         [ 0.1192,  0.1671,  0.2939,  ...,  0.1614, -0.0975,  0.0159],\n",
       "         [-0.1638, -0.1135, -0.0382,  ...,  0.0856, -0.1583, -0.0257],\n",
       "         [-0.1689,  0.3257, -0.1021,  ...,  0.0256,  0.0517,  0.1899]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_keys.bias': tensor([ 0.0186, -0.0253, -0.0241,  ...,  0.0240,  0.0197,  0.0040],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_values.weight': tensor([[-0.0698, -0.0300,  0.1226,  ..., -0.2991,  0.0958,  0.0717],\n",
       "         [ 0.1055,  0.0383, -0.1597,  ..., -0.2573,  0.1906,  0.0244],\n",
       "         [ 0.0713, -0.3877, -0.1547,  ...,  0.0464, -0.0274,  0.0415],\n",
       "         ...,\n",
       "         [ 0.0169,  0.1136, -0.2030,  ..., -0.1438,  0.3379,  0.1071],\n",
       "         [-0.2815,  0.1594,  0.4478,  ...,  0.1702, -0.4883,  0.0009],\n",
       "         [-0.2661, -0.0815,  0.4202,  ..., -0.1316, -0.3354,  0.0138]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_values.bias': tensor([-0.0147, -0.1171,  0.1478,  ..., -0.0172, -0.0030, -0.1357],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_query.weight': tensor([[-0.3167,  0.2019,  0.2131,  ...,  0.0332, -0.3059, -0.3101],\n",
       "         [ 0.0149, -0.0750,  0.2404,  ..., -0.1279, -0.1794,  0.1234],\n",
       "         [-0.0178, -0.0139, -0.2239,  ..., -0.1698, -0.0556, -0.1077],\n",
       "         ...,\n",
       "         [-0.1376,  0.0729, -0.2188,  ...,  0.0415, -0.1272,  0.3601],\n",
       "         [ 0.0909,  0.0670, -0.0636,  ..., -0.1163, -0.2096, -0.0964],\n",
       "         [ 0.2123, -0.3875, -0.1823,  ..., -0.0737, -0.0089, -0.1017]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_query.bias': tensor([-0.1918,  0.3306,  0.0953,  ..., -0.0160, -0.1255,  0.0032],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.final_linear.weight': tensor([[ 0.3052,  0.0142, -0.2898,  ...,  0.0723,  0.0241,  0.1895],\n",
       "         [-0.2295, -0.2798, -0.0404,  ...,  0.1388,  0.2332,  0.2834],\n",
       "         [ 0.1124,  0.0247,  0.2905,  ...,  0.0372, -0.3989, -0.0923],\n",
       "         ...,\n",
       "         [ 0.0914,  0.4182,  0.0561,  ..., -0.3076, -0.0513,  0.0178],\n",
       "         [-0.0081, -0.1631,  0.3223,  ...,  0.0817, -0.0063,  0.0272],\n",
       "         [-0.0464,  0.0386, -0.3821,  ..., -0.2686,  0.2832, -0.3052]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.final_linear.bias': tensor([-0.2148, -0.2712, -0.4692,  ..., -0.4463, -0.2773, -0.1874],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.layer_norm.weight': tensor([0.2480, 0.2932, 0.3071,  ..., 0.1970, 0.1952, 0.0856],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.layer_norm.bias': tensor([ 0.0061, -0.0186,  0.0067,  ..., -0.0136,  0.0044, -0.1420],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_1.weight': tensor([[-0.0947, -0.3777,  0.1453,  ...,  0.2079,  0.1239, -0.1075],\n",
       "         [-0.0224, -0.1260,  0.0084,  ..., -0.1088, -0.1128,  0.4102],\n",
       "         [-0.1868,  0.2651, -0.2267,  ..., -0.2732,  0.2051,  0.1484],\n",
       "         ...,\n",
       "         [-0.1461, -0.2017,  0.1912,  ..., -0.0526, -0.1860,  0.0266],\n",
       "         [ 0.3555,  0.1292, -0.0576,  ..., -0.0812, -0.0305, -0.1492],\n",
       "         [ 0.0394, -0.0345,  0.0431,  ...,  0.0626,  0.0320,  0.5259]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_1.bias': tensor([-0.1158, -0.1146, -0.0953,  ..., -0.0958, -0.1493,  0.1250],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_2.weight': tensor([[ 9.1736e-02, -3.4851e-02,  6.6711e-02,  ...,  1.7236e-01,\n",
       "          -2.4426e-01, -1.8814e-02],\n",
       "         [ 2.3706e-01,  1.6125e-01, -1.7261e-01,  ...,  1.8347e-01,\n",
       "           3.2921e-03,  2.4902e-02],\n",
       "         [ 1.3171e-01,  1.8689e-01, -5.2910e-03,  ..., -8.6365e-02,\n",
       "          -4.3640e-02,  3.5248e-03],\n",
       "         ...,\n",
       "         [-3.4094e-04, -2.9468e-01,  1.6211e-01,  ...,  2.6520e-02,\n",
       "          -4.6265e-02,  5.0537e-02],\n",
       "         [-2.1143e-01, -1.3879e-01,  4.9731e-01,  ...,  7.4158e-03,\n",
       "           2.5854e-01,  2.4811e-02],\n",
       "         [-8.2092e-02,  2.2675e-02, -2.8735e-01,  ...,  6.6528e-02,\n",
       "           2.5195e-01,  3.7183e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_2.bias': tensor([-0.0294, -0.0543, -0.1670,  ..., -0.4087, -0.3076, -0.2484],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.layer_norm.weight': tensor([0.8389, 0.8896, 0.9126,  ..., 0.8003, 0.6929, 0.9141],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.layer_norm.bias': tensor([ 0.0629, -0.1814,  0.1497,  ...,  0.3884,  0.2186,  0.6089],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_keys.weight': tensor([[-0.1027,  0.1290,  0.2034,  ...,  0.0239,  0.0739,  0.1147],\n",
       "         [ 0.0134,  0.0109,  0.0040,  ..., -0.1880, -0.0925,  0.1240],\n",
       "         [ 0.1074, -0.2524,  0.1588,  ..., -0.0675, -0.1399, -0.1630],\n",
       "         ...,\n",
       "         [-0.1376,  0.0674, -0.1263,  ..., -0.0240, -0.1779,  0.2888],\n",
       "         [-0.0420, -0.0428, -0.0071,  ...,  0.1560,  0.2296, -0.0860],\n",
       "         [ 0.2198,  0.2279, -0.0904,  ..., -0.0740,  0.1239, -0.1846]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_keys.bias': tensor([-0.0248, -0.0112,  0.0246,  ...,  0.0078,  0.0279, -0.0154],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_values.weight': tensor([[-6.2683e-02,  4.0723e-01,  3.0078e-01,  ...,  2.5342e-01,\n",
       "           3.8208e-01, -1.4209e-01],\n",
       "         [ 2.1057e-01, -4.9731e-01, -5.0195e-01,  ...,  4.3604e-01,\n",
       "          -2.5562e-01,  7.9468e-02],\n",
       "         [ 2.2192e-01, -4.8315e-01, -4.9951e-01,  ...,  2.4561e-01,\n",
       "          -1.2524e-01, -8.5876e-02],\n",
       "         ...,\n",
       "         [ 2.9297e-03,  1.6528e-01,  1.7249e-01,  ...,  2.3157e-01,\n",
       "          -8.5205e-02, -1.6647e-02],\n",
       "         [ 1.7163e-01, -5.5176e-01,  1.1542e-01,  ..., -2.9545e-03,\n",
       "           3.3618e-01,  3.1757e-04],\n",
       "         [-1.7358e-01,  1.0901e-01,  3.8971e-02,  ..., -3.2129e-01,\n",
       "          -6.4148e-02,  9.6985e-02]], dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_values.bias': tensor([ 0.2517,  0.0800, -0.1105,  ...,  0.1067,  0.0918, -0.2163],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_query.weight': tensor([[-0.0835, -0.2556,  0.1780,  ..., -0.0013,  0.0685,  0.1277],\n",
       "         [-0.0474,  0.0945,  0.0859,  ..., -0.0839, -0.2522,  0.3069],\n",
       "         [-0.1220,  0.1346,  0.0013,  ..., -0.1627,  0.1812, -0.3811],\n",
       "         ...,\n",
       "         [-0.5020, -0.2435, -0.0367,  ..., -0.1248, -0.0159,  0.0864],\n",
       "         [-0.0185, -0.1132, -0.1614,  ...,  0.0128, -0.2505,  0.0236],\n",
       "         [ 0.0471, -0.0351,  0.2712,  ..., -0.0532, -0.0487,  0.1573]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_query.bias': tensor([-0.1298,  0.3081, -0.0649,  ...,  0.3333, -0.2089, -0.3911],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.final_linear.weight': tensor([[-0.1759, -0.2527, -0.4905,  ..., -0.1455,  0.0436,  0.0316],\n",
       "         [-0.0808,  0.3103, -0.0531,  ...,  0.2908, -0.4807, -0.0984],\n",
       "         [-0.2214, -0.2119,  0.0950,  ...,  0.3025,  0.3235,  0.0836],\n",
       "         ...,\n",
       "         [-0.1042, -0.2352, -0.2393,  ..., -0.0567, -0.1390, -0.5044],\n",
       "         [ 0.1320, -0.2820,  0.1831,  ..., -0.0705,  0.1049,  0.4670],\n",
       "         [ 0.1141, -0.1040,  0.2449,  ...,  0.2822, -0.1600,  0.0797]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.final_linear.bias': tensor([-0.2974,  0.1377, -0.3240,  ..., -0.3740, -0.3955, -0.0625],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.layer_norm.weight': tensor([0.2593, 0.2888, 0.2932,  ..., 0.2134, 0.1947, 0.1024],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.layer_norm.bias': tensor([ 0.0130, -0.0358,  0.0096,  ..., -0.0243, -0.0059, -0.1379],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_1.weight': tensor([[-0.1627,  0.4009,  0.3484,  ..., -0.4468,  0.2238,  0.0247],\n",
       "         [-0.2316, -0.2040,  0.2120,  ...,  0.0018,  0.2175, -0.0315],\n",
       "         [ 0.0982,  0.2788, -0.5264,  ...,  0.2260, -0.1183, -0.1161],\n",
       "         ...,\n",
       "         [-0.1323, -0.2255,  0.0363,  ..., -0.2161, -0.0649, -0.0839],\n",
       "         [ 0.0827,  0.3855,  0.0304,  ..., -0.1301,  0.0207,  0.0511],\n",
       "         [ 0.1125,  0.0268,  0.0286,  ..., -0.0140, -0.2603,  0.0757]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_1.bias': tensor([-0.3113, -0.2347, -0.2471,  ...,  0.0296, -0.0106, -0.1477],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_2.weight': tensor([[ 0.1118, -0.0317,  0.3906,  ...,  0.1901,  0.0196,  0.1421],\n",
       "         [ 0.2644, -0.2418, -0.0213,  ...,  0.2583, -0.1804,  0.0911],\n",
       "         [ 0.1860,  0.1185, -0.1493,  ..., -0.0756, -0.0252, -0.0974],\n",
       "         ...,\n",
       "         [-0.0878,  0.0639,  0.0248,  ...,  0.1627, -0.0352,  0.0266],\n",
       "         [-0.2057,  0.3218,  0.3306,  ...,  0.0302, -0.1030, -0.1403],\n",
       "         [-0.3589,  0.0693,  0.3821,  ...,  0.0552,  0.0178,  0.1909]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_2.bias': tensor([-0.1635,  0.1593,  0.2888,  ..., -0.3391, -0.1981,  0.2345],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.layer_norm.weight': tensor([1.0498, 1.0732, 1.0986,  ..., 1.0576, 0.9355, 1.1182],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.layer_norm.bias': tensor([ 0.0972, -0.2222,  0.1204,  ...,  0.2439, -0.0014,  0.7427],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_keys.weight': tensor([[-0.0706, -0.0345,  0.2610,  ..., -0.1284,  0.0302, -0.1357],\n",
       "         [ 0.1028,  0.0043, -0.1156,  ..., -0.1282, -0.1825, -0.1663],\n",
       "         [-0.2213, -0.1600,  0.1575,  ...,  0.2169, -0.0125,  0.1002],\n",
       "         ...,\n",
       "         [-0.0800, -0.0073, -0.0764,  ..., -0.1770, -0.0122, -0.1235],\n",
       "         [ 0.1169,  0.0127, -0.1982,  ..., -0.0235,  0.0922,  0.0699],\n",
       "         [-0.4729, -0.2825,  0.0516,  ...,  0.0944,  0.0304,  0.3552]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_keys.bias': tensor([-0.0212,  0.0140,  0.0011,  ...,  0.0077,  0.0287, -0.0167],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_values.weight': tensor([[-0.1652,  0.3330,  0.3162,  ..., -0.2389,  0.2849, -0.0800],\n",
       "         [-0.1203,  0.2966, -0.1333,  ..., -0.2632,  0.3467,  0.0620],\n",
       "         [ 0.1744, -0.0900,  0.2561,  ..., -0.0182,  0.3352, -0.1104],\n",
       "         ...,\n",
       "         [-0.5029, -0.0768,  0.3154,  ..., -0.1250, -0.3794,  0.0287],\n",
       "         [ 0.2097,  0.2666, -0.5264,  ..., -0.3022,  0.2620, -0.2422],\n",
       "         [-0.3618,  0.1602,  0.1276,  ...,  0.1013, -0.4070, -0.0555]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_values.bias': tensor([-0.1273,  0.0925, -0.0681,  ...,  0.1183,  0.1335,  0.1152],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_query.weight': tensor([[ 5.8380e-02,  1.7212e-01,  1.0687e-01,  ...,  7.8491e-02,\n",
       "           2.8854e-02,  3.4326e-01],\n",
       "         [ 3.1348e-01,  1.0724e-01, -2.2888e-03,  ..., -3.3398e-03,\n",
       "          -2.1375e-01,  2.3218e-01],\n",
       "         [-1.6968e-01, -1.7670e-02,  1.2512e-01,  ...,  4.8615e-02,\n",
       "          -2.1106e-01, -2.4805e-01],\n",
       "         ...,\n",
       "         [-4.3365e-02,  4.7638e-02,  7.3303e-02,  ..., -3.2837e-02,\n",
       "           5.4840e-02, -1.5967e-01],\n",
       "         [ 7.6599e-02,  1.3269e-01, -4.7241e-02,  ...,  1.3574e-01,\n",
       "          -1.0687e-01, -2.5854e-01],\n",
       "         [ 1.8738e-02,  1.0598e-04,  3.7262e-02,  ...,  1.2688e-02,\n",
       "           3.1647e-02, -2.9468e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_query.bias': tensor([-0.4375,  0.0213,  0.2203,  ..., -0.4126, -0.1324,  0.9414],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.final_linear.weight': tensor([[ 0.4932, -0.2959, -0.2666,  ..., -0.0205,  0.1765, -0.2189],\n",
       "         [ 0.2407,  0.2262,  0.1125,  ..., -0.0656,  0.1926,  0.0654],\n",
       "         [ 0.2922,  0.1119,  0.3481,  ...,  0.2129,  0.0788,  0.0352],\n",
       "         ...,\n",
       "         [-0.1580,  0.1183,  0.0581,  ..., -0.2288, -0.0887, -0.0232],\n",
       "         [-0.0381,  0.1404, -0.0415,  ..., -0.2959,  0.0758, -0.3286],\n",
       "         [-0.5059,  0.4998, -0.0927,  ...,  0.3774, -0.2629, -0.5054]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.final_linear.bias': tensor([-0.0626,  0.2250, -0.1521,  ..., -0.4531, -0.2175,  0.0847],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.layer_norm.weight': tensor([0.2781, 0.3113, 0.3044,  ..., 0.2424, 0.2245, 0.1198],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.layer_norm.bias': tensor([ 0.0091, -0.0322,  0.0044,  ..., -0.0353, -0.0171, -0.1396],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_1.weight': tensor([[ 0.5049, -0.2141,  0.1185,  ...,  0.0346, -0.0762, -0.2939],\n",
       "         [-0.1039,  0.0520, -0.2483,  ..., -0.2549,  0.0668,  0.0578],\n",
       "         [-0.1609, -0.0087,  0.0487,  ...,  0.0201, -0.0370, -0.1423],\n",
       "         ...,\n",
       "         [-0.2238,  0.2118,  0.5020,  ..., -0.2603, -0.5088, -0.1318],\n",
       "         [ 0.0547, -0.1289, -0.1384,  ..., -0.3176, -0.0857,  0.4788],\n",
       "         [-0.1636, -0.1747,  0.0696,  ...,  0.1959, -0.3271, -0.2164]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_1.bias': tensor([-0.2440, -0.1483, -0.1898,  ..., -0.2588, -0.2106, -0.1549],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_2.weight': tensor([[-0.1581, -0.0368,  0.2334,  ..., -0.3040,  0.1361,  0.1009],\n",
       "         [ 0.2061,  0.0373, -0.1328,  ...,  0.4993, -0.0421, -0.2350],\n",
       "         [ 0.0025,  0.0223, -0.1836,  ...,  0.1327, -0.1272,  0.0468],\n",
       "         ...,\n",
       "         [-0.1857,  0.1321, -0.2494,  ..., -0.3591, -0.0569,  0.1892],\n",
       "         [-0.3350, -0.0670,  0.2271,  ...,  0.2461, -0.0009, -0.2045],\n",
       "         [ 0.0830,  0.0142,  0.1000,  ..., -0.2190,  0.0870,  0.2712]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_2.bias': tensor([-0.2479, -0.1766,  0.3108,  ..., -0.2715,  0.1544, -0.0607],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.layer_norm.weight': tensor([1.2949, 1.2705, 1.2734,  ..., 1.2637, 1.1494, 1.0869],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.layer_norm.bias': tensor([ 0.1816, -0.1693,  0.0043,  ...,  0.1831, -0.1348,  0.7734],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_keys.weight': tensor([[ 0.0403,  0.2040, -0.1902,  ...,  0.1509, -0.1453, -0.1630],\n",
       "         [-0.0783, -0.0748, -0.1115,  ...,  0.1044, -0.0614, -0.2024],\n",
       "         [-0.0826, -0.0220,  0.1033,  ...,  0.1572, -0.1219,  0.0381],\n",
       "         ...,\n",
       "         [-0.1497, -0.0581, -0.2620,  ..., -0.0068, -0.0917,  0.1129],\n",
       "         [-0.3176,  0.1254,  0.0963,  ...,  0.0521, -0.0949, -0.0911],\n",
       "         [ 0.0673, -0.1017, -0.2588,  ...,  0.0936,  0.1602,  0.0665]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_keys.bias': tensor([ 0.0198,  0.0307,  0.0190,  ...,  0.0079, -0.0173, -0.0075],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_values.weight': tensor([[ 0.6250,  0.3130, -0.0906,  ...,  0.1709,  0.1100,  0.0266],\n",
       "         [-0.3528,  0.0912, -0.4282,  ...,  0.2196, -0.1589, -0.0099],\n",
       "         [-0.0517, -0.0556, -0.1302,  ...,  0.4043, -0.1920,  0.2158],\n",
       "         ...,\n",
       "         [-0.0071, -0.0645, -0.3860,  ..., -0.0900,  0.0782, -0.0291],\n",
       "         [ 0.0308,  0.2062, -0.3958,  ...,  0.0598,  0.4902, -0.1539],\n",
       "         [ 0.4363, -0.0987, -0.4602,  ...,  0.1437,  0.0404,  0.0533]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_values.bias': tensor([ 0.0676,  0.4995, -0.2866,  ..., -0.1379, -0.1763,  0.2477],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_query.weight': tensor([[ 0.0831,  0.0398,  0.1328,  ...,  0.0081, -0.0090,  0.0434],\n",
       "         [-0.1038,  0.0436, -0.0704,  ..., -0.0676,  0.1190, -0.1210],\n",
       "         [ 0.0927,  0.0960,  0.0286,  ...,  0.0106,  0.1908,  0.1411],\n",
       "         ...,\n",
       "         [ 0.0671,  0.2081,  0.0379,  ...,  0.1769,  0.0137,  0.0703],\n",
       "         [-0.0284,  0.0137,  0.2231,  ..., -0.0323,  0.2351,  0.2407],\n",
       "         [ 0.0638,  0.0581, -0.0652,  ...,  0.0352,  0.0883,  0.0115]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_query.bias': tensor([-0.0459,  0.5107,  0.0079,  ...,  0.2482,  0.0854,  0.0585],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.final_linear.weight': tensor([[-0.3962,  0.1968,  0.2440,  ..., -0.2708,  0.0613,  0.5044],\n",
       "         [-0.1608, -0.2025,  0.0812,  ...,  0.4180,  0.1942,  0.0641],\n",
       "         [ 0.1642, -0.0959,  0.0797,  ...,  0.0237, -0.0937,  0.5010],\n",
       "         ...,\n",
       "         [-0.1365, -0.1866,  0.0842,  ..., -0.2437, -0.0931,  0.2573],\n",
       "         [-0.1290,  0.1565,  0.2512,  ..., -0.3945,  0.0866, -0.0850],\n",
       "         [-0.3518,  0.4900,  0.2866,  ...,  0.2408,  0.2727, -0.0621]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.final_linear.bias': tensor([-0.1945, -0.0603, -0.1410,  ..., -0.2971, -0.3428, -0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.layer_norm.weight': tensor([0.2864, 0.2981, 0.3025,  ..., 0.2600, 0.2637, 0.1532],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.layer_norm.bias': tensor([ 0.0018, -0.0353,  0.0016,  ..., -0.0442, -0.0206, -0.0556],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_1.weight': tensor([[ 0.3796, -0.2915,  0.0097,  ..., -0.1077,  0.2246,  0.0941],\n",
       "         [ 0.2150,  0.0715, -0.2764,  ..., -0.3174, -0.0606, -0.1829],\n",
       "         [-0.1274,  0.3252,  0.2388,  ..., -0.0192, -0.5010,  0.2556],\n",
       "         ...,\n",
       "         [-0.1538,  0.1974,  0.0007,  ...,  0.4119,  0.2036, -0.1060],\n",
       "         [ 0.1875, -0.0032, -0.2629,  ..., -0.0845,  0.0578,  0.1394],\n",
       "         [ 0.0598, -0.2800,  0.1261,  ..., -0.0494,  0.1498, -0.3682]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_1.bias': tensor([-0.1786,  0.0657, -0.2452,  ..., -0.1400, -0.1942, -0.2534],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_2.weight': tensor([[-0.0225,  0.0469,  0.5161,  ..., -0.0067, -0.4446,  0.1309],\n",
       "         [-0.1541,  0.0912, -0.1689,  ..., -0.0529, -0.1357, -0.1484],\n",
       "         [-0.1372,  0.0805, -0.4978,  ..., -0.1472,  0.0931,  0.0875],\n",
       "         ...,\n",
       "         [ 0.3457,  0.2556,  0.1699,  ...,  0.0536,  0.0854,  0.0499],\n",
       "         [ 0.2449, -0.0298,  0.0054,  ...,  0.1077, -0.1932, -0.1685],\n",
       "         [-0.1469, -0.0487, -0.0607,  ...,  0.0502, -0.5054,  0.0828]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_2.bias': tensor([-0.1750, -0.2800,  0.2668,  ..., -0.0279,  0.1831,  0.1775],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.layer_norm.weight': tensor([1.4658, 1.5234, 1.4697,  ..., 1.4619, 1.3975, 1.0264],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.layer_norm.bias': tensor([ 0.2140, -0.1531, -0.1310,  ...,  0.1624, -0.3196,  0.5806],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_keys.weight': tensor([[-0.0688, -0.0091, -0.1277,  ..., -0.0792, -0.1315,  0.2549],\n",
       "         [ 0.0327, -0.0327,  0.1985,  ..., -0.1526, -0.1306, -0.0013],\n",
       "         [ 0.0291, -0.2593,  0.0817,  ..., -0.0741,  0.0684, -0.0975],\n",
       "         ...,\n",
       "         [ 0.1205,  0.0697, -0.0167,  ...,  0.0344, -0.0850,  0.0958],\n",
       "         [-0.0356, -0.0033,  0.0279,  ...,  0.2449,  0.3352,  0.3486],\n",
       "         [-0.0198, -0.0017, -0.0009,  ..., -0.1373,  0.0296,  0.0921]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_keys.bias': tensor([ 0.0190,  0.0186,  0.0075,  ..., -0.0027,  0.0239, -0.0230],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_values.weight': tensor([[ 2.1698e-02,  5.0391e-01, -6.3599e-02,  ...,  3.4375e-01,\n",
       "          -5.6732e-02, -2.5439e-01],\n",
       "         [-5.0098e-01,  4.8828e-01, -3.9917e-01,  ..., -6.4163e-03,\n",
       "           2.7271e-01,  5.1239e-02],\n",
       "         [ 5.0342e-01, -2.5781e-01, -9.2224e-02,  ..., -2.5854e-01,\n",
       "           3.8013e-01,  2.5391e-01],\n",
       "         ...,\n",
       "         [-2.3806e-04, -2.4878e-01, -3.6865e-01,  ...,  1.6638e-01,\n",
       "           4.3030e-02,  1.0706e-01],\n",
       "         [-7.1472e-02,  5.3406e-02,  3.3667e-01,  ..., -4.8535e-01,\n",
       "          -4.1321e-02, -2.5244e-01],\n",
       "         [ 5.5518e-01, -6.1310e-02,  4.2041e-01,  ...,  2.2180e-01,\n",
       "           1.3086e-01, -1.9629e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_values.bias': tensor([ 0.0462, -0.1036, -0.0646,  ..., -0.1625,  0.0988,  0.0123],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_query.weight': tensor([[ 0.0249, -0.0852, -0.0412,  ...,  0.1812,  0.1111,  0.2671],\n",
       "         [-0.0025,  0.0505, -0.0931,  ...,  0.1137, -0.0060, -0.0775],\n",
       "         [ 0.2181,  0.0528,  0.0793,  ...,  0.2654,  0.0399, -0.0110],\n",
       "         ...,\n",
       "         [-0.0602,  0.0107, -0.1671,  ...,  0.1301,  0.2366,  0.0963],\n",
       "         [-0.0008,  0.1672,  0.2468,  ..., -0.1220, -0.1705, -0.0371],\n",
       "         [-0.1020,  0.0135,  0.0702,  ..., -0.0245,  0.1068, -0.0165]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_query.bias': tensor([ 0.4907, -0.1603, -0.2605,  ...,  0.0511,  0.5312,  0.1677],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.final_linear.weight': tensor([[ 0.5000, -0.0681,  0.1069,  ..., -0.0848, -0.1550,  0.4285],\n",
       "         [-0.2615,  0.5898,  0.2981,  ..., -0.0019, -0.3152, -0.5073],\n",
       "         [-0.1832,  0.0960,  0.3252,  ..., -0.1443, -0.3098,  0.2847],\n",
       "         ...,\n",
       "         [-0.0236,  0.0312,  0.1584,  ..., -0.2113, -0.5024,  0.0351],\n",
       "         [ 0.4995,  0.0998,  0.1969,  ...,  0.3953,  0.0782, -0.1827],\n",
       "         [ 0.4517, -0.3076, -0.0215,  ...,  0.5000, -0.2598,  0.3438]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.final_linear.bias': tensor([ 0.1201,  0.2529, -0.2769,  ..., -0.3010,  0.0786, -0.0475],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.layer_norm.weight': tensor([0.3359, 0.3503, 0.3406,  ..., 0.3118, 0.3076, 0.1715],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.layer_norm.bias': tensor([ 0.0137, -0.0487, -0.0163,  ..., -0.0402, -0.0260, -0.1025],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_1.weight': tensor([[-0.3015, -0.1304,  0.0669,  ..., -0.0325, -0.2152, -0.0944],\n",
       "         [-0.2681, -0.3765,  0.2029,  ...,  0.0684, -0.3738,  0.5010],\n",
       "         [ 0.1047, -0.2003, -0.0580,  ...,  0.0778, -0.3823,  0.1543],\n",
       "         ...,\n",
       "         [ 0.2312, -0.0673, -0.2435,  ..., -0.1077,  0.1111,  0.4194],\n",
       "         [-0.0049, -0.4768,  0.1390,  ...,  0.1024,  0.1753,  0.2595],\n",
       "         [-0.2419, -0.3213, -0.1992,  ..., -0.2561, -0.0931,  0.1797]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_1.bias': tensor([ 0.0402, -0.1921,  0.0009,  ..., -0.1022, -0.2727, -0.0250],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_2.weight': tensor([[ 2.2571e-01,  5.2917e-02,  3.8025e-02,  ...,  1.0181e-01,\n",
       "          -2.2070e-01,  8.1055e-02],\n",
       "         [-2.0561e-03, -7.6782e-02,  1.0541e-01,  ...,  3.5132e-01,\n",
       "          -4.7266e-01,  1.1688e-01],\n",
       "         [ 7.1564e-03, -2.0728e-01, -2.0337e-01,  ...,  1.1371e-01,\n",
       "          -2.3010e-01,  1.0876e-01],\n",
       "         ...,\n",
       "         [-2.3773e-02,  1.3578e-04, -8.6914e-02,  ...,  7.0740e-02,\n",
       "          -2.6953e-01,  2.6047e-02],\n",
       "         [ 9.0515e-02, -1.7542e-01,  3.3740e-01,  ...,  2.4524e-01,\n",
       "           1.2427e-01, -1.3501e-01],\n",
       "         [-9.7717e-02, -6.4453e-02,  9.1858e-02,  ...,  1.1902e-02,\n",
       "          -2.8101e-01,  2.2546e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_2.bias': tensor([-0.2666, -0.3450,  0.4014,  ..., -0.3533,  0.4529,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.layer_norm.weight': tensor([1.7168, 1.6738, 1.7178,  ..., 1.6064, 1.6738, 1.0039],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.layer_norm.bias': tensor([ 0.3455, -0.1840, -0.2661,  ...,  0.2267, -0.2754,  0.4849],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_keys.weight': tensor([[-0.0934,  0.0262,  0.0886,  ...,  0.1398,  0.0416,  0.0706],\n",
       "         [ 0.0422, -0.0273,  0.0023,  ...,  0.0563, -0.0426, -0.0468],\n",
       "         [ 0.0401,  0.0974, -0.2075,  ...,  0.0203, -0.0175, -0.0652],\n",
       "         ...,\n",
       "         [-0.1060,  0.0012, -0.0681,  ...,  0.2020, -0.1016, -0.1328],\n",
       "         [-0.0526,  0.1748, -0.0415,  ...,  0.1202,  0.0574, -0.2179],\n",
       "         [-0.1506, -0.1725,  0.0459,  ..., -0.1196, -0.1444, -0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_keys.bias': tensor([ 0.0083,  0.0081,  0.0163,  ..., -0.0311,  0.0125, -0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_values.weight': tensor([[-0.2930, -0.3538,  0.0164,  ...,  0.4600,  0.1323, -0.1270],\n",
       "         [ 0.0593, -0.1552, -0.1039,  ..., -0.1021, -0.5010, -0.3408],\n",
       "         [ 0.5088, -0.0402, -0.3328,  ...,  0.3240,  0.4419, -0.1626],\n",
       "         ...,\n",
       "         [ 0.1453,  0.3970, -0.5234,  ..., -0.2471, -0.4275, -0.0396],\n",
       "         [ 0.2164,  0.4973, -0.1378,  ...,  0.0124, -0.0421,  0.1594],\n",
       "         [-0.1237, -0.2634, -0.2815,  ...,  0.0323,  0.0985, -0.0444]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_values.bias': tensor([-0.0606,  0.2057,  0.1285,  ...,  0.0414, -0.0179, -0.1126],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_query.weight': tensor([[ 0.0533, -0.0367, -0.0298,  ..., -0.1113, -0.1151,  0.0941],\n",
       "         [-0.1364,  0.1113, -0.1127,  ..., -0.2859,  0.1389,  0.1482],\n",
       "         [-0.0801, -0.3044, -0.0587,  ...,  0.1190,  0.0527, -0.0526],\n",
       "         ...,\n",
       "         [ 0.0027,  0.0098,  0.0071,  ..., -0.0561, -0.0421,  0.0130],\n",
       "         [-0.0845, -0.0067,  0.0457,  ..., -0.0438,  0.0351,  0.0575],\n",
       "         [ 0.0757,  0.1078,  0.1119,  ...,  0.0146, -0.0102,  0.1037]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_query.bias': tensor([-0.0395,  0.2544,  0.0701,  ..., -0.0873, -0.4170,  0.1514],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.final_linear.weight': tensor([[ 0.1595,  0.1053,  0.3035,  ..., -0.3784, -0.0549, -0.2336],\n",
       "         [-0.2150, -0.3525,  0.2207,  ..., -0.0771, -0.3467,  0.3674],\n",
       "         [ 0.0105,  0.2457,  0.1207,  ...,  0.3616, -0.4292,  0.0353],\n",
       "         ...,\n",
       "         [ 0.5269, -0.0899, -0.2500,  ...,  0.1394, -0.0237,  0.4280],\n",
       "         [ 0.0251, -0.3645,  0.2576,  ..., -0.2942, -0.0091, -0.1046],\n",
       "         [-0.3721,  0.2549, -0.1851,  ...,  0.2076, -0.0285, -0.1213]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.final_linear.bias': tensor([ 0.1194,  0.1234, -0.3315,  ..., -0.1862, -0.2507, -0.3210],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.layer_norm.weight': tensor([0.3367, 0.3257, 0.3416,  ..., 0.3267, 0.3186, 0.2015],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.layer_norm.bias': tensor([-0.0108, -0.0378, -0.0120,  ..., -0.0397, -0.0296,  0.0007],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_1.weight': tensor([[-0.0850, -0.0334,  0.3296,  ..., -0.1797,  0.3176, -0.1475],\n",
       "         [ 0.2062,  0.0526,  0.4924,  ...,  0.3694,  0.2479, -0.2455],\n",
       "         [-0.1028, -0.2615, -0.3381,  ...,  0.1091, -0.3706,  0.1146],\n",
       "         ...,\n",
       "         [ 0.1309, -0.0182, -0.2957,  ...,  0.1622,  0.2084,  0.1324],\n",
       "         [-0.0830, -0.2047, -0.0750,  ..., -0.1594, -0.1129, -0.0185],\n",
       "         [ 0.2568,  0.1365, -0.0729,  ...,  0.1531,  0.0869,  0.1686]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_1.bias': tensor([-0.0652, -0.2603, -0.2491,  ..., -0.2477, -0.1270,  0.0648],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_2.weight': tensor([[ 0.0651, -0.1250,  0.2908,  ..., -0.2876,  0.0086, -0.3081],\n",
       "         [-0.4285,  0.4309, -0.1884,  ..., -0.0551, -0.2028, -0.0470],\n",
       "         [ 0.1276, -0.3735, -0.4778,  ..., -0.2922,  0.0392,  0.0829],\n",
       "         ...,\n",
       "         [-0.3789,  0.1226,  0.0482,  ...,  0.4937,  0.3669, -0.0059],\n",
       "         [-0.2620,  0.1331, -0.2130,  ..., -0.1647, -0.0382,  0.0402],\n",
       "         [-0.1763, -0.3599,  0.0088,  ..., -0.2683, -0.1316,  0.0857]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_2.bias': tensor([-0.2073, -0.3306,  0.3516,  ..., -0.1648,  0.4053,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.layer_norm.weight': tensor([1.8896, 1.8975, 1.8369,  ..., 1.7158, 1.8867, 1.0020],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.layer_norm.bias': tensor([ 0.3481, -0.0704, -0.3877,  ...,  0.0132, -0.2754,  0.4976],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_keys.weight': tensor([[ 0.0754, -0.0750, -0.0309,  ..., -0.0340,  0.1871, -0.0750],\n",
       "         [-0.1177,  0.2014,  0.1215,  ...,  0.3188, -0.0710, -0.0375],\n",
       "         [ 0.1743, -0.0444,  0.1678,  ..., -0.1851,  0.1493,  0.0254],\n",
       "         ...,\n",
       "         [-0.1746, -0.0400,  0.0757,  ...,  0.1132, -0.1665,  0.1760],\n",
       "         [ 0.0428, -0.0995, -0.0690,  ...,  0.0299, -0.1648,  0.1179],\n",
       "         [-0.0603,  0.0314, -0.0255,  ...,  0.0553,  0.0923,  0.2301]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_keys.bias': tensor([ 0.0078, -0.0056, -0.0106,  ..., -0.0212, -0.0186, -0.0229],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_values.weight': tensor([[-0.1522,  0.2383,  0.1865,  ...,  0.2905,  0.0820,  0.0166],\n",
       "         [ 0.2666,  0.1146, -0.0781,  ...,  0.1699, -0.3335,  0.1304],\n",
       "         [-0.4468, -0.3083,  0.0360,  ..., -0.0930, -0.3240, -0.0488],\n",
       "         ...,\n",
       "         [ 0.0994, -0.2683,  0.5088,  ..., -0.0464, -0.1176,  0.3032],\n",
       "         [ 0.2908,  0.2324, -0.0009,  ..., -0.1620,  0.3689,  0.2500],\n",
       "         [ 0.0656, -0.1532, -0.0412,  ...,  0.4946, -0.2261, -0.2732]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_values.bias': tensor([-0.0977, -0.1240,  0.0131,  ..., -0.0121,  0.0525, -0.0734],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_query.weight': tensor([[-0.1930,  0.0522,  0.0082,  ...,  0.0521,  0.0998, -0.0263],\n",
       "         [-0.0575,  0.1549, -0.1658,  ..., -0.1860,  0.2107, -0.1044],\n",
       "         [-0.0764,  0.0324,  0.0944,  ...,  0.1270, -0.0540, -0.0314],\n",
       "         ...,\n",
       "         [-0.0464, -0.0764,  0.0583,  ...,  0.2264,  0.1029,  0.0735],\n",
       "         [ 0.0351, -0.0892, -0.0684,  ...,  0.1586,  0.0099, -0.1727],\n",
       "         [-0.0319, -0.0603, -0.1011,  ..., -0.3140,  0.0933, -0.0415]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_query.bias': tensor([-0.3320,  0.1873,  0.0091,  ...,  0.1371,  0.0784, -0.0020],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.final_linear.weight': tensor([[-0.5034, -0.2983,  0.0629,  ...,  0.0390, -0.5015, -0.2040],\n",
       "         [ 0.1003,  0.1798,  0.1031,  ..., -0.3835,  0.0084,  0.5010],\n",
       "         [ 0.1758,  0.1630, -0.2917,  ...,  0.0962,  0.4963,  0.5000],\n",
       "         ...,\n",
       "         [ 0.1755,  0.3667,  0.3611,  ..., -0.2289,  0.1060, -0.2825],\n",
       "         [-0.2671, -0.4214, -0.3074,  ..., -0.2625, -0.3059,  0.0285],\n",
       "         [ 0.4990,  0.3005, -0.4709,  ...,  0.2185, -0.4902,  0.2612]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.final_linear.bias': tensor([-0.0365,  0.1382, -0.2482,  ..., -0.3245, -0.1206, -0.3130],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.layer_norm.weight': tensor([0.3611, 0.3506, 0.3416,  ..., 0.3398, 0.3438, 0.2307],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.layer_norm.bias': tensor([-0.0012, -0.0452, -0.0125,  ..., -0.0408, -0.0147,  0.0466],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_1.weight': tensor([[ 0.1156, -0.0344,  0.1548,  ..., -0.2179,  0.3853, -0.0242],\n",
       "         [ 0.3975, -0.1139,  0.0091,  ..., -0.0827,  0.4434, -0.1761],\n",
       "         [ 0.3960,  0.0216, -0.0314,  ...,  0.0225, -0.2169, -0.0543],\n",
       "         ...,\n",
       "         [ 0.1395, -0.3721,  0.1024,  ..., -0.0687,  0.1179, -0.2325],\n",
       "         [-0.1383, -0.0200,  0.1689,  ...,  0.2786, -0.1664, -0.4736],\n",
       "         [-0.0500, -0.1879,  0.0883,  ...,  0.0870,  0.1624, -0.0334]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_1.bias': tensor([-0.1774, -0.2493,  0.0089,  ...,  0.0812, -0.1042, -0.0112],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_2.weight': tensor([[ 0.0633,  0.3196, -0.3215,  ..., -0.1116,  0.1827,  0.2673],\n",
       "         [ 0.0570, -0.2937, -0.0856,  ...,  0.1217, -0.1844,  0.2048],\n",
       "         [-0.4844, -0.1295, -0.0923,  ...,  0.0325, -0.0368, -0.0098],\n",
       "         ...,\n",
       "         [-0.0031,  0.2913, -0.1672,  ...,  0.0862,  0.0590, -0.1099],\n",
       "         [-0.2598,  0.1019,  0.2947,  ..., -0.1364, -0.1061,  0.0092],\n",
       "         [ 0.1287, -0.1024,  0.1221,  ..., -0.0401,  0.0828, -0.0964]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_2.bias': tensor([-0.1252, -0.2593,  0.1232,  ...,  0.0485,  0.2494,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.layer_norm.weight': tensor([1.7891, 1.7773, 1.8184,  ..., 1.7373, 1.7686, 1.0000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.layer_norm.bias': tensor([ 0.3123, -0.1324, -0.2803,  ..., -0.2485, -0.1224,  0.3059],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_keys.weight': tensor([[ 0.0086, -0.0414, -0.3499,  ...,  0.1313,  0.1610,  0.0051],\n",
       "         [ 0.1420,  0.0161, -0.0805,  ...,  0.0367,  0.0750, -0.0147],\n",
       "         [ 0.1501,  0.0788, -0.0873,  ..., -0.0138,  0.0100, -0.0401],\n",
       "         ...,\n",
       "         [-0.2258,  0.1349, -0.0797,  ...,  0.0210, -0.0510, -0.0725],\n",
       "         [ 0.0133, -0.2283, -0.1971,  ...,  0.2808, -0.1448,  0.1022],\n",
       "         [-0.2223,  0.0643, -0.2065,  ..., -0.0892,  0.0763,  0.0452]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_keys.bias': tensor([-0.0247, -0.0124,  0.0158,  ...,  0.0298,  0.0184, -0.0053],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_values.weight': tensor([[-0.3228, -0.2213, -0.4314,  ..., -0.1243,  0.0023, -0.1805],\n",
       "         [-0.2544,  0.2683,  0.0088,  ..., -0.3044,  0.3425, -0.0644],\n",
       "         [ 0.0420,  0.0554, -0.0193,  ..., -0.2462,  0.1820, -0.2064],\n",
       "         ...,\n",
       "         [-0.3894,  0.0691, -0.2698,  ...,  0.0479,  0.0766,  0.0311],\n",
       "         [-0.5674, -0.0828, -0.1783,  ..., -0.1588,  0.3806, -0.0439],\n",
       "         [ 0.2032,  0.0678, -0.4326,  ..., -0.1093, -0.0641,  0.1697]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_values.bias': tensor([ 0.0423,  0.0190, -0.0619,  ..., -0.0843,  0.0345, -0.0243],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_query.weight': tensor([[ 0.1095, -0.1726,  0.1010,  ..., -0.0748, -0.0682, -0.0528],\n",
       "         [ 0.0183, -0.0203,  0.2111,  ...,  0.5200,  0.1798, -0.0073],\n",
       "         [ 0.1667,  0.0603, -0.1227,  ...,  0.1139,  0.0238,  0.0292],\n",
       "         ...,\n",
       "         [-0.1715,  0.1740,  0.0278,  ..., -0.0693,  0.1809, -0.0255],\n",
       "         [-0.0011, -0.0814,  0.0205,  ...,  0.0806, -0.0358,  0.1978],\n",
       "         [ 0.0307, -0.0151,  0.0194,  ..., -0.1848, -0.0357,  0.0113]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_query.bias': tensor([-0.0655,  0.1114, -0.0804,  ..., -0.0082,  0.4026, -0.2406],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.final_linear.weight': tensor([[-0.1425, -0.1304,  0.2463,  ...,  0.2605,  0.0704,  0.5000],\n",
       "         [-0.3113,  0.3472,  0.5015,  ...,  0.2778,  0.4353,  0.2678],\n",
       "         [-0.1364, -0.0914, -0.2534,  ..., -0.2903, -0.2021,  0.0350],\n",
       "         ...,\n",
       "         [-0.3306, -0.3472,  0.4177,  ...,  0.0071, -0.5371, -0.0557],\n",
       "         [ 0.4880, -0.2247, -0.1022,  ...,  0.0623, -0.1614, -0.0088],\n",
       "         [-0.0360, -0.0154,  0.0797,  ...,  0.0604, -0.0828,  0.0997]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.final_linear.bias': tensor([-0.0739, -0.0063, -0.0346,  ..., -0.2489, -0.1971, -0.2751],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.layer_norm.weight': tensor([0.3723, 0.3530, 0.3521,  ..., 0.3430, 0.3640, 0.5117],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.layer_norm.bias': tensor([ 0.0076, -0.0373, -0.0152,  ..., -0.0352,  0.0002,  0.1772],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_1.weight': tensor([[ 2.5732e-01, -1.6187e-01, -4.4678e-01,  ...,  5.9845e-02,\n",
       "          -3.4668e-01, -6.9824e-02],\n",
       "         [ 1.7688e-01, -1.4697e-01,  3.6548e-01,  ..., -4.4287e-01,\n",
       "          -1.0376e-01, -8.9600e-02],\n",
       "         [-2.4670e-01,  2.3022e-01,  3.3618e-01,  ..., -1.1487e-01,\n",
       "          -3.8867e-01,  1.1646e-01],\n",
       "         ...,\n",
       "         [-1.4368e-01, -6.0242e-02,  3.1592e-01,  ...,  7.5500e-02,\n",
       "           1.4355e-01,  8.1177e-02],\n",
       "         [ 4.7302e-02,  3.1885e-01,  1.1621e-01,  ..., -6.1920e-02,\n",
       "          -9.5032e-02,  5.9395e-03],\n",
       "         [-3.4888e-01, -3.6890e-01, -3.6548e-01,  ...,  2.2339e-01,\n",
       "           2.6584e-04,  1.1902e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_1.bias': tensor([-0.2379, -0.0254, -0.0665,  ..., -0.1392, -0.1793, -0.1711],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_2.weight': tensor([[-0.0247, -0.5405,  0.3447,  ...,  0.0279,  0.1028,  0.2759],\n",
       "         [ 0.1445,  0.2554,  0.0915,  ..., -0.1010, -0.0536,  0.1388],\n",
       "         [-0.0830, -0.0148, -0.2334,  ..., -0.0434, -0.1500,  0.2351],\n",
       "         ...,\n",
       "         [-0.4978,  0.0639, -0.3618,  ..., -0.0822,  0.0499,  0.0111],\n",
       "         [-0.1675, -0.2073, -0.1583,  ..., -0.1167, -0.0303,  0.3142],\n",
       "         [-0.0075,  0.0165,  0.0419,  ..., -0.0137,  0.0292, -0.0189]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_2.bias': tensor([-0.0811, -0.1230,  0.0258,  ...,  0.1039,  0.1157,  0.2913],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.layer_norm.weight': tensor([1.3672, 1.2451, 1.1787,  ..., 1.4297, 1.2148, 1.0000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.layer_norm.bias': tensor([ 0.1785, -0.0873, -0.0390,  ..., -0.2549,  0.0047, -0.2499],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.layer_norm.weight': tensor([0.4553, 0.4626, 0.4673,  ..., 0.4241, 0.4702, 0.7456],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.layer_norm.bias': tensor([ 0.0014, -0.0053,  0.0018,  ..., -0.0308,  0.0012, -0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.embeddings.make_embedding.emb_luts.0.weight': tensor([[-0.0321,  0.0348,  0.0181,  ...,  0.0312, -0.0099, -0.0133],\n",
       "         [-0.0039,  0.0104, -0.0156,  ...,  0.0290, -0.0138, -0.0134],\n",
       "         [-0.0245, -0.0283, -0.0295,  ...,  0.9712, -0.0255, -0.0273],\n",
       "         ...,\n",
       "         [-0.0123, -0.0031, -0.0089,  ...,  0.0645, -0.0182, -0.0740],\n",
       "         [ 0.0085, -0.0088, -0.0091,  ...,  0.0571, -0.0035, -0.1298],\n",
       "         [-0.0076, -0.0107, -0.0051,  ...,  1.0264, -0.0338, -0.1175]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.embeddings.make_embedding.pe.pe': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.8415,  0.8317,  0.8218,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.9093,  0.9236,  0.9365,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.9563,  0.5417,  0.7653,  ...,  0.8688,  0.8733,  0.8777]],\n",
       " \n",
       "         [[ 0.2705,  0.9999,  0.9649,  ...,  0.8687,  0.8733,  0.8777]],\n",
       " \n",
       "         [[-0.6639,  0.5685,  0.3343,  ...,  0.8687,  0.8732,  0.8776]]]),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_keys.weight': tensor([[ 0.2527, -0.0136, -0.0460,  ...,  0.0115,  0.2996, -0.2917],\n",
       "         [-0.2238, -0.0130,  0.0161,  ..., -0.0285, -0.1180, -0.1647],\n",
       "         [-0.0419,  0.1165,  0.0529,  ..., -0.1235, -0.1420, -0.0377],\n",
       "         ...,\n",
       "         [-0.1418, -0.2262, -0.2668,  ..., -0.4019,  0.1725, -0.4397],\n",
       "         [ 0.8843,  0.7051, -0.0199,  ...,  0.0214, -0.0945, -0.0924],\n",
       "         [ 0.5151,  0.7905,  0.5708,  ..., -0.1842,  0.1663, -0.4202]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_keys.bias': tensor([ 0.0171,  0.0190, -0.0028,  ...,  0.0214,  0.0051,  0.0162],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_values.weight': tensor([[ 0.1139, -0.0122,  0.0055,  ..., -0.0195, -0.0603, -0.2316],\n",
       "         [-0.0013,  0.0484, -0.0739,  ...,  0.0040,  0.0352,  0.0255],\n",
       "         [ 0.0599, -0.0119, -0.0344,  ...,  0.0804,  0.0247, -0.1047],\n",
       "         ...,\n",
       "         [-0.0121, -0.1064, -0.1040,  ...,  0.1565, -0.1312, -0.0582],\n",
       "         [ 0.0189, -0.0357, -0.0127,  ...,  0.1639, -0.0505,  0.2944],\n",
       "         [ 0.0603,  0.0012, -0.0043,  ...,  0.0229, -0.0510, -0.0253]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_values.bias': tensor([-0.1753, -0.0671,  0.0499,  ...,  0.0657, -0.1055,  0.1422],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_query.weight': tensor([[-0.0608, -0.0219, -0.0292,  ..., -0.2030,  0.2261,  0.2169],\n",
       "         [ 0.1031,  0.2079, -0.1537,  ...,  0.4563, -0.2065, -0.2493],\n",
       "         [-0.0536, -0.1057,  0.1284,  ...,  0.4861,  0.1749,  0.3396],\n",
       "         ...,\n",
       "         [-0.5005, -0.5000, -0.5034,  ...,  0.0190,  0.0634,  0.2839],\n",
       "         [ 0.7227,  0.9077,  0.5024,  ..., -0.3882,  0.0387, -0.2537],\n",
       "         [ 0.4541,  0.6118,  0.9834,  ...,  0.1675, -0.1345,  0.0667]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_query.bias': tensor([ 0.1714, -0.2122,  0.0087,  ..., -0.0495, -0.3044, -0.4622],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.final_linear.weight': tensor([[-0.0922, -0.0627,  0.0594,  ..., -0.0709, -0.0629,  0.0347],\n",
       "         [-0.0212,  0.0095,  0.0910,  ..., -0.0070,  0.0226,  0.1028],\n",
       "         [ 0.0100, -0.0276,  0.0167,  ...,  0.0674,  0.0024, -0.0916],\n",
       "         ...,\n",
       "         [-0.0880, -0.1554, -0.0174,  ...,  0.0215, -0.1620,  0.0854],\n",
       "         [-0.1394,  0.1870,  0.1448,  ...,  0.1100, -0.1603,  0.1107],\n",
       "         [-0.1072,  0.2668,  0.0040,  ..., -0.1271, -0.0542,  0.1467]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.final_linear.bias': tensor([-0.1847, -0.5151, -0.2632,  ...,  0.0610,  0.0335,  0.0851],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_1.weight': tensor([0.2671, 1.0840, 1.7480,  ..., 0.0716, 0.1120, 0.1166],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_1.bias': tensor([-0.0013,  0.0142,  0.0267,  ...,  0.0082,  0.0058,  0.0043],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_keys.weight': tensor([[ 2.7686e-01,  1.1139e-01,  1.2846e-03,  ...,  1.1462e-01,\n",
       "          -3.6523e-01,  2.1698e-02],\n",
       "         [ 3.3984e-01,  5.4596e-02,  1.8262e-01,  ..., -1.6614e-01,\n",
       "           5.4962e-02,  9.5703e-02],\n",
       "         [-3.4485e-02,  3.1982e-02,  2.4927e-01,  ...,  1.3464e-01,\n",
       "          -1.5210e-01,  2.5131e-02],\n",
       "         ...,\n",
       "         [ 1.2830e-01, -9.8999e-02, -4.3060e-02,  ..., -1.1230e-01,\n",
       "           4.0527e-02,  3.7445e-02],\n",
       "         [-6.1572e-01,  3.0398e-05, -5.9692e-02,  ..., -2.1881e-02,\n",
       "           9.4528e-03,  9.6970e-03],\n",
       "         [-4.3845e-04, -4.5288e-02,  7.2693e-02,  ..., -2.0020e-02,\n",
       "          -1.5234e-01, -4.1809e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_keys.bias': tensor([-0.0035,  0.0259,  0.0131,  ...,  0.0161, -0.0030, -0.0134],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_values.weight': tensor([[-2.2168e-01,  1.9531e-01, -2.2302e-01,  ..., -1.5430e-01,\n",
       "          -1.2484e-03, -3.5038e-03],\n",
       "         [-3.2806e-02, -1.0162e-01, -2.2998e-01,  ...,  1.2439e-01,\n",
       "           1.1713e-01,  2.1912e-02],\n",
       "         [ 8.3557e-02, -7.8430e-03,  4.4479e-03,  ..., -7.7515e-02,\n",
       "           1.2612e-04,  6.9237e-03],\n",
       "         ...,\n",
       "         [-1.2396e-01, -4.8584e-02,  6.2744e-02,  ...,  1.0675e-01,\n",
       "          -1.0156e-01, -3.1647e-02],\n",
       "         [ 1.4001e-01, -7.8613e-02, -2.6871e-02,  ..., -1.4417e-01,\n",
       "           1.5289e-02,  5.5725e-02],\n",
       "         [ 7.7400e-03,  1.3008e-02,  1.4258e-01,  ..., -1.0828e-01,\n",
       "           1.8225e-01, -2.6154e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_values.bias': tensor([ 0.0178, -0.0514, -0.0856,  ..., -0.0892, -0.1333,  0.0561],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_query.weight': tensor([[ 0.0181,  0.1831, -0.3489,  ...,  0.0055,  0.0179,  0.3159],\n",
       "         [-0.0963,  0.0248, -0.2091,  ..., -0.0937, -0.1661,  0.0223],\n",
       "         [-0.3262,  0.1173,  0.0812,  ..., -0.0140, -0.0066,  0.2837],\n",
       "         ...,\n",
       "         [ 0.1371, -0.1003,  0.0622,  ...,  0.0039, -0.0370, -0.1047],\n",
       "         [-0.5054,  0.0831, -0.1569,  ..., -0.0121,  0.0830, -0.0902],\n",
       "         [-0.2988, -0.0426,  0.0012,  ...,  0.2725,  0.2629, -0.3853]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_query.bias': tensor([-0.0820,  0.0203,  0.0393,  ...,  0.0010, -0.1102, -0.0185],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.final_linear.weight': tensor([[ 5.9479e-02,  5.2246e-02,  1.3879e-01,  ..., -9.1675e-02,\n",
       "          -2.8214e-02,  1.6602e-02],\n",
       "         [ 4.7424e-02,  9.0332e-02, -1.6830e-02,  ..., -4.2999e-02,\n",
       "           5.8899e-02, -5.5199e-03],\n",
       "         [ 5.9357e-02, -1.4062e-01,  1.0791e-01,  ...,  7.4707e-02,\n",
       "          -3.4363e-02, -7.2876e-02],\n",
       "         ...,\n",
       "         [-1.1938e-01, -1.7102e-01, -6.7566e-02,  ...,  5.9052e-02,\n",
       "           5.6091e-02,  7.9163e-02],\n",
       "         [ 2.0984e-01,  8.2825e-02,  1.6260e-01,  ...,  4.7180e-02,\n",
       "          -1.4214e-02,  1.7029e-01],\n",
       "         [ 4.0222e-02,  1.0779e-01, -3.9624e-01,  ...,  9.2896e-02,\n",
       "          -4.1656e-02, -9.8169e-05]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.final_linear.bias': tensor([-0.2084,  0.1163, -0.0021,  ..., -0.0227,  0.0979,  0.2081],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_2.weight': tensor([0.1486, 0.3196, 0.3987,  ..., 0.1199, 0.0912, 0.0984],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_2.bias': tensor([-0.0154, -0.0182, -0.0321,  ..., -0.0105, -0.0070, -0.0171],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_1.weight': tensor([[ 0.1344,  0.7622,  0.2412,  ...,  0.2900, -0.2639, -0.3789],\n",
       "         [-0.0172,  0.1448, -0.2893,  ...,  0.1109, -0.2581, -0.0345],\n",
       "         [ 0.1434, -0.1132,  0.1077,  ..., -0.1946,  0.0080, -0.4224],\n",
       "         ...,\n",
       "         [-0.0646,  0.4250, -0.0431,  ..., -0.1595, -0.1165,  0.3054],\n",
       "         [ 0.2461, -0.0331,  0.0623,  ...,  0.1078,  0.2034, -0.1764],\n",
       "         [ 0.3833, -0.1958, -0.3770,  ...,  0.0027, -0.2030, -0.2375]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_1.bias': tensor([-0.2781, -0.0742, -0.0874,  ..., -0.0566, -0.0241, -0.2001],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_2.weight': tensor([[-0.1371, -0.1132,  0.0466,  ...,  0.2681, -0.0298, -0.1131],\n",
       "         [ 0.2164, -0.0201, -0.0924,  ...,  0.1089, -0.1300, -0.1272],\n",
       "         [ 0.0881,  0.0721, -0.0802,  ..., -0.0063,  0.0746,  0.1890],\n",
       "         ...,\n",
       "         [ 0.1101,  0.0833, -0.1298,  ..., -0.0008, -0.0935, -0.0485],\n",
       "         [-0.3896,  0.1687, -0.1404,  ...,  0.0498,  0.0757,  0.1858],\n",
       "         [-0.2925, -0.0252,  0.2664,  ...,  0.1076,  0.4316,  0.0273]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_2.bias': tensor([ 9.9304e-02,  5.1483e-02,  2.4277e-02,  ..., -4.9146e-01,\n",
       "         -1.7102e-01, -5.7220e-06], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.layer_norm.weight': tensor([0.2993, 0.6899, 0.8115,  ..., 0.2859, 0.1858, 0.2041],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.layer_norm.bias': tensor([-0.0114, -0.0121, -0.0416,  ...,  0.0494,  0.0188,  0.0542],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_keys.weight': tensor([[ 0.1534, -0.1125, -0.1119,  ..., -0.1871,  0.2374,  0.0232],\n",
       "         [ 0.3218, -0.1428,  0.0255,  ..., -0.1315, -0.0137,  0.1196],\n",
       "         [-0.1437, -0.1470, -0.0161,  ..., -0.2886,  0.1324, -0.1108],\n",
       "         ...,\n",
       "         [-0.1249,  0.1697,  0.4082,  ..., -0.3542, -0.2754, -0.1086],\n",
       "         [ 0.4036, -0.0794,  0.0101,  ..., -0.0826,  0.5649, -0.0558],\n",
       "         [-0.0320,  0.0214, -0.0146,  ...,  0.2869, -0.0469, -0.2600]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_keys.bias': tensor([-0.0115,  0.0259, -0.0176,  ...,  0.0260,  0.0236,  0.0175],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_values.weight': tensor([[ 0.1611,  0.2081,  0.1771,  ..., -0.2059, -0.0025,  0.0425],\n",
       "         [ 0.0439, -0.1763, -0.0055,  ..., -0.1410, -0.0632, -0.1220],\n",
       "         [ 0.1693,  0.2229,  0.4146,  ...,  0.0634,  0.0104,  0.1014],\n",
       "         ...,\n",
       "         [ 0.0663, -0.0892, -0.1144,  ..., -0.2166, -0.0717,  0.0168],\n",
       "         [ 0.0919,  0.2917, -0.1696,  ..., -0.0205, -0.2695,  0.1384],\n",
       "         [-0.1870,  0.1490, -0.2499,  ..., -0.0961, -0.0006,  0.1333]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_values.bias': tensor([ 0.0769, -0.0881, -0.1488,  ..., -0.0063, -0.0072,  0.0170],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_query.weight': tensor([[-0.0667,  0.2040,  0.0103,  ..., -0.0268, -0.1711,  0.0939],\n",
       "         [-0.2396,  0.3296, -0.2190,  ...,  0.1805,  0.2666, -0.0803],\n",
       "         [ 0.0565,  0.0851, -0.0085,  ...,  0.4153,  0.1097, -0.0129],\n",
       "         ...,\n",
       "         [-0.0325, -0.0953,  0.1277,  ..., -0.4856, -0.5068,  0.2008],\n",
       "         [ 0.0311, -0.1217, -0.0499,  ...,  0.2189, -0.4949,  0.3477],\n",
       "         [-0.2493,  0.1967,  0.4160,  ..., -0.4136, -0.1923,  0.0126]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_query.bias': tensor([ 0.0458, -0.0001,  0.0027,  ..., -0.0262, -0.0651,  0.0208],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.final_linear.weight': tensor([[-0.1395,  0.1007, -0.2021,  ..., -0.2854,  0.2642,  0.0026],\n",
       "         [-0.2791,  0.3120, -0.3350,  ...,  0.0471, -0.1516,  0.1459],\n",
       "         [ 0.2573, -0.1997,  0.0403,  ...,  0.0028,  0.0232, -0.1825],\n",
       "         ...,\n",
       "         [ 0.4160,  0.3020, -0.0767,  ...,  0.2146, -0.3484,  0.1781],\n",
       "         [-0.0596, -0.2515,  0.1478,  ...,  0.0984, -0.0452,  0.0968],\n",
       "         [-0.3391,  0.4890, -0.1302,  ...,  0.3733, -0.3181, -0.0583]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.final_linear.bias': tensor([-0.1322, -0.5068, -0.3179,  ..., -0.4104,  0.5020,  0.0186],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_1.weight': tensor([0.2335, 0.3899, 0.4363,  ..., 0.1646, 0.1715, 0.1766],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_1.bias': tensor([ 0.0122,  0.0031,  0.0142,  ..., -0.0172,  0.0160,  0.0054],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_keys.weight': tensor([[ 3.3398e-01,  3.1158e-02,  4.3152e-02,  ..., -1.9287e-01,\n",
       "          -1.6858e-01,  4.2175e-02],\n",
       "         [ 3.4515e-02, -1.7725e-01, -7.6660e-02,  ..., -5.5206e-02,\n",
       "          -6.0150e-02, -2.6245e-01],\n",
       "         [-1.0291e-01, -2.0947e-01,  4.8615e-02,  ..., -1.3843e-01,\n",
       "           1.7810e-01, -4.2267e-02],\n",
       "         ...,\n",
       "         [ 3.3081e-02,  8.9050e-02, -9.6863e-02,  ..., -4.3579e-02,\n",
       "          -4.2603e-02,  7.5928e-02],\n",
       "         [ 1.0266e-01, -3.2788e-01, -1.7285e-01,  ..., -2.2192e-01,\n",
       "           2.8801e-04,  2.7344e-01],\n",
       "         [ 3.6304e-01, -2.3499e-01, -4.5776e-01,  ...,  1.2268e-01,\n",
       "           1.1481e-01, -2.8976e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_keys.bias': tensor([-0.0274, -0.0099, -0.0295,  ...,  0.0261, -0.0028, -0.0228],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_values.weight': tensor([[-0.0637, -0.1584,  0.0154,  ..., -0.1114, -0.0318, -0.0013],\n",
       "         [ 0.2046,  0.1764, -0.1729,  ..., -0.3098,  0.1407, -0.0028],\n",
       "         [ 0.0202,  0.1407,  0.1124,  ...,  0.0605, -0.0785, -0.0263],\n",
       "         ...,\n",
       "         [ 0.1542,  0.1243,  0.1514,  ...,  0.1077, -0.0696,  0.0235],\n",
       "         [-0.1639, -0.0312,  0.2416,  ...,  0.0569,  0.0289,  0.0510],\n",
       "         [-0.0209,  0.0379,  0.0607,  ...,  0.0742,  0.1700, -0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_values.bias': tensor([ 0.0453, -0.0273, -0.0125,  ..., -0.0927, -0.0215,  0.1722],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_query.weight': tensor([[-0.0729, -0.0311, -0.1705,  ...,  0.1267,  0.0778, -0.0111],\n",
       "         [ 0.0575,  0.2003,  0.1246,  ...,  0.1231, -0.0115,  0.0741],\n",
       "         [ 0.1191,  0.1030, -0.2544,  ...,  0.0974,  0.0105, -0.0771],\n",
       "         ...,\n",
       "         [-0.5625, -0.1671,  0.2000,  ..., -0.2129,  0.0068,  0.2164],\n",
       "         [ 0.0772, -0.0503,  0.0390,  ..., -0.3298, -0.1742,  0.3379],\n",
       "         [ 0.0915,  0.0277, -0.4065,  ..., -0.1199,  0.4858, -0.0520]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_query.bias': tensor([-0.2184, -0.5171, -0.0284,  ..., -0.0183,  0.0548,  0.1344],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.final_linear.weight': tensor([[-0.0327,  0.3237, -0.1772,  ...,  0.2573, -0.1348,  0.1152],\n",
       "         [ 0.0838,  0.0265, -0.2900,  ...,  0.2081,  0.1089,  0.0315],\n",
       "         [ 0.1299,  0.1479,  0.1301,  ..., -0.1229, -0.1685,  0.0691],\n",
       "         ...,\n",
       "         [-0.1422,  0.1223,  0.1954,  ..., -0.1614, -0.1797,  0.1772],\n",
       "         [ 0.0510,  0.0167, -0.0936,  ..., -0.1155, -0.2397,  0.1880],\n",
       "         [-0.3721, -0.2397,  0.0360,  ...,  0.0610, -0.0598,  0.0428]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.final_linear.bias': tensor([-0.0711,  0.3042, -0.3445,  ..., -0.2491,  0.4126,  0.2225],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_2.weight': tensor([0.1310, 0.2273, 0.2188,  ..., 0.1075, 0.1068, 0.0997],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_2.bias': tensor([-0.0150, -0.0313, -0.0118,  ...,  0.0090,  0.0072, -0.0125],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_1.weight': tensor([[ 0.0250,  0.2991, -0.1091,  ..., -0.1277, -0.1576,  0.0674],\n",
       "         [ 0.2976, -0.1415,  0.4507,  ..., -0.1866,  0.1283,  0.0190],\n",
       "         [ 0.3267, -0.0324,  0.1790,  ..., -0.1440, -0.3320, -0.0600],\n",
       "         ...,\n",
       "         [ 0.1567,  0.0956,  0.1346,  ..., -0.3232, -0.1976, -0.3655],\n",
       "         [ 0.4209,  0.2257,  0.0028,  ..., -0.1316, -0.3711,  0.0569],\n",
       "         [ 0.1774, -0.2188,  0.1565,  ..., -0.2905,  0.0203, -0.2708]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_1.bias': tensor([-0.1600, -0.0608, -0.1709,  ..., -0.2771, -0.2356, -0.0980],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_2.weight': tensor([[-0.2366, -0.0439, -0.2294,  ...,  0.1348,  0.0668, -0.1799],\n",
       "         [ 0.1781,  0.1968,  0.0236,  ..., -0.1300, -0.2268,  0.2125],\n",
       "         [-0.0632,  0.1316,  0.0245,  ...,  0.0402,  0.0947, -0.1364],\n",
       "         ...,\n",
       "         [ 0.0862,  0.2155, -0.0999,  ..., -0.3252, -0.0651,  0.0750],\n",
       "         [ 0.1539,  0.5024,  0.3135,  ..., -0.2551,  0.0806, -0.0781],\n",
       "         [ 0.0167,  0.2075,  0.0334,  ..., -0.1337,  0.0619,  0.1277]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_2.bias': tensor([ 0.0667,  0.1331,  0.1181,  ..., -0.2947, -0.1676, -0.1841],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.layer_norm.weight': tensor([0.3525, 0.4556, 0.4563,  ..., 0.3020, 0.2478, 0.2815],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.layer_norm.bias': tensor([-0.0249, -0.0007, -0.0149,  ...,  0.0699,  0.0163,  0.0864],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_keys.weight': tensor([[-0.3308,  0.3665,  0.0386,  ...,  0.1205, -0.4648,  0.2186],\n",
       "         [ 0.0590,  0.1039,  0.0496,  ...,  0.1836, -0.3901,  0.3811],\n",
       "         [-0.4600, -0.1686,  0.0210,  ...,  0.0736,  0.1978,  0.0778],\n",
       "         ...,\n",
       "         [-0.5742, -0.1058, -0.0801,  ...,  0.3740, -0.0912, -0.0032],\n",
       "         [ 0.2705, -0.2336,  0.1692,  ..., -0.0341, -0.2332,  0.3018],\n",
       "         [ 0.0272, -0.0501,  0.1230,  ..., -0.1545, -0.0927, -0.0757]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_keys.bias': tensor([ 0.0152,  0.0089,  0.0074,  ...,  0.0129, -0.0011,  0.0167],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_values.weight': tensor([[-0.0995, -0.1671, -0.5259,  ..., -0.2869, -0.1268,  0.0750],\n",
       "         [ 0.0398, -0.0916, -0.0912,  ..., -0.1322, -0.2208,  0.1377],\n",
       "         [ 0.3433,  0.0499,  0.0323,  ...,  0.1874, -0.1367,  0.1506],\n",
       "         ...,\n",
       "         [ 0.0250,  0.0933,  0.0583,  ...,  0.0499, -0.1655, -0.2617],\n",
       "         [ 0.1227, -0.1143,  0.0930,  ...,  0.0697,  0.1770,  0.0898],\n",
       "         [ 0.0276,  0.1170, -0.1428,  ..., -0.0865,  0.0061, -0.1729]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_values.bias': tensor([-0.0004,  0.0150,  0.0520,  ...,  0.0121,  0.0303, -0.0188],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_query.weight': tensor([[-0.3401,  0.2352,  0.4128,  ...,  0.2554, -0.1636, -0.0297],\n",
       "         [ 0.1205, -0.1771, -0.1298,  ..., -0.0942,  0.0591, -0.1454],\n",
       "         [-0.0718, -0.0007,  0.0856,  ..., -0.1609,  0.2598, -0.0106],\n",
       "         ...,\n",
       "         [-0.0469, -0.1349,  0.0050,  ...,  0.1782,  0.1202, -0.1854],\n",
       "         [ 0.0954,  0.0739, -0.3987,  ...,  0.0170,  0.0279,  0.0166],\n",
       "         [-0.0461,  0.4138, -0.0368,  ..., -0.1155, -0.2113, -0.0650]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_query.bias': tensor([-0.0418, -0.0768,  0.0216,  ..., -0.0235,  0.2318, -0.0897],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.final_linear.weight': tensor([[-1.5540e-01, -1.6052e-01,  9.6558e-02,  ...,  9.5215e-02,\n",
       "          -5.2490e-01, -1.0329e-04],\n",
       "         [-1.7261e-01,  1.2408e-01,  8.1604e-02,  ..., -2.1411e-01,\n",
       "          -1.5759e-01,  1.6846e-01],\n",
       "         [-2.4548e-01, -2.9126e-01, -7.3509e-03,  ..., -1.0956e-01,\n",
       "          -1.0693e-01, -7.5806e-02],\n",
       "         ...,\n",
       "         [ 2.4243e-01, -2.2388e-01,  3.2446e-01,  ..., -3.1104e-01,\n",
       "           1.0699e-01, -3.1201e-01],\n",
       "         [-4.9121e-01,  1.8164e-01,  1.7285e-01,  ..., -5.4102e-01,\n",
       "           1.8896e-01, -1.7456e-01],\n",
       "         [-1.4868e-01, -4.2686e-03, -1.5247e-01,  ..., -2.5244e-01,\n",
       "           2.0667e-01, -1.2164e-01]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.final_linear.bias': tensor([-0.4189,  0.2380, -0.4163,  ..., -0.5039, -0.1493,  0.4475],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_1.weight': tensor([0.2588, 0.3323, 0.3691,  ..., 0.1847, 0.1929, 0.1981],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_1.bias': tensor([ 0.0080,  0.0052,  0.0182,  ..., -0.0058,  0.0125, -0.0036],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_keys.weight': tensor([[ 3.9368e-03,  1.2466e-02, -1.2500e-01,  ..., -4.4922e-01,\n",
       "           1.3086e-01, -1.2421e-01],\n",
       "         [-4.1553e-01, -2.4854e-01,  6.1249e-02,  ..., -1.4575e-01,\n",
       "           1.7358e-01, -3.6469e-02],\n",
       "         [ 2.8638e-01,  1.9629e-01, -1.6016e-01,  ...,  2.6993e-02,\n",
       "           1.7017e-01, -1.0522e-01],\n",
       "         ...,\n",
       "         [ 4.3457e-01, -1.6064e-01,  2.1777e-01,  ...,  7.3486e-02,\n",
       "          -2.4500e-01,  2.2827e-02],\n",
       "         [ 8.1360e-02,  3.6682e-02, -1.1883e-03,  ..., -8.8074e-02,\n",
       "          -5.0568e-02, -5.5603e-02],\n",
       "         [ 3.4475e-04,  4.4116e-01, -6.1188e-02,  ...,  6.7322e-02,\n",
       "           1.3672e-01, -5.3192e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_keys.bias': tensor([ 0.0274,  0.0169, -0.0277,  ..., -0.0282, -0.0058, -0.0312],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_values.weight': tensor([[ 0.0640, -0.0147, -0.0991,  ..., -0.4907, -0.1158,  0.0133],\n",
       "         [-0.0900, -0.2211, -0.1050,  ..., -0.0369,  0.0284, -0.0867],\n",
       "         [ 0.2096, -0.0718, -0.1810,  ..., -0.0245,  0.1345,  0.0412],\n",
       "         ...,\n",
       "         [-0.1543, -0.3372, -0.2124,  ...,  0.0370, -0.2200, -0.0192],\n",
       "         [-0.0036,  0.1351, -0.0414,  ..., -0.2722, -0.1978,  0.0154],\n",
       "         [-0.0208,  0.1348, -0.2732,  ...,  0.0633,  0.1826,  0.0693]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_values.bias': tensor([-0.0737,  0.0847,  0.0364,  ...,  0.0214,  0.0005, -0.0131],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_query.weight': tensor([[-0.4275,  0.0265,  0.0817,  ..., -0.0469,  0.2341,  0.2118],\n",
       "         [ 0.3743,  0.1727,  0.0540,  ..., -0.3494,  0.1705, -0.0107],\n",
       "         [-0.1183, -0.0934,  0.1401,  ..., -0.1702,  0.0417, -0.0448],\n",
       "         ...,\n",
       "         [ 0.1122,  0.2097,  0.0602,  ...,  0.1998, -0.2957,  0.0191],\n",
       "         [ 0.2045, -0.2030, -0.1022,  ..., -0.0297, -0.2910,  0.0159],\n",
       "         [-0.4851,  0.4463,  0.0319,  ...,  0.0139, -0.0826, -0.0349]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_query.bias': tensor([-0.0117,  0.0652, -0.1204,  ...,  0.0750,  0.0415, -0.0578],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.final_linear.weight': tensor([[-5.6915e-02,  1.0187e-01, -2.7832e-01,  ...,  2.2229e-01,\n",
       "          -3.0542e-01, -7.3204e-03],\n",
       "         [ 7.6111e-02,  1.6968e-01, -1.3794e-01,  ..., -8.0750e-02,\n",
       "          -4.1077e-02,  4.9683e-02],\n",
       "         [-4.5776e-02, -2.0325e-01, -1.5405e-01,  ..., -2.6611e-01,\n",
       "           2.3071e-01, -2.0093e-01],\n",
       "         ...,\n",
       "         [ 3.4741e-01,  2.8296e-01,  3.5187e-02,  ...,  3.4546e-02,\n",
       "           7.2754e-02,  1.6708e-02],\n",
       "         [-2.9907e-01,  3.6499e-02, -2.6807e-01,  ..., -3.5181e-01,\n",
       "          -2.1741e-01, -3.6224e-02],\n",
       "         [-2.3279e-01,  3.2013e-02,  2.1243e-04,  ..., -2.9346e-01,\n",
       "           4.3140e-01,  1.1359e-01]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.final_linear.bias': tensor([-0.1670,  0.2517,  0.0768,  ..., -0.3137, -0.0340, -0.1135],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_2.weight': tensor([0.1266, 0.1838, 0.1929,  ..., 0.1061, 0.0986, 0.1010],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_2.bias': tensor([-0.0076, -0.0356, -0.0011,  ..., -0.0028, -0.0035, -0.0181],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_1.weight': tensor([[-0.1963, -0.0854,  0.0271,  ..., -0.0640, -0.1954,  0.2534],\n",
       "         [-0.3438,  0.1814, -0.1447,  ..., -0.3826, -0.0184, -0.3777],\n",
       "         [ 0.0417,  0.0775,  0.2869,  ...,  0.1899,  0.0681, -0.3806],\n",
       "         ...,\n",
       "         [-0.2186, -0.0697, -0.2954,  ..., -0.0013, -0.0532, -0.4646],\n",
       "         [-0.1605,  0.4458,  0.0753,  ...,  0.0030, -0.1979,  0.0666],\n",
       "         [ 0.1459,  0.1836,  0.0529,  ...,  0.0804, -0.0881,  0.0609]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_1.bias': tensor([-0.1088, -0.2505, -0.1223,  ..., -0.2303, -0.1230, -0.0989],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_2.weight': tensor([[-0.1610, -0.3735, -0.0555,  ...,  0.2761, -0.0305, -0.1532],\n",
       "         [-0.0477, -0.2759,  0.1680,  ...,  0.0407, -0.1489, -0.1984],\n",
       "         [-0.0375, -0.1848, -0.0933,  ...,  0.1871,  0.2727, -0.1232],\n",
       "         ...,\n",
       "         [-0.0792, -0.1058, -0.3218,  ...,  0.0746,  0.1451,  0.1779],\n",
       "         [-0.0492, -0.1247,  0.2181,  ...,  0.3079, -0.0853,  0.2299],\n",
       "         [ 0.4763,  0.1882, -0.0437,  ..., -0.0560, -0.4338, -0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_2.bias': tensor([-0.1108, -0.2070, -0.0164,  ..., -0.2815, -0.0843, -0.2876],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.layer_norm.weight': tensor([0.3970, 0.4524, 0.4319,  ..., 0.3435, 0.3228, 0.3274],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.layer_norm.bias': tensor([-0.0156,  0.0081,  0.0066,  ...,  0.0600, -0.0039,  0.0792],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_keys.weight': tensor([[-0.0989,  0.3494,  0.1242,  ..., -0.0166, -0.2554, -0.0117],\n",
       "         [-0.0774, -0.2800,  0.0182,  ..., -0.2566, -0.0605, -0.3606],\n",
       "         [ 0.1135, -0.0656,  0.0745,  ...,  0.1853, -0.1089, -0.1870],\n",
       "         ...,\n",
       "         [-0.1294, -0.1048, -0.0658,  ...,  0.0122, -0.0033, -0.1639],\n",
       "         [-0.0522,  0.1150, -0.0699,  ..., -0.0789,  0.0958,  0.0314],\n",
       "         [-0.1689,  0.0449,  0.0771,  ..., -0.0376, -0.2283, -0.1467]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_keys.bias': tensor([-0.0116, -0.0057, -0.0070,  ...,  0.0291, -0.0091, -0.0291],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_values.weight': tensor([[-0.1167, -0.2267, -0.1385,  ..., -0.1125,  0.1224, -0.4749],\n",
       "         [-0.1150, -0.0827, -0.2052,  ...,  0.1290, -0.1851,  0.3667],\n",
       "         [ 0.0052,  0.1235,  0.1295,  ..., -0.2764,  0.4204,  0.4370],\n",
       "         ...,\n",
       "         [ 0.3010, -0.2048, -0.3379,  ..., -0.2324,  0.0846,  0.2581],\n",
       "         [-0.4292, -0.1766,  0.1385,  ...,  0.1300,  0.1146,  0.2145],\n",
       "         [ 0.2388, -0.5005, -0.0915,  ..., -0.0520, -0.3730,  0.1678]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_values.bias': tensor([-0.0255,  0.0488,  0.0688,  ...,  0.0421, -0.0326,  0.0906],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_query.weight': tensor([[ 0.2737, -0.1266,  0.1499,  ...,  0.0596,  0.1345,  0.2371],\n",
       "         [-0.0415,  0.2070,  0.0330,  ..., -0.1792,  0.1012,  0.2859],\n",
       "         [-0.0612,  0.1016,  0.1646,  ..., -0.2700, -0.0338, -0.0159],\n",
       "         ...,\n",
       "         [ 0.1676, -0.0497,  0.4077,  ..., -0.0945,  0.0942, -0.0088],\n",
       "         [-0.1548, -0.1628, -0.3193,  ...,  0.2554, -0.0501,  0.0714],\n",
       "         [ 0.2166,  0.1407, -0.0704,  ...,  0.0569,  0.3152, -0.0768]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_query.bias': tensor([ 0.0457,  0.1059,  0.3831,  ...,  0.3333,  0.0374, -0.0630],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.final_linear.weight': tensor([[-0.1353, -0.2498,  0.0072,  ...,  0.0026,  0.3059,  0.0142],\n",
       "         [ 0.0606, -0.2023,  0.1234,  ...,  0.5112, -0.1735,  0.4958],\n",
       "         [ 0.0301,  0.1292,  0.4243,  ..., -0.1786, -0.1874,  0.2764],\n",
       "         ...,\n",
       "         [ 0.1820,  0.1312,  0.3752,  ..., -0.4602,  0.6631, -0.1891],\n",
       "         [ 0.1621, -0.3711,  0.2749,  ...,  0.4641,  0.3682, -0.2791],\n",
       "         [-0.3870,  0.2444,  0.1794,  ..., -0.2311,  0.4253, -0.3052]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.final_linear.bias': tensor([-0.3191, -0.0130, -0.3569,  ..., -0.4990, -0.2812,  0.3171],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_1.weight': tensor([0.2649, 0.2991, 0.3367,  ..., 0.1940, 0.2025, 0.2090],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_1.bias': tensor([ 0.0098,  0.0048,  0.0200,  ..., -0.0096,  0.0063, -0.0139],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_keys.weight': tensor([[-0.1865, -0.0974,  0.1832,  ..., -0.2744, -0.0507, -0.1809],\n",
       "         [ 0.3071, -0.1432,  0.2676,  ...,  0.0955, -0.1697,  0.0543],\n",
       "         [ 0.0473,  0.2034,  0.2032,  ..., -0.0693, -0.2028,  0.1306],\n",
       "         ...,\n",
       "         [-0.2595,  0.1549, -0.1284,  ..., -0.0772, -0.1320,  0.1205],\n",
       "         [-0.1119,  0.0875,  0.0643,  ...,  0.0091, -0.0217, -0.0189],\n",
       "         [ 0.0364,  0.2268,  0.0769,  ..., -0.1428,  0.0320,  0.0672]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_keys.bias': tensor([-0.0310,  0.0280,  0.0024,  ...,  0.0099, -0.0284, -0.0260],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_values.weight': tensor([[ 2.4078e-02,  2.6733e-01,  2.0782e-02,  ...,  1.9263e-01,\n",
       "           1.7105e-02,  2.2621e-03],\n",
       "         [ 1.1975e-01,  6.5063e-02, -1.6510e-02,  ..., -3.9642e-02,\n",
       "           1.5393e-01,  4.3671e-02],\n",
       "         [ 2.0248e-02,  1.1452e-02,  8.4961e-02,  ..., -2.9495e-02,\n",
       "          -1.4844e-01,  1.0025e-02],\n",
       "         ...,\n",
       "         [ 2.6025e-01,  3.3112e-02,  6.1096e-02,  ...,  1.0437e-01,\n",
       "           3.6987e-01, -4.9896e-03],\n",
       "         [-7.1680e-01, -2.0828e-02, -1.8994e-01,  ...,  4.0741e-02,\n",
       "           2.2595e-01,  1.6713e-04],\n",
       "         [ 2.0004e-02,  2.5366e-01,  2.1960e-01,  ..., -1.0065e-01,\n",
       "           6.7871e-02,  1.7929e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_values.bias': tensor([-0.0029,  0.0220, -0.1296,  ...,  0.0403,  0.0458,  0.0118],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_query.weight': tensor([[-0.0173,  0.0173,  0.1548,  ...,  0.4448,  0.2622, -0.3184],\n",
       "         [ 0.0507,  0.5000,  0.1766,  ...,  0.2209, -0.3264, -0.1075],\n",
       "         [ 0.0124, -0.0648,  0.1494,  ..., -0.2532,  0.1809, -0.1466],\n",
       "         ...,\n",
       "         [ 0.2498, -0.0932, -0.2915,  ..., -0.2399, -0.0685,  0.0255],\n",
       "         [ 0.0212,  0.2756,  0.0865,  ...,  0.0206, -0.1403,  0.0765],\n",
       "         [ 0.0407,  0.2849, -0.2264,  ..., -0.1996,  0.0529,  0.0208]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_query.bias': tensor([-0.1206,  0.1025,  0.0757,  ..., -0.0092, -0.0883, -0.1151],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.final_linear.weight': tensor([[ 0.0876, -0.1027,  0.1193,  ...,  0.2145,  0.0585, -0.1265],\n",
       "         [ 0.0244,  0.0413, -0.1685,  ...,  0.0888,  0.1541, -0.0012],\n",
       "         [-0.1416, -0.0668, -0.3159,  ..., -0.0815,  0.0106, -0.0503],\n",
       "         ...,\n",
       "         [ 0.0349, -0.1460, -0.0229,  ...,  0.1868, -0.0360,  0.0837],\n",
       "         [ 0.1722,  0.0825, -0.0028,  ...,  0.3721,  0.1023,  0.1249],\n",
       "         [-0.0881,  0.0850, -0.1405,  ..., -0.2732,  0.2292, -0.1927]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.final_linear.bias': tensor([ 0.1139,  0.2313,  0.3328,  ...,  0.1598,  0.1838, -0.0592],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_2.weight': tensor([0.1249, 0.1664, 0.1544,  ..., 0.0951, 0.1037, 0.1024],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_2.bias': tensor([-0.0096, -0.0279, -0.0147,  ..., -0.0196,  0.0010, -0.0201],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_1.weight': tensor([[ 0.2854, -0.1564,  0.2632,  ...,  0.3538,  0.1858, -0.2240],\n",
       "         [ 0.1320, -0.0382,  0.1373,  ...,  0.0072, -0.1225,  0.2688],\n",
       "         [-0.0849, -0.1731,  0.4026,  ..., -0.0120,  0.2983, -0.0650],\n",
       "         ...,\n",
       "         [-0.2664, -0.1324,  0.2439,  ...,  0.1598,  0.0373,  0.1060],\n",
       "         [-0.0652,  0.0218,  0.0721,  ..., -0.0628, -0.5562, -0.1991],\n",
       "         [ 0.0721,  0.0939, -0.2037,  ..., -0.0305, -0.1075, -0.0715]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_1.bias': tensor([-0.1403, -0.0063, -0.0494,  ...,  0.0057, -0.2385, -0.1196],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_2.weight': tensor([[-3.0322e-01, -6.6833e-02,  1.0114e-01,  ..., -5.2452e-04,\n",
       "           4.5197e-02,  2.4658e-02],\n",
       "         [ 7.6111e-02, -1.4819e-01,  2.0898e-01,  ..., -1.3293e-01,\n",
       "           1.6663e-02,  5.0812e-02],\n",
       "         [ 1.4941e-01, -1.0266e-01, -1.2354e-01,  ..., -6.5327e-04,\n",
       "          -8.2458e-02, -1.0616e-04],\n",
       "         ...,\n",
       "         [ 8.2153e-02,  1.2646e-01, -1.3855e-01,  ...,  7.0679e-02,\n",
       "          -1.0352e-01, -8.3435e-02],\n",
       "         [-2.7199e-03,  3.4009e-01, -2.1057e-01,  ..., -4.7485e-01,\n",
       "           7.7454e-02, -3.9380e-01],\n",
       "         [ 2.1704e-01,  3.9139e-03,  8.0872e-02,  ..., -1.1017e-01,\n",
       "          -1.6699e-01, -2.3010e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_2.bias': tensor([-0.1926, -0.1788,  0.1004,  ..., -0.1218,  0.0177, -0.1982],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.layer_norm.weight': tensor([0.4517, 0.4846, 0.4919,  ..., 0.3994, 0.3762, 0.3960],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.layer_norm.bias': tensor([0.0141, 0.0581, 0.0347,  ..., 0.0001, 0.0165, 0.0414],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_keys.weight': tensor([[ 0.2207,  0.1823, -0.0239,  ..., -0.0892, -0.2250, -0.0438],\n",
       "         [-0.1675,  0.0461, -0.2908,  ..., -0.0573,  0.2861, -0.1185],\n",
       "         [-0.2162,  0.2639,  0.0948,  ...,  0.0665,  0.1389,  0.2520],\n",
       "         ...,\n",
       "         [-0.0280, -0.0919,  0.0092,  ...,  0.2295, -0.2079,  0.0559],\n",
       "         [ 0.1720,  0.1978, -0.1338,  ..., -0.3010,  0.5542,  0.1371],\n",
       "         [ 0.1345,  0.1317, -0.1661,  ...,  0.0614, -0.0829, -0.2491]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_keys.bias': tensor([ 0.0078,  0.0124, -0.0312,  ..., -0.0085, -0.0288, -0.0269],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_values.weight': tensor([[-0.2673,  0.0440,  0.2004,  ...,  0.0255, -0.0587,  0.0551],\n",
       "         [ 0.0173, -0.0415, -0.1914,  ...,  0.2194, -0.2268,  0.0632],\n",
       "         [-0.3674, -0.1038,  0.1384,  ...,  0.1515,  0.1569, -0.2007],\n",
       "         ...,\n",
       "         [ 0.0292,  0.3396, -0.3240,  ...,  0.2029,  0.3286,  0.3315],\n",
       "         [ 0.1886, -0.2532,  0.0946,  ..., -0.0008,  0.2737,  0.4102],\n",
       "         [ 0.4709, -0.1427, -0.1335,  ..., -0.3120, -0.1081,  0.0392]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_values.bias': tensor([ 0.0049,  0.0786,  0.0156,  ..., -0.0225, -0.0117, -0.1213],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_query.weight': tensor([[-0.1050, -0.0892, -0.0248,  ..., -0.2117,  0.2351, -0.1338],\n",
       "         [-0.0142, -0.0568, -0.2524,  ...,  0.1010, -0.2367,  0.1089],\n",
       "         [ 0.0411, -0.0777,  0.0359,  ..., -0.0947,  0.0923,  0.1312],\n",
       "         ...,\n",
       "         [-0.0166,  0.0511, -0.0418,  ...,  0.2347,  0.0373,  0.0219],\n",
       "         [-0.3071, -0.1300,  0.0977,  ..., -0.3276, -0.2328, -0.2103],\n",
       "         [-0.0814, -0.2233,  0.1093,  ..., -0.1879, -0.1793, -0.1509]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_query.bias': tensor([-0.1097, -0.2244,  0.1980,  ..., -0.0424,  0.0051, -0.0490],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.final_linear.weight': tensor([[-0.2305, -0.0163,  0.1232,  ...,  0.3679,  0.2944, -0.0201],\n",
       "         [ 0.2825, -0.3196,  0.0299,  ...,  0.3411,  0.2332, -0.2466],\n",
       "         [ 0.1153, -0.1301, -0.1711,  ...,  0.0217, -0.2856, -0.2861],\n",
       "         ...,\n",
       "         [-0.2355,  0.1714,  0.0613,  ..., -0.0398, -0.2347,  0.0804],\n",
       "         [ 0.1771, -0.1948,  0.1324,  ...,  0.2856, -0.0511, -0.0304],\n",
       "         [ 0.0372,  0.3025, -0.4363,  ...,  0.2578, -0.0452, -0.1451]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.final_linear.bias': tensor([-0.2571, -0.0980, -0.3325,  ..., -0.5020, -0.4917,  0.4910],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_1.weight': tensor([0.2859, 0.3113, 0.3257,  ..., 0.2101, 0.2292, 0.2230],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_1.bias': tensor([ 0.0132,  0.0039,  0.0213,  ..., -0.0128,  0.0103, -0.0153],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_keys.weight': tensor([[-0.3931,  0.0401,  0.1293,  ..., -0.1195, -0.0222,  0.0602],\n",
       "         [ 0.2490, -0.2781, -0.0809,  ..., -0.0480,  0.1019, -0.0571],\n",
       "         [-0.1403,  0.0654, -0.0033,  ...,  0.0448,  0.0354,  0.1317],\n",
       "         ...,\n",
       "         [-0.1971, -0.1921, -0.2170,  ...,  0.2629,  0.1705, -0.0448],\n",
       "         [ 0.0312, -0.1581,  0.1361,  ..., -0.0624, -0.0419,  0.0023],\n",
       "         [-0.0662,  0.0148, -0.1705,  ..., -0.0999, -0.0140, -0.0345]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_keys.bias': tensor([ 0.0095,  0.0270,  0.0019,  ...,  0.0180, -0.0116,  0.0144],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_values.weight': tensor([[ 0.0465,  0.1771, -0.3411,  ..., -0.0360, -0.1864,  0.0047],\n",
       "         [ 0.0253, -0.0935,  0.0439,  ...,  0.2808,  0.1083, -0.0020],\n",
       "         [ 0.0543, -0.3330, -0.0420,  ..., -0.2228,  0.1534,  0.0454],\n",
       "         ...,\n",
       "         [-0.1678, -0.2131, -0.0310,  ..., -0.1007,  0.1016, -0.0550],\n",
       "         [-0.1109,  0.0102,  0.1556,  ...,  0.1377, -0.0242,  0.0895],\n",
       "         [ 0.0603,  0.3479,  0.2795,  ...,  0.0861, -0.2308, -0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_values.bias': tensor([-0.0964, -0.0339,  0.0177,  ..., -0.0941, -0.0497, -0.0724],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_query.weight': tensor([[-0.1450, -0.3315, -0.1952,  ...,  0.0352,  0.0111,  0.0752],\n",
       "         [-0.0774, -0.0184, -0.0053,  ...,  0.1453,  0.0826,  0.3909],\n",
       "         [-0.2399, -0.0374, -0.0986,  ..., -0.2700,  0.3972,  0.3582],\n",
       "         ...,\n",
       "         [-0.0827, -0.0493, -0.0366,  ...,  0.0909, -0.2639,  0.0032],\n",
       "         [ 0.1049,  0.1342,  0.3726,  ..., -0.0033,  0.0166,  0.1332],\n",
       "         [-0.2563, -0.3057, -0.1438,  ..., -0.1454, -0.0888, -0.0361]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_query.bias': tensor([ 0.0404,  0.1339, -0.0085,  ...,  0.1522,  0.0819,  0.0841],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.final_linear.weight': tensor([[ 0.0031, -0.0746,  0.2087,  ..., -0.1304, -0.2308, -0.2993],\n",
       "         [-0.0189, -0.2008, -0.2449,  ..., -0.1711, -0.0311,  0.1272],\n",
       "         [-0.2607,  0.1437, -0.4104,  ...,  0.0939, -0.0751,  0.2810],\n",
       "         ...,\n",
       "         [ 0.0663, -0.4783,  0.0988,  ..., -0.0980,  0.1279, -0.1688],\n",
       "         [-0.1671, -0.1387,  0.1354,  ..., -0.2666, -0.3020, -0.0603],\n",
       "         [ 0.0801, -0.0495,  0.4460,  ...,  0.1710, -0.0508, -0.0991]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.final_linear.bias': tensor([ 0.1298,  0.2185,  0.3086,  ...,  0.0321, -0.1702, -0.3853],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_2.weight': tensor([0.1193, 0.1481, 0.1348,  ..., 0.0941, 0.1001, 0.0947],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_2.bias': tensor([-0.0073, -0.0116, -0.0107,  ..., -0.0408, -0.0026, -0.0193],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_1.weight': tensor([[-0.4097, -0.2700,  0.0737,  ...,  0.0936,  0.0958,  0.2720],\n",
       "         [ 0.0781, -0.1074,  0.0117,  ...,  0.2820,  0.2788, -0.1580],\n",
       "         [-0.2754, -0.2556,  0.0128,  ...,  0.2820,  0.0628,  0.0275],\n",
       "         ...,\n",
       "         [ 0.1747,  0.2019,  0.3281,  ...,  0.3142,  0.0674,  0.1089],\n",
       "         [-0.1899, -0.1687,  0.3840,  ..., -0.1477, -0.3643,  0.2465],\n",
       "         [ 0.4243,  0.2018, -0.3101,  ...,  0.2864, -0.1592,  0.0157]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_1.bias': tensor([-0.2307,  0.0841, -0.3652,  ..., -0.2961, -0.1600, -0.1461],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_2.weight': tensor([[-0.0831, -0.1288,  0.0689,  ..., -0.2583, -0.0450,  0.1154],\n",
       "         [-0.3525, -0.0558, -0.0667,  ..., -0.2041,  0.1604, -0.0671],\n",
       "         [-0.1544, -0.0462, -0.3406,  ...,  0.0112,  0.2053,  0.0386],\n",
       "         ...,\n",
       "         [ 0.2124, -0.1754, -0.0749,  ...,  0.2812,  0.3555,  0.1595],\n",
       "         [-0.0262, -0.1567,  0.1155,  ...,  0.2015, -0.0365,  0.1342],\n",
       "         [ 0.1613,  0.0448,  0.0573,  ...,  0.3638, -0.1046,  0.0436]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_2.bias': tensor([-0.1475, -0.1466,  0.2227,  ..., -0.0585,  0.1493,  0.0556],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.layer_norm.weight': tensor([0.5186, 0.5400, 0.5186,  ..., 0.4551, 0.4565, 0.4644],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.layer_norm.bias': tensor([ 0.0312,  0.1107,  0.0245,  ..., -0.1113, -0.0250,  0.0216],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_keys.weight': tensor([[-6.5857e-02,  2.0251e-01, -5.7465e-02,  ...,  4.4647e-02,\n",
       "          -1.0632e-01,  7.2449e-02],\n",
       "         [ 1.3733e-02, -1.0150e-01, -2.9434e-02,  ...,  1.1426e-01,\n",
       "           1.4832e-01,  8.0338e-03],\n",
       "         [ 1.1176e-01, -4.4739e-02, -8.9355e-02,  ..., -5.9605e-06,\n",
       "          -1.0858e-01, -2.6672e-02],\n",
       "         ...,\n",
       "         [-2.2217e-01, -1.2128e-01, -5.0537e-02,  ...,  1.6589e-01,\n",
       "          -1.8567e-01, -5.2338e-02],\n",
       "         [ 5.4565e-02,  7.6027e-03, -1.1421e-02,  ..., -1.1682e-01,\n",
       "           5.4169e-02,  2.6636e-01],\n",
       "         [-1.3696e-01, -3.6450e-01,  2.5366e-01,  ..., -3.2410e-02,\n",
       "          -1.6187e-01,  9.6558e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_keys.bias': tensor([-0.0155,  0.0081, -0.0183,  ..., -0.0101, -0.0080,  0.0053],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_values.weight': tensor([[ 0.3101, -0.0659, -0.4985,  ..., -0.0261,  0.1904, -0.0820],\n",
       "         [ 0.1340, -0.1665, -0.0553,  ..., -0.0634,  0.3303, -0.4929],\n",
       "         [-0.5005, -0.4053,  0.0614,  ...,  0.1809, -0.4783,  0.2988],\n",
       "         ...,\n",
       "         [-0.0119, -0.3416, -0.1237,  ...,  0.0163, -0.1481, -0.0235],\n",
       "         [-0.2915,  0.0356, -0.1187,  ..., -0.1050, -0.2200,  0.3716],\n",
       "         [-0.2551,  0.0391,  0.1863,  ..., -0.0909, -0.0381,  0.0756]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_values.bias': tensor([-0.0251, -0.0740,  0.1063,  ..., -0.0436,  0.0135,  0.0956],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_query.weight': tensor([[-0.0420, -0.3079, -0.0490,  ...,  0.1382,  0.0266,  0.1229],\n",
       "         [-0.0640,  0.0458,  0.1144,  ...,  0.1064, -0.1210, -0.0217],\n",
       "         [ 0.1219, -0.0167,  0.0353,  ..., -0.0523, -0.1027,  0.1458],\n",
       "         ...,\n",
       "         [ 0.3435, -0.0014,  0.2062,  ...,  0.0873, -0.1273, -0.0268],\n",
       "         [-0.1941,  0.1359, -0.2434,  ...,  0.2717,  0.1084,  0.2108],\n",
       "         [-0.1007,  0.1511, -0.1353,  ...,  0.1998, -0.2651, -0.3638]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_query.bias': tensor([-0.0583, -0.0863,  0.0507,  ..., -0.0739,  0.1298,  0.1917],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.final_linear.weight': tensor([[ 0.2006, -0.1216,  0.1897,  ...,  0.0042,  0.0221, -0.0220],\n",
       "         [-0.2788,  0.2749,  0.3147,  ..., -0.3538, -0.1953,  0.1487],\n",
       "         [-0.1451,  0.3015, -0.4993,  ..., -0.1499,  0.0264, -0.0385],\n",
       "         ...,\n",
       "         [-0.3020,  0.2366, -0.0396,  ..., -0.0085, -0.3369, -0.0049],\n",
       "         [ 0.2009, -0.1084, -0.2537,  ..., -0.3242, -0.2581,  0.1196],\n",
       "         [ 0.4978, -0.2510,  0.3047,  ..., -0.0637,  0.0760, -0.1024]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.final_linear.bias': tensor([-0.2795,  0.4678, -0.2693,  ..., -0.4160, -0.0284,  0.2915],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_1.weight': tensor([0.2969, 0.3320, 0.3101,  ..., 0.2297, 0.2537, 0.2499],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_1.bias': tensor([ 0.0145,  0.0063,  0.0268,  ..., -0.0158,  0.0065, -0.0284],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_keys.weight': tensor([[ 0.0375, -0.0067,  0.0670,  ..., -0.3262, -0.0666,  0.0624],\n",
       "         [-0.0308,  0.0286, -0.1774,  ..., -0.1131, -0.0634,  0.1097],\n",
       "         [-0.0727,  0.0724, -0.2861,  ...,  0.2018,  0.0775, -0.0070],\n",
       "         ...,\n",
       "         [-0.1735, -0.0476, -0.1813,  ..., -0.2632, -0.2131, -0.0457],\n",
       "         [ 0.2214, -0.1711,  0.0067,  ..., -0.3740,  0.2871, -0.0119],\n",
       "         [-0.2520, -0.1650,  0.0536,  ..., -0.2666, -0.4377,  0.1949]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_keys.bias': tensor([ 0.0144, -0.0133,  0.0258,  ...,  0.0226, -0.0057, -0.0240],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_values.weight': tensor([[ 0.1630, -0.0317,  0.1660,  ..., -0.4785, -0.2400, -0.0245],\n",
       "         [ 0.0836, -0.0155,  0.2700,  ...,  0.0586, -0.1124,  0.0049],\n",
       "         [-0.0585,  0.0667, -0.0399,  ..., -0.2175, -0.0422, -0.0768],\n",
       "         ...,\n",
       "         [ 0.2810,  0.2720, -0.0113,  ..., -0.2407, -0.2625,  0.0165],\n",
       "         [ 0.1631,  0.1704,  0.0071,  ..., -0.2157, -0.0864,  0.0110],\n",
       "         [ 0.0294,  0.1296,  0.1190,  ...,  0.1326, -0.0536,  0.0583]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_values.bias': tensor([ 0.0158, -0.1880,  0.0825,  ..., -0.0160, -0.0419, -0.0264],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_query.weight': tensor([[ 0.0022,  0.1277, -0.0131,  ...,  0.0833, -0.0323, -0.1841],\n",
       "         [ 0.1743,  0.0327, -0.2566,  ..., -0.0372, -0.0149,  0.1061],\n",
       "         [ 0.2786,  0.0632,  0.1578,  ...,  0.1000,  0.0400,  0.3135],\n",
       "         ...,\n",
       "         [-0.1490, -0.1283, -0.1852,  ...,  0.0140, -0.1982,  0.0712],\n",
       "         [-0.0038,  0.1048, -0.1748,  ...,  0.1429,  0.2014, -0.0426],\n",
       "         [ 0.2123,  0.0413, -0.0383,  ...,  0.0410, -0.1842,  0.3259]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_query.bias': tensor([-0.0406, -0.0256,  0.0312,  ..., -0.0875,  0.0524,  0.0250],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.final_linear.weight': tensor([[ 0.0500, -0.2297, -0.2686,  ...,  0.1371, -0.0784,  0.0501],\n",
       "         [ 0.3943,  0.1156,  0.1155,  ...,  0.1086, -0.0457,  0.1461],\n",
       "         [-0.0682, -0.1912, -0.1614,  ...,  0.2607,  0.1146, -0.2332],\n",
       "         ...,\n",
       "         [-0.2773, -0.2771,  0.3865,  ..., -0.0358,  0.0470, -0.2032],\n",
       "         [-0.0219,  0.0157, -0.1818,  ..., -0.1792, -0.1313,  0.1989],\n",
       "         [ 0.0125,  0.2400, -0.2211,  ..., -0.0269, -0.1218, -0.4712]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.final_linear.bias': tensor([ 0.1956,  0.0657,  0.3936,  ...,  0.0127, -0.3669, -0.3601],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_2.weight': tensor([0.1075, 0.1220, 0.1219,  ..., 0.0916, 0.0882, 0.0904],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_2.bias': tensor([-0.0060, -0.0189, -0.0099,  ..., -0.0571, -0.0138, -0.0278],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_1.weight': tensor([[ 0.0246, -0.1316,  0.0693,  ...,  0.0710,  0.0610, -0.1390],\n",
       "         [-0.0105,  0.1313, -0.1672,  ...,  0.0849,  0.3064, -0.0118],\n",
       "         [-0.0682,  0.0808,  0.1024,  ..., -0.0484,  0.1665,  0.0039],\n",
       "         ...,\n",
       "         [ 0.3459,  0.1885,  0.3340,  ...,  0.1039, -0.0782, -0.0128],\n",
       "         [ 0.0859, -0.0403,  0.0482,  ..., -0.0431,  0.1514,  0.0355],\n",
       "         [ 0.1876,  0.1115, -0.5215,  ..., -0.3174, -0.3076,  0.0912]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_1.bias': tensor([-0.1182, -0.0240, -0.1111,  ..., -0.0903,  0.0151, -0.2751],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_2.weight': tensor([[-0.0988, -0.2712,  0.0759,  ..., -0.0606,  0.0951,  0.0548],\n",
       "         [-0.0896,  0.0380, -0.1500,  ...,  0.1359,  0.1032, -0.2303],\n",
       "         [-0.2039,  0.2030, -0.0993,  ...,  0.0145, -0.0025,  0.0596],\n",
       "         ...,\n",
       "         [-0.2715,  0.0426,  0.1118,  ..., -0.2710,  0.0401,  0.3145],\n",
       "         [ 0.3484, -0.2305, -0.2507,  ...,  0.0446, -0.0930,  0.0582],\n",
       "         [ 0.0522,  0.2581,  0.1652,  ...,  0.1074, -0.0864,  0.0522]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_2.bias': tensor([-0.0361,  0.0535,  0.2190,  ..., -0.0262,  0.0795, -0.0141],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.layer_norm.weight': tensor([0.5527, 0.5947, 0.5669,  ..., 0.5171, 0.5190, 0.5498],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.layer_norm.bias': tensor([-0.0238,  0.1709,  0.0458,  ..., -0.1510, -0.0305, -0.0568],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_keys.weight': tensor([[ 0.0374,  0.2539,  0.0807,  ..., -0.2534, -0.1730,  0.1367],\n",
       "         [ 0.1406,  0.1671, -0.1053,  ..., -0.0083, -0.1061,  0.0356],\n",
       "         [ 0.1313,  0.2104,  0.0596,  ..., -0.2021,  0.1768,  0.1305],\n",
       "         ...,\n",
       "         [-0.0445,  0.3679,  0.3291,  ..., -0.1658,  0.0309,  0.0033],\n",
       "         [ 0.1257,  0.0351,  0.0739,  ..., -0.0812, -0.0751,  0.0815],\n",
       "         [-0.3774, -0.2363, -0.0306,  ...,  0.2869, -0.1887,  0.2236]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_keys.bias': tensor([-0.0245,  0.0265,  0.0033,  ...,  0.0219, -0.0003, -0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_values.weight': tensor([[ 0.1777,  0.1213, -0.0913,  ..., -0.0241, -0.2084,  0.0174],\n",
       "         [ 0.5625,  0.0407,  0.4060,  ...,  0.0525, -0.2460, -0.0887],\n",
       "         [-0.0046, -0.1355,  0.1956,  ..., -0.2605,  0.1372, -0.1455],\n",
       "         ...,\n",
       "         [ 0.3633, -0.1598,  0.4990,  ...,  0.0370, -0.4541,  0.3074],\n",
       "         [-0.6509,  0.4268,  0.5879,  ...,  0.2170, -0.2910,  0.5000],\n",
       "         [ 0.0174, -0.2291,  0.1272,  ...,  0.3635,  0.0128, -0.2561]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_values.bias': tensor([-0.0603,  0.0184,  0.1882,  ..., -0.0049,  0.0327, -0.1523],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_query.weight': tensor([[-0.0482, -0.3528, -0.1902,  ...,  0.0988,  0.0460,  0.0452],\n",
       "         [-0.0535, -0.1464,  0.1217,  ..., -0.1593, -0.1014,  0.0892],\n",
       "         [-0.0216, -0.0822,  0.0185,  ..., -0.0079,  0.3145,  0.1541],\n",
       "         ...,\n",
       "         [-0.1473,  0.0253, -0.0071,  ..., -0.0023, -0.0278, -0.0009],\n",
       "         [ 0.3037, -0.0680,  0.0512,  ..., -0.0131, -0.1829, -0.1847],\n",
       "         [-0.0150, -0.1372, -0.0367,  ...,  0.0043, -0.1564,  0.1874]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_query.bias': tensor([-0.1130, -0.0684, -0.0753,  ..., -0.3828, -0.1595,  0.0504],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.final_linear.weight': tensor([[ 0.1996,  0.2776,  0.0723,  ...,  0.6182, -0.4133, -0.1593],\n",
       "         [-0.1759,  0.1315,  0.0181,  ...,  0.3464,  0.4951, -0.2612],\n",
       "         [-0.2367,  0.1771,  0.1803,  ..., -0.5269, -0.2527, -0.2202],\n",
       "         ...,\n",
       "         [ 0.0767, -0.0532, -0.1245,  ...,  0.1116,  0.5005, -0.0312],\n",
       "         [-0.0836,  0.0947,  0.0076,  ...,  0.2340, -0.0242, -0.0476],\n",
       "         [ 0.0997,  0.3879, -0.1774,  ...,  0.1447,  0.4998,  0.0815]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.final_linear.bias': tensor([-0.2966,  0.2942, -0.3508,  ..., -0.3872,  0.0909,  0.3867],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_1.weight': tensor([0.3369, 0.3384, 0.3252,  ..., 0.2742, 0.3064, 0.2991],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_1.bias': tensor([ 0.0210,  0.0098,  0.0302,  ..., -0.0051,  0.0017, -0.0262],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_keys.weight': tensor([[ 0.3401,  0.1907,  0.0227,  ...,  0.1218, -0.2205, -0.1613],\n",
       "         [-0.1348,  0.0866,  0.0611,  ...,  0.0736,  0.0831, -0.0015],\n",
       "         [-0.2825,  0.1018,  0.0981,  ..., -0.0231,  0.2522, -0.1433],\n",
       "         ...,\n",
       "         [-0.0963,  0.3123, -0.3767,  ...,  0.2382, -0.0230,  0.0461],\n",
       "         [ 0.3325, -0.4280, -0.1127,  ..., -0.1572,  0.1757,  0.0476],\n",
       "         [ 0.1704,  0.1230, -0.1737,  ..., -0.1663, -0.2683, -0.0545]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_keys.bias': tensor([-0.0267, -0.0164,  0.0116,  ...,  0.0257, -0.0025,  0.0022],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_values.weight': tensor([[ 1.6235e-01, -8.6121e-02, -4.5074e-02,  ...,  1.9666e-01,\n",
       "          -3.8672e-01,  8.2092e-03],\n",
       "         [-2.8613e-01,  3.4271e-02, -4.3677e-01,  ..., -5.0964e-02,\n",
       "          -6.2012e-02,  7.8857e-02],\n",
       "         [-2.7466e-01, -2.5659e-01,  4.3921e-01,  ..., -4.0820e-01,\n",
       "          -3.2642e-01,  3.2349e-02],\n",
       "         ...,\n",
       "         [-4.6753e-02,  2.1582e-01,  1.4502e-01,  ...,  6.9336e-02,\n",
       "           6.7322e-02, -1.3863e-02],\n",
       "         [-7.0251e-02, -2.0645e-02, -1.1169e-01,  ...,  1.6626e-01,\n",
       "           8.9355e-02,  2.6276e-02],\n",
       "         [ 5.1416e-01, -5.3525e-05,  3.3600e-02,  ...,  2.0093e-01,\n",
       "           2.9614e-01,  3.6316e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_values.bias': tensor([-0.0952, -0.1188, -0.1442,  ..., -0.0037,  0.0580,  0.0503],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_query.weight': tensor([[ 0.2246, -0.0369, -0.0668,  ..., -0.2939, -0.1271,  0.0820],\n",
       "         [-0.2778, -0.0588,  0.1204,  ..., -0.2460,  0.1610, -0.0326],\n",
       "         [ 0.1885,  0.0735,  0.1874,  ..., -0.1624,  0.1464, -0.0825],\n",
       "         ...,\n",
       "         [-0.1677,  0.0193, -0.3943,  ...,  0.0600, -0.1323, -0.0068],\n",
       "         [-0.2080, -0.0361,  0.1622,  ..., -0.1429,  0.1573, -0.1770],\n",
       "         [-0.0502,  0.0901,  0.1974,  ...,  0.0373,  0.0597,  0.1471]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_query.bias': tensor([-0.0816, -0.0087, -0.1379,  ...,  0.0420,  0.0195, -0.1461],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.final_linear.weight': tensor([[-0.0215, -0.2637, -0.1755,  ..., -0.4727, -0.0643,  0.0902],\n",
       "         [ 0.0960,  0.2106,  0.0665,  ...,  0.1514, -0.2832, -0.0386],\n",
       "         [ 0.2603, -0.0852,  0.4165,  ..., -0.0095, -0.2157, -0.1486],\n",
       "         ...,\n",
       "         [-0.0221,  0.1790, -0.2588,  ..., -0.1587, -0.1099, -0.0893],\n",
       "         [-0.1489,  0.0752,  0.2411,  ...,  0.0696, -0.1183, -0.0610],\n",
       "         [-0.1570, -0.2546, -0.0327,  ...,  0.0521, -0.1205,  0.4062]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.final_linear.bias': tensor([ 0.4001,  0.2559,  0.4946,  ...,  0.2712, -0.3901, -0.4368],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_2.weight': tensor([0.1088, 0.1266, 0.1223,  ..., 0.0982, 0.0980, 0.0988],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_2.bias': tensor([-0.0053, -0.0124, -0.0187,  ..., -0.0555, -0.0078, -0.0295],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_1.weight': tensor([[-0.0851,  0.0754,  0.1345,  ...,  0.3159,  0.1464,  0.0422],\n",
       "         [ 0.2727,  0.1659, -0.0242,  ..., -0.1598, -0.0930,  0.0657],\n",
       "         [ 0.1584, -0.0405, -0.1112,  ..., -0.0997, -0.1469, -0.2573],\n",
       "         ...,\n",
       "         [ 0.2394, -0.2903, -0.0901,  ...,  0.3789,  0.2290, -0.3430],\n",
       "         [ 0.0126,  0.0057, -0.0182,  ...,  0.0438, -0.3665, -0.0600],\n",
       "         [-0.3196,  0.0820,  0.0243,  ...,  0.1395, -0.0446, -0.4631]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_1.bias': tensor([-0.1229, -0.1085, -0.0858,  ..., -0.3970, -0.1575,  0.0030],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_2.weight': tensor([[-0.1260, -0.0411, -0.0211,  ..., -0.1797,  0.1743,  0.2720],\n",
       "         [-0.2678,  0.2886,  0.2220,  ...,  0.0752,  0.0397,  0.1187],\n",
       "         [-0.2213, -0.2236, -0.0878,  ..., -0.0323, -0.0224, -0.0335],\n",
       "         ...,\n",
       "         [-0.1696,  0.0558,  0.2617,  ..., -0.2012, -0.1853, -0.0159],\n",
       "         [-0.1678, -0.0100, -0.1174,  ..., -0.1779,  0.0478,  0.1150],\n",
       "         [ 0.1125, -0.0822,  0.0068,  ..., -0.2668, -0.2499,  0.3943]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_2.bias': tensor([ 0.0576, -0.2017,  0.3735,  ..., -0.0267,  0.5044,  0.0363],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.layer_norm.weight': tensor([0.6333, 0.6772, 0.6577,  ..., 0.6431, 0.6191, 0.6387],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.layer_norm.bias': tensor([-0.0312,  0.2100,  0.0613,  ..., -0.2198, -0.0563,  0.0056],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_keys.weight': tensor([[-0.2045,  0.0935, -0.1895,  ..., -0.0121, -0.1221, -0.0599],\n",
       "         [-0.0090, -0.3213, -0.0044,  ..., -0.0103, -0.0870,  0.2140],\n",
       "         [-0.0508, -0.1552, -0.1685,  ..., -0.0257, -0.1137, -0.3550],\n",
       "         ...,\n",
       "         [ 0.0738,  0.0740, -0.0399,  ...,  0.0630,  0.0160, -0.0910],\n",
       "         [ 0.0360, -0.0048, -0.0846,  ..., -0.0117,  0.0858, -0.0630],\n",
       "         [-0.0284,  0.0037, -0.2744,  ..., -0.1581, -0.0492, -0.3699]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_keys.bias': tensor([ 0.0037,  0.0206,  0.0255,  ..., -0.0012, -0.0041, -0.0044],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_values.weight': tensor([[-0.0089,  0.4580,  0.1262,  ...,  0.0078,  0.3901, -0.1656],\n",
       "         [ 0.1880, -0.0881,  0.2271,  ..., -0.1149, -0.0731, -0.2908],\n",
       "         [-0.1429, -0.2030, -0.2288,  ..., -0.1512,  0.1527, -0.1395],\n",
       "         ...,\n",
       "         [ 0.1218,  0.2458, -0.0825,  ...,  0.2137,  0.2061, -0.0891],\n",
       "         [ 0.1573,  0.2622, -0.0113,  ...,  0.0221, -0.0740,  0.0135],\n",
       "         [-0.1108, -0.0303,  0.2396,  ..., -0.0332, -0.0999,  0.1989]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_values.bias': tensor([-0.0156,  0.0625,  0.0502,  ..., -0.3411,  0.2294,  0.1083],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_query.weight': tensor([[-0.1903, -0.0818,  0.0698,  ..., -0.1096, -0.1135, -0.2006],\n",
       "         [-0.1033,  0.3027,  0.1921,  ...,  0.1516, -0.0990,  0.0273],\n",
       "         [ 0.1155,  0.1646, -0.0541,  ..., -0.2522,  0.0373, -0.0517],\n",
       "         ...,\n",
       "         [-0.1730, -0.1442,  0.3608,  ...,  0.0540, -0.0877,  0.0861],\n",
       "         [ 0.1680,  0.1840, -0.1689,  ...,  0.0338,  0.0041,  0.0251],\n",
       "         [ 0.0446,  0.1721, -0.0281,  ...,  0.0358,  0.1898,  0.2507]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_query.bias': tensor([ 0.0382, -0.0410, -0.0156,  ..., -0.2959, -0.1064, -0.0396],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.final_linear.weight': tensor([[-0.1278, -0.2954, -0.0012,  ...,  0.0865, -0.0617,  0.0590],\n",
       "         [-0.0119,  0.1688,  0.1304,  ...,  0.3594,  0.0177, -0.3987],\n",
       "         [-0.4302,  0.1376,  0.2698,  ...,  0.2532,  0.1486,  0.0579],\n",
       "         ...,\n",
       "         [ 0.1769,  0.1301,  0.2328,  ...,  0.0317, -0.1260, -0.1396],\n",
       "         [ 0.1765,  0.1703,  0.3884,  ...,  0.1753, -0.0198,  0.1588],\n",
       "         [-0.3267, -0.1447, -0.5879,  ..., -0.1171,  0.1121,  0.1244]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.final_linear.bias': tensor([-0.1833,  0.3335, -0.2705,  ..., -0.1660, -0.0508,  0.5049],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_1.weight': tensor([0.3381, 0.3489, 0.3391,  ..., 0.2952, 0.3115, 0.3103],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_1.bias': tensor([ 0.0134,  0.0132,  0.0375,  ..., -0.0148,  0.0051, -0.0371],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_keys.weight': tensor([[-0.3711, -0.0614,  0.0996,  ..., -0.1182,  0.0873, -0.0322],\n",
       "         [-0.2235,  0.3223,  0.1847,  ..., -0.1969, -0.2405,  0.1166],\n",
       "         [-0.2136,  0.0717, -0.1069,  ...,  0.2681,  0.1412,  0.0034],\n",
       "         ...,\n",
       "         [-0.2046, -0.1971, -0.0922,  ..., -0.1748,  0.0704, -0.0338],\n",
       "         [-0.2839,  0.0338, -0.0923,  ..., -0.1671, -0.1193, -0.1566],\n",
       "         [ 0.1528,  0.1070,  0.4490,  ..., -0.1133,  0.0535, -0.0446]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_keys.bias': tensor([-0.0200, -0.0157, -0.0066,  ..., -0.0196,  0.0060, -0.0199],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_values.weight': tensor([[ 0.1058, -0.1161, -0.4517,  ..., -0.2382,  0.5146,  0.0323],\n",
       "         [-0.3267, -0.0266, -0.2542,  ...,  0.1765,  0.0455,  0.0431],\n",
       "         [-0.0636, -0.2844, -0.0081,  ...,  0.1559,  0.4092, -0.1288],\n",
       "         ...,\n",
       "         [ 0.1447,  0.1050,  0.2108,  ..., -0.6055,  0.3354, -0.0129],\n",
       "         [ 0.3230,  0.1869,  0.1417,  ...,  0.0695, -0.3398, -0.0172],\n",
       "         [ 0.1238, -0.2754,  0.4731,  ..., -0.1932, -0.1099, -0.0350]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_values.bias': tensor([-0.1930, -0.0421,  0.1481,  ..., -0.1722, -0.0246,  0.0468],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_query.weight': tensor([[-0.4705, -0.0850, -0.0084,  ..., -0.3408,  0.0473,  0.0865],\n",
       "         [ 0.1898,  0.0959,  0.1753,  ...,  0.1469, -0.1388,  0.1073],\n",
       "         [ 0.1635,  0.0573, -0.0794,  ..., -0.0566, -0.0975, -0.1176],\n",
       "         ...,\n",
       "         [ 0.0769, -0.1356, -0.0036,  ..., -0.0539,  0.0759, -0.1608],\n",
       "         [ 0.1654, -0.2303,  0.0085,  ..., -0.2002, -0.1268, -0.1071],\n",
       "         [-0.1133, -0.1595, -0.2695,  ..., -0.3528,  0.2029,  0.0522]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_query.bias': tensor([-0.0659,  0.3047,  0.0176,  ..., -0.0298, -0.1838,  0.0766],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.final_linear.weight': tensor([[ 0.1005, -0.2866,  0.0150,  ...,  0.0687,  0.0201,  0.1119],\n",
       "         [-0.3127,  0.0046, -0.4910,  ...,  0.1282, -0.5044, -0.1580],\n",
       "         [-0.0880,  0.1805, -0.3584,  ...,  0.2240, -0.0374, -0.4968],\n",
       "         ...,\n",
       "         [-0.4656,  0.1459, -0.1335,  ..., -0.4026, -0.0428, -0.1377],\n",
       "         [ 0.1560,  0.2075,  0.0927,  ..., -0.0337,  0.0627,  0.0725],\n",
       "         [-0.0769,  0.4978,  0.0244,  ...,  0.6108, -0.0981,  0.1642]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.final_linear.bias': tensor([ 0.1737,  0.0965,  0.4023,  ..., -0.2581, -0.4963, -0.3105],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_2.weight': tensor([0.1185, 0.1268, 0.1243,  ..., 0.0994, 0.1035, 0.1086],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_2.bias': tensor([-0.0175, -0.0222, -0.0108,  ..., -0.0543, -0.0084, -0.0273],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_1.weight': tensor([[ 0.0210, -0.0683,  0.2157,  ...,  0.0250,  0.3140,  0.4192],\n",
       "         [ 0.2238,  0.2529,  0.1068,  ...,  0.2678,  0.0637,  0.1896],\n",
       "         [ 0.4622,  0.0760,  0.2435,  ...,  0.1342,  0.2158, -0.1066],\n",
       "         ...,\n",
       "         [-0.0657,  0.0519, -0.1526,  ...,  0.2031,  0.1222, -0.0950],\n",
       "         [ 0.3167,  0.2002,  0.4006,  ...,  0.2532,  0.0899,  0.1620],\n",
       "         [ 0.0201, -0.0225, -0.0485,  ...,  0.0050, -0.2136, -0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_1.bias': tensor([-0.1454,  0.0207, -0.2444,  ..., -0.2520, -0.2686, -0.0136],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_2.weight': tensor([[ 0.0240,  0.0366, -0.3574,  ..., -0.0224, -0.1803, -0.0250],\n",
       "         [-0.1412, -0.0702, -0.0832,  ...,  0.1190,  0.1544, -0.0342],\n",
       "         [ 0.1305, -0.0353, -0.0725,  ..., -0.1155,  0.4028, -0.3269],\n",
       "         ...,\n",
       "         [-0.0705, -0.2150,  0.0446,  ...,  0.0066,  0.0831,  0.1426],\n",
       "         [-0.1654,  0.1814, -0.2573,  ..., -0.2487,  0.2815, -0.0829],\n",
       "         [-0.1708,  0.1843,  0.0834,  ...,  0.1592,  0.1464, -0.4170]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_2.bias': tensor([ 0.3928, -0.1920,  0.4954,  ..., -0.3877,  0.5059,  0.1106],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.layer_norm.weight': tensor([0.7974, 0.8071, 0.7432,  ..., 0.8247, 0.7603, 0.7881],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.layer_norm.bias': tensor([-0.1459,  0.1334,  0.0034,  ..., -0.1862, -0.0635, -0.1029],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_keys.weight': tensor([[-0.1423,  0.0493, -0.0364,  ..., -0.2412, -0.0038, -0.1906],\n",
       "         [-0.1034,  0.0400, -0.0563,  ...,  0.0095,  0.1847,  0.1011],\n",
       "         [ 0.0593, -0.0185, -0.1671,  ...,  0.0114, -0.2832, -0.0166],\n",
       "         ...,\n",
       "         [-0.0690, -0.1224,  0.2441,  ..., -0.0893,  0.0546,  0.2991],\n",
       "         [-0.0170, -0.0854,  0.1444,  ..., -0.0768,  0.1268,  0.1306],\n",
       "         [ 0.1249,  0.1434,  0.1725,  ..., -0.2191, -0.0253, -0.0129]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_keys.bias': tensor([-0.0060,  0.0152,  0.0233,  ..., -0.0166,  0.0221, -0.0134],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_values.weight': tensor([[ 0.1410,  0.1727, -0.0191,  ..., -0.1436,  0.0425,  0.3655],\n",
       "         [ 0.2812, -0.0403,  0.1802,  ..., -0.1816, -0.2754, -0.1415],\n",
       "         [ 0.1836,  0.2639, -0.3894,  ..., -0.3167,  0.1504, -0.4910],\n",
       "         ...,\n",
       "         [ 0.2883, -0.0306, -0.3403,  ...,  0.0630, -0.2426, -0.0954],\n",
       "         [-0.0223,  0.1888, -0.0462,  ..., -0.0820,  0.1877, -0.0966],\n",
       "         [-0.1565, -0.0103,  0.1691,  ..., -0.1262, -0.2935,  0.1974]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_values.bias': tensor([ 0.0117,  0.1648,  0.0165,  ..., -0.2168,  0.2529, -0.0457],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_query.weight': tensor([[ 0.0427, -0.1158, -0.1973,  ..., -0.0760,  0.0096,  0.0612],\n",
       "         [ 0.0319, -0.3293,  0.0804,  ...,  0.0157,  0.0489,  0.0158],\n",
       "         [ 0.1538,  0.0602,  0.1025,  ...,  0.0074, -0.0712, -0.3633],\n",
       "         ...,\n",
       "         [-0.0150, -0.0189,  0.0870,  ...,  0.0556,  0.0825,  0.0517],\n",
       "         [ 0.0912, -0.2279, -0.0597,  ...,  0.1247, -0.0776, -0.0311],\n",
       "         [ 0.0519,  0.0293, -0.0393,  ...,  0.1355,  0.0712, -0.2561]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_query.bias': tensor([-0.1656, -0.0432, -0.0004,  ...,  0.0256, -0.1768, -0.0460],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.final_linear.weight': tensor([[ 0.4148,  0.2620,  0.1461,  ..., -0.2103, -0.0971, -0.0137],\n",
       "         [ 0.0315,  0.1788, -0.1793,  ...,  0.2517, -0.2411, -0.2437],\n",
       "         [ 0.2203, -0.0828, -0.3955,  ...,  0.0433, -0.3066, -0.2430],\n",
       "         ...,\n",
       "         [ 0.2292,  0.0508, -0.0446,  ..., -0.0126,  0.1786, -0.0538],\n",
       "         [-0.1774, -0.1196, -0.0755,  ...,  0.2372, -0.1290,  0.0710],\n",
       "         [-0.3435,  0.0744,  0.2435,  ...,  0.1345, -0.1583, -0.0632]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.final_linear.bias': tensor([ 0.1243,  0.2539, -0.2976,  ...,  0.2218,  0.1137,  0.5005],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_1.weight': tensor([0.4102, 0.3804, 0.3806,  ..., 0.3447, 0.3757, 0.3708],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_1.bias': tensor([ 0.0182,  0.0095,  0.0290,  ..., -0.0136,  0.0106, -0.0280],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_keys.weight': tensor([[-0.1570, -0.1323,  0.1772,  ...,  0.0469, -0.0352,  0.0019],\n",
       "         [ 0.1349, -0.2822,  0.0867,  ...,  0.0389,  0.1478, -0.0174],\n",
       "         [ 0.3291,  0.3396, -0.0086,  ...,  0.1729, -0.1600, -0.0617],\n",
       "         ...,\n",
       "         [ 0.0868, -0.1453,  0.1772,  ...,  0.0400,  0.0132,  0.0280],\n",
       "         [ 0.2019, -0.1984, -0.2167,  ..., -0.0485,  0.0724,  0.0322],\n",
       "         [-0.0590, -0.1819,  0.2715,  ..., -0.0208,  0.1816,  0.0951]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_keys.bias': tensor([-0.0289,  0.0023, -0.0247,  ..., -0.0080, -0.0143, -0.0205],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_values.weight': tensor([[ 0.1135,  0.0676,  0.0016,  ...,  0.1982,  0.0425, -0.0825],\n",
       "         [ 0.2925, -0.0800, -0.0367,  ...,  0.3589,  0.2947,  0.0084],\n",
       "         [ 0.2712, -0.0820,  0.3889,  ..., -0.0808, -0.3374, -0.0158],\n",
       "         ...,\n",
       "         [ 0.2910,  0.1021, -0.0634,  ..., -0.1815,  0.0561,  0.0302],\n",
       "         [-0.0091,  0.0112,  0.0781,  ...,  0.1381, -0.3035, -0.0421],\n",
       "         [ 0.1682, -0.0823, -0.3062,  ..., -0.4304,  0.1691, -0.1249]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_values.bias': tensor([ 0.0173, -0.0172,  0.1008,  ..., -0.0360,  0.2008,  0.3875],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_query.weight': tensor([[-0.1891, -0.1931, -0.1881,  ..., -0.2788, -0.0663, -0.0147],\n",
       "         [ 0.1151, -0.2732, -0.0383,  ..., -0.3081, -0.1140,  0.0378],\n",
       "         [ 0.0862,  0.1174,  0.1058,  ...,  0.0028,  0.0516,  0.1337],\n",
       "         ...,\n",
       "         [ 0.1978, -0.2303,  0.2014,  ...,  0.0764, -0.0551, -0.0450],\n",
       "         [-0.0210,  0.0884,  0.1086,  ...,  0.0174, -0.0796,  0.1521],\n",
       "         [ 0.0110, -0.0436, -0.0723,  ..., -0.0287, -0.0842, -0.0739]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_query.bias': tensor([ 0.0989,  0.0967, -0.0564,  ..., -0.0964, -0.0172,  0.1020],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.final_linear.weight': tensor([[-0.1542,  0.2229, -0.0826,  ..., -0.1195, -0.4167,  0.3042],\n",
       "         [ 0.1630, -0.0679,  0.4854,  ..., -0.0095,  0.1709,  0.2983],\n",
       "         [ 0.0172,  0.0249, -0.0252,  ..., -0.3215,  0.0625,  0.4380],\n",
       "         ...,\n",
       "         [-0.0400, -0.0425,  0.1798,  ...,  0.2079,  0.4265, -0.1339],\n",
       "         [-0.0088,  0.0418, -0.2290,  ..., -0.1038, -0.1912,  0.1637],\n",
       "         [-0.0147,  0.0756,  0.0246,  ..., -0.1266, -0.1960,  0.1256]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.final_linear.bias': tensor([-0.3616,  0.0895, -0.0173,  ...,  0.2443, -0.3513, -0.4993],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_2.weight': tensor([0.1331, 0.1266, 0.1376,  ..., 0.1132, 0.1064, 0.1123],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_2.bias': tensor([-0.0070, -0.0088, -0.0046,  ..., -0.0548, -0.0182, -0.0306],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_1.weight': tensor([[-0.4417, -0.2146,  0.1429,  ..., -0.1768, -0.0359,  0.2349],\n",
       "         [-0.0397, -0.4207,  0.0406,  ...,  0.1848, -0.0008, -0.0076],\n",
       "         [ 0.1375, -0.1194,  0.0920,  ..., -0.1770,  0.4021, -0.0606],\n",
       "         ...,\n",
       "         [-0.0806, -0.1650,  0.2084,  ...,  0.1735,  0.2954, -0.1643],\n",
       "         [ 0.5210, -0.0171,  0.2417,  ...,  0.1959, -0.0807, -0.0129],\n",
       "         [-0.1121,  0.0619, -0.0764,  ..., -0.1229, -0.0679, -0.0245]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_1.bias': tensor([-0.1028, -0.3286, -0.2461,  ..., -0.3433, -0.4426, -0.0970],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_2.weight': tensor([[ 0.0093,  0.0911, -0.0565,  ..., -0.0317, -0.2344, -0.0305],\n",
       "         [-0.1876,  0.0094,  0.1968,  ..., -0.0558, -0.0459,  0.0405],\n",
       "         [ 0.0945, -0.0292,  0.0138,  ..., -0.2668,  0.0869,  0.0090],\n",
       "         ...,\n",
       "         [-0.2488,  0.2688,  0.2932,  ...,  0.2343, -0.2141, -0.0137],\n",
       "         [ 0.0183,  0.1749, -0.2096,  ...,  0.0723,  0.1492,  0.2289],\n",
       "         [ 0.0099, -0.0686,  0.1202,  ...,  0.0895,  0.4971,  0.1537]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_2.bias': tensor([ 0.5020, -0.3313,  0.4246,  ..., -0.5049,  0.5127, -0.2952],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.layer_norm.weight': tensor([1.0195, 1.0068, 0.9004,  ..., 1.0664, 0.9517, 1.0547],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.layer_norm.bias': tensor([-0.0638,  0.1104, -0.0249,  ..., -0.1152, -0.0183, -0.0844],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_keys.weight': tensor([[ 0.0412,  0.0670, -0.1750,  ...,  0.0121,  0.0238, -0.1610],\n",
       "         [-0.0029, -0.0763, -0.0480,  ..., -0.0039, -0.0032, -0.0043],\n",
       "         [-0.1422, -0.0167, -0.0263,  ..., -0.0453,  0.0587,  0.0488],\n",
       "         ...,\n",
       "         [-0.0135, -0.2300, -0.1558,  ...,  0.0684, -0.0237, -0.0024],\n",
       "         [ 0.0916, -0.0360,  0.0775,  ...,  0.0323,  0.3794,  0.0118],\n",
       "         [ 0.0227, -0.2444, -0.0505,  ...,  0.1031,  0.0501, -0.0388]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_keys.bias': tensor([ 0.0125, -0.0178, -0.0150,  ...,  0.0234, -0.0055, -0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_values.weight': tensor([[ 0.0773, -0.0530,  0.0605,  ..., -0.1372,  0.0030,  0.0672],\n",
       "         [ 0.2700,  0.0829, -0.3567,  ...,  0.2375, -0.0533,  0.0267],\n",
       "         [ 0.0301,  0.2338,  0.0894,  ..., -0.2131, -0.3374,  0.2045],\n",
       "         ...,\n",
       "         [-0.2666, -0.2839, -0.1636,  ...,  0.3601,  0.0040, -0.3984],\n",
       "         [-0.0587,  0.0031, -0.1780,  ...,  0.2126,  0.2250,  0.1445],\n",
       "         [-0.2861,  0.4861,  0.2120,  ..., -0.1197,  0.0020, -0.3445]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_values.bias': tensor([ 0.2822,  0.0126,  0.1081,  ..., -0.1305, -0.0354, -0.1240],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_query.weight': tensor([[ 0.0190,  0.2964, -0.2443,  ..., -0.0494,  0.1162, -0.1262],\n",
       "         [-0.0831,  0.1069, -0.2057,  ...,  0.0015, -0.0763, -0.0235],\n",
       "         [-0.0543, -0.1862, -0.0384,  ...,  0.0033,  0.2153,  0.0687],\n",
       "         ...,\n",
       "         [ 0.1157,  0.0988,  0.0569,  ...,  0.2520,  0.2612, -0.1421],\n",
       "         [ 0.1771, -0.0110, -0.0386,  ...,  0.0368, -0.1282,  0.1573],\n",
       "         [ 0.0934, -0.0471,  0.1450,  ...,  0.0489, -0.0100, -0.0621]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_query.bias': tensor([ 0.0312, -0.0041,  0.0637,  ...,  0.0500,  0.0525, -0.0266],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.final_linear.weight': tensor([[ 0.0059,  0.2668,  0.2118,  ..., -0.2654, -0.0499,  0.2559],\n",
       "         [-0.2656,  0.0468, -0.2856,  ...,  0.0208, -0.1278, -0.0139],\n",
       "         [ 0.3335, -0.2891,  0.0821,  ...,  0.1823, -0.1914,  0.5107],\n",
       "         ...,\n",
       "         [ 0.3220, -0.3181,  0.3914,  ..., -0.2502, -0.1149, -0.1750],\n",
       "         [ 0.0428,  0.4807, -0.2045,  ..., -0.2837,  0.4756,  0.1137],\n",
       "         [ 0.2433,  0.1946,  0.1001,  ..., -0.3577,  0.1799,  0.0641]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.final_linear.bias': tensor([ 0.1238, -0.4033, -0.2258,  ...,  0.2472,  0.3831,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_1.weight': tensor([0.4631, 0.4277, 0.4272,  ..., 0.4153, 0.4421, 0.4478],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_1.bias': tensor([ 0.0149,  0.0303,  0.0506,  ..., -0.0093,  0.0063, -0.0349],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_keys.weight': tensor([[ 0.0770,  0.0722,  0.1160,  ...,  0.3164,  0.0057, -0.0553],\n",
       "         [ 0.3330, -0.0047,  0.2705,  ..., -0.0791,  0.2482,  0.0441],\n",
       "         [-0.3704, -0.2062, -0.1801,  ..., -0.1881, -0.1003,  0.1001],\n",
       "         ...,\n",
       "         [-0.1610, -0.0007,  0.0804,  ..., -0.1913,  0.0624, -0.0886],\n",
       "         [ 0.3018,  0.2052, -0.0257,  ..., -0.0631,  0.1400,  0.0320],\n",
       "         [ 0.1862,  0.1296,  0.1224,  ..., -0.0197, -0.2944, -0.0590]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_keys.bias': tensor([-0.0226, -0.0145,  0.0011,  ...,  0.0308, -0.0099,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_values.weight': tensor([[-0.3394,  0.0433, -0.1200,  ...,  0.0173, -0.2808, -0.0782],\n",
       "         [-0.0045,  0.4124,  0.1859,  ..., -0.4805,  0.1549,  0.0018],\n",
       "         [-0.4233,  0.1075,  0.4949,  ...,  0.1077,  0.1019, -0.0264],\n",
       "         ...,\n",
       "         [ 0.2230, -0.0882, -0.2074,  ...,  0.0633,  0.1359, -0.0247],\n",
       "         [-0.5117,  0.3386,  0.1121,  ..., -0.0284, -0.0029, -0.0371],\n",
       "         [ 0.0726,  0.0780,  0.4983,  ...,  0.0255, -0.1683, -0.0468]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_values.bias': tensor([ 0.3779, -0.3152,  0.2307,  ...,  0.1636,  0.0676,  0.1646],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_query.weight': tensor([[ 0.2583,  0.1307,  0.1001,  ..., -0.1404,  0.1581, -0.2004],\n",
       "         [-0.3770,  0.1218, -0.2306,  ..., -0.0723, -0.1956, -0.0639],\n",
       "         [-0.0841, -0.5142, -0.1659,  ..., -0.0734, -0.1177,  0.3169],\n",
       "         ...,\n",
       "         [-0.2815,  0.1479,  0.0992,  ..., -0.1552, -0.0829, -0.0184],\n",
       "         [-0.2330, -0.3279,  0.1219,  ..., -0.0037,  0.1787, -0.1523],\n",
       "         [-0.0017,  0.0161,  0.3259,  ..., -0.0775,  0.1696,  0.1904]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_query.bias': tensor([ 0.0332,  0.0112, -0.0296,  ...,  0.0381, -0.1301,  0.1093],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.final_linear.weight': tensor([[ 0.1061, -0.4470, -0.2705,  ...,  0.2384,  0.1384, -0.0640],\n",
       "         [-0.0952,  0.2932,  0.1537,  ..., -0.0050,  0.5049,  0.0322],\n",
       "         [-0.0566,  0.2688,  0.1437,  ...,  0.0014, -0.3093, -0.1046],\n",
       "         ...,\n",
       "         [ 0.1476, -0.1459,  0.0959,  ...,  0.0439,  0.0358,  0.0531],\n",
       "         [-0.2729,  0.0743, -0.1349,  ..., -0.3132, -0.3823,  0.0961],\n",
       "         [-0.0887,  0.0021,  0.0411,  ...,  0.0129,  0.2395, -0.0094]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.final_linear.bias': tensor([-0.2170, -0.0152,  0.1914,  ...,  0.2715, -0.2610,  0.1967],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_2.weight': tensor([0.1378, 0.1429, 0.1512,  ..., 0.1249, 0.1181, 0.1212],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_2.bias': tensor([-0.0044, -0.0116, -0.0141,  ..., -0.0624, -0.0088, -0.0331],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_1.weight': tensor([[-0.1227, -0.1321,  0.0471,  ..., -0.0699,  0.3000,  0.0210],\n",
       "         [ 0.0005, -0.0152,  0.2771,  ...,  0.0279,  0.3499,  0.0677],\n",
       "         [ 0.1163, -0.1272,  0.0693,  ..., -0.0362, -0.1906, -0.1945],\n",
       "         ...,\n",
       "         [ 0.0235,  0.0792, -0.1301,  ..., -0.2754,  0.1683,  0.1143],\n",
       "         [ 0.2629,  0.1120,  0.1351,  ..., -0.4358,  0.3750,  0.1439],\n",
       "         [-0.0416, -0.0441, -0.0393,  ...,  0.2874, -0.1884, -0.1794]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_1.bias': tensor([-0.1962,  0.0445, -0.2059,  ..., -0.0576, -0.1960, -0.2871],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_2.weight': tensor([[ 8.3008e-02, -5.6122e-02, -7.4219e-02,  ...,  1.0742e-01,\n",
       "           1.8079e-01,  3.5797e-02],\n",
       "         [ 6.8481e-02, -3.7988e-01,  6.8176e-02,  ..., -1.2708e-01,\n",
       "          -2.2437e-01, -1.4900e-02],\n",
       "         [ 6.8115e-02,  1.5976e-02, -5.3986e-02,  ...,  9.3079e-03,\n",
       "          -7.8064e-02, -2.0206e-04],\n",
       "         ...,\n",
       "         [ 1.0767e-01, -2.2559e-01,  6.6956e-02,  ...,  1.7554e-01,\n",
       "          -1.1255e-01, -1.7712e-01],\n",
       "         [ 1.7139e-01, -2.7878e-02,  2.8882e-01,  ..., -3.6530e-02,\n",
       "           3.8892e-01, -3.6774e-02],\n",
       "         [ 1.1041e-01,  1.1151e-01,  4.4946e-01,  ...,  2.5220e-01,\n",
       "          -1.1469e-01,  2.3083e-01]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_2.bias': tensor([ 0.4521, -0.3462,  0.2539,  ..., -0.4795,  0.3608, -0.4741],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.layer_norm.weight': tensor([1.1299, 1.1377, 1.1543,  ..., 1.1816, 1.1719, 1.1152],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.layer_norm.bias': tensor([-0.0729,  0.0707,  0.0654,  ..., -0.0680, -0.0355, -0.0500],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_keys.weight': tensor([[-0.0400,  0.3137,  0.2144,  ..., -0.0206, -0.0992,  0.0430],\n",
       "         [ 0.0554, -0.1588, -0.0986,  ...,  0.0203,  0.0802,  0.0438],\n",
       "         [ 0.0055,  0.3245,  0.2040,  ...,  0.0994,  0.1707, -0.0129],\n",
       "         ...,\n",
       "         [ 0.2585,  0.1141, -0.0263,  ...,  0.3691, -0.1616,  0.1261],\n",
       "         [-0.1812, -0.1230, -0.0220,  ...,  0.2556,  0.0544, -0.1011],\n",
       "         [ 0.0005,  0.0013, -0.0595,  ...,  0.1917,  0.1915, -0.1076]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_keys.bias': tensor([-0.0079, -0.0251, -0.0022,  ...,  0.0141, -0.0074, -0.0267],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_values.weight': tensor([[ 0.0881, -0.0816, -0.3635,  ..., -0.1008,  0.2979, -0.1902],\n",
       "         [-0.4851,  0.2356, -0.1570,  ...,  0.4988,  0.2627, -0.2037],\n",
       "         [-0.4224,  0.0797, -0.1847,  ...,  0.1333,  0.2605,  0.1112],\n",
       "         ...,\n",
       "         [-0.1384,  0.1107,  0.3318,  ...,  0.0625, -0.3311,  0.2041],\n",
       "         [ 0.2361, -0.0741,  0.0787,  ...,  0.1681,  0.2666,  0.1646],\n",
       "         [ 0.0750,  0.3904,  0.2969,  ..., -0.0723,  0.3203,  0.2676]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_values.bias': tensor([ 0.0285,  0.0306, -0.0096,  ...,  0.1098, -0.0996,  0.0311],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_query.weight': tensor([[-0.0460, -0.0241, -0.1788,  ...,  0.0292,  0.1790,  0.0556],\n",
       "         [ 0.1548,  0.5137,  0.0047,  ...,  0.0356, -0.0297, -0.0916],\n",
       "         [ 0.2031,  0.1603,  0.0542,  ...,  0.1442, -0.1305, -0.3298],\n",
       "         ...,\n",
       "         [ 0.1368, -0.1372,  0.1624,  ..., -0.0352,  0.0616,  0.0765],\n",
       "         [-0.0724,  0.2190,  0.0684,  ...,  0.4541,  0.0286,  0.0825],\n",
       "         [ 0.0134,  0.2773, -0.0466,  ...,  0.0743, -0.0175,  0.0654]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_query.bias': tensor([-0.1167,  0.1196,  0.5557,  ...,  0.0797,  0.0830, -0.0103],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.final_linear.weight': tensor([[ 0.1730, -0.1925,  0.2759,  ..., -0.1399,  0.3088, -0.1022],\n",
       "         [ 0.3936,  0.5000,  0.0141,  ..., -0.1937, -0.4775,  0.0814],\n",
       "         [ 0.2512, -0.1377, -0.1252,  ..., -0.0349, -0.4585, -0.1528],\n",
       "         ...,\n",
       "         [ 0.0133,  0.1696,  0.0926,  ..., -0.1819,  0.3171, -0.1846],\n",
       "         [ 0.3127,  0.3918,  0.3259,  ...,  0.1276,  0.2471, -0.1536],\n",
       "         [-0.2988, -0.4556,  0.1615,  ...,  0.1554,  0.1527,  0.1873]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.final_linear.bias': tensor([-0.0384, -0.5000, -0.2482,  ...,  0.2445,  0.2729,  0.2881],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_1.weight': tensor([0.4563, 0.4343, 0.4404,  ..., 0.4568, 0.4783, 0.4636],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_1.bias': tensor([ 0.0194,  0.0422,  0.0615,  ..., -0.0120,  0.0118, -0.0328],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_keys.weight': tensor([[ 3.4149e-02, -5.1575e-02, -6.8474e-03,  ..., -2.6270e-01,\n",
       "          -1.0559e-01,  3.8544e-02],\n",
       "         [-1.1383e-02,  1.3562e-01,  5.2887e-02,  ..., -3.1143e-02,\n",
       "           4.0924e-02, -1.0577e-01],\n",
       "         [ 1.4014e-01, -5.2338e-02,  1.0590e-01,  ...,  8.5938e-02,\n",
       "          -1.3757e-01, -5.6519e-02],\n",
       "         ...,\n",
       "         [ 8.4595e-02,  1.6101e-01,  5.9387e-02,  ...,  2.5620e-02,\n",
       "           1.3062e-01,  8.1665e-02],\n",
       "         [-1.1390e-04,  1.9577e-02, -4.6783e-02,  ...,  6.4331e-02,\n",
       "           2.7808e-01,  7.2205e-02],\n",
       "         [ 1.6769e-02,  1.3708e-01,  1.8848e-01,  ...,  1.6357e-01,\n",
       "          -3.4241e-02,  4.7729e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_keys.bias': tensor([-0.0041, -0.0047, -0.0187,  ..., -0.0097,  0.0097, -0.0026],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_values.weight': tensor([[-0.3379, -0.1038, -0.1940,  ...,  0.1746, -0.0856,  0.0266],\n",
       "         [-0.2671,  0.0333, -0.0767,  ...,  0.4155, -0.5005, -0.0095],\n",
       "         [ 0.3232, -0.4922, -0.1841,  ..., -0.3206, -0.0970, -0.0087],\n",
       "         ...,\n",
       "         [ 0.1046,  0.0024, -0.0066,  ...,  0.4270, -0.3845, -0.0042],\n",
       "         [-0.1265, -0.1398,  0.5059,  ..., -0.2610, -0.1061, -0.1057],\n",
       "         [-0.2502,  0.1376, -0.0500,  ...,  0.3198, -0.2014, -0.0424]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_values.bias': tensor([-0.1736, -0.1248, -0.0724,  ..., -0.0193,  0.0529, -0.0103],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_query.weight': tensor([[ 0.2465,  0.3572, -0.1578,  ...,  0.1051,  0.1056,  0.2705],\n",
       "         [ 0.1396,  0.0517,  0.1371,  ..., -0.1715,  0.2111,  0.0310],\n",
       "         [ 0.2795, -0.0452,  0.0254,  ...,  0.0745, -0.2004, -0.0875],\n",
       "         ...,\n",
       "         [ 0.2090,  0.1552,  0.0294,  ...,  0.0163,  0.1880, -0.0748],\n",
       "         [-0.0975,  0.2720, -0.0205,  ..., -0.2959,  0.0607, -0.1752],\n",
       "         [-0.0417,  0.0686,  0.0341,  ..., -0.0052, -0.0607,  0.1924]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_query.bias': tensor([-0.0300, -0.0188,  0.1372,  ...,  0.0365,  0.1879, -0.0723],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.final_linear.weight': tensor([[-0.3167,  0.0122,  0.5063,  ..., -0.1279, -0.4751, -0.0692],\n",
       "         [ 0.3191, -0.3286, -0.1993,  ...,  0.2517, -0.3118,  0.1114],\n",
       "         [-0.2600, -0.3374,  0.1562,  ..., -0.0804, -0.0756,  0.4536],\n",
       "         ...,\n",
       "         [-0.4307,  0.0817, -0.2385,  ...,  0.0475, -0.0667, -0.0591],\n",
       "         [-0.3049, -0.0431, -0.3372,  ...,  0.0893, -0.2561, -0.6758],\n",
       "         [ 0.0142, -0.3330, -0.1852,  ...,  0.0263,  0.1252,  0.2230]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.final_linear.bias': tensor([-0.4207,  0.3188, -0.1364,  ...,  0.4988,  0.1904,  0.2290],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_2.weight': tensor([0.1527, 0.1567, 0.1797,  ..., 0.1515, 0.1356, 0.1373],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_2.bias': tensor([ 0.0061, -0.0064, -0.0070,  ..., -0.0638, -0.0081, -0.0396],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_1.weight': tensor([[ 0.1241, -0.1385, -0.1334,  ..., -0.0159,  0.2927,  0.0763],\n",
       "         [ 0.0085,  0.0656,  0.0775,  ..., -0.0494, -0.1176,  0.4116],\n",
       "         [-0.4534,  0.1737,  0.0739,  ...,  0.1304,  0.3660, -0.1552],\n",
       "         ...,\n",
       "         [ 0.4180,  0.0042, -0.1140,  ..., -0.1505, -0.3511, -0.1108],\n",
       "         [-0.1115,  0.1649,  0.0151,  ...,  0.1686,  0.1980, -0.2250],\n",
       "         [ 0.4780,  0.0598, -0.0205,  ...,  0.0529,  0.2556, -0.0136]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_1.bias': tensor([ 0.0577, -0.0452, -0.0366,  ..., -0.1164, -0.1792, -0.0677],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_2.weight': tensor([[-0.0407, -0.1617,  0.1550,  ...,  0.1205, -0.5635,  0.1567],\n",
       "         [-0.4338,  0.2764, -0.1478,  ..., -0.0103, -0.0054,  0.1014],\n",
       "         [-0.3440, -0.4995, -0.1874,  ...,  0.0639, -0.1431, -0.2632],\n",
       "         ...,\n",
       "         [-0.0983,  0.1627,  0.1613,  ..., -0.0656, -0.2231,  0.2571],\n",
       "         [ 0.2744, -0.3892,  0.2253,  ..., -0.0503,  0.2094,  0.0518],\n",
       "         [ 0.1449, -0.2666,  0.1943,  ..., -0.1539, -0.0191, -0.0632]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_2.bias': tensor([ 0.2487, -0.1239, -0.1879,  ..., -0.2219, -0.0636, -0.2351],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.layer_norm.weight': tensor([1.2422, 1.2334, 1.1982,  ..., 1.0586, 1.2021, 1.0361],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.layer_norm.bias': tensor([-0.0576,  0.0120,  0.0236,  ..., -0.0124,  0.0219, -0.0676],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_keys.weight': tensor([[ 0.2886,  0.1121, -0.0573,  ...,  0.0407, -0.0726, -0.2524],\n",
       "         [-0.0529, -0.0389,  0.0386,  ..., -0.1946, -0.0904,  0.0975],\n",
       "         [ 0.0696, -0.2507,  0.1560,  ..., -0.0846, -0.1680,  0.0520],\n",
       "         ...,\n",
       "         [-0.1136,  0.1085,  0.0013,  ...,  0.1771,  0.0459,  0.0127],\n",
       "         [-0.0032, -0.1432,  0.0987,  ...,  0.0447, -0.1344, -0.1840],\n",
       "         [ 0.0046, -0.1639, -0.0983,  ...,  0.0025, -0.1478,  0.0221]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_keys.bias': tensor([-0.0265, -0.0275, -0.0131,  ..., -0.0024,  0.0249,  0.0030],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_values.weight': tensor([[-0.0421,  0.3135,  0.3291,  ...,  0.0999,  0.2000, -0.1260],\n",
       "         [ 0.4084, -0.0457,  0.0492,  ..., -0.3721,  0.1077, -0.1754],\n",
       "         [ 0.2480, -0.3030, -0.0977,  ..., -0.2354,  0.1797,  0.2527],\n",
       "         ...,\n",
       "         [-0.5186, -0.2668,  0.1226,  ..., -0.4153, -0.1384, -0.2952],\n",
       "         [ 0.1610, -0.0661,  0.2795,  ..., -0.1015,  0.3125,  0.0173],\n",
       "         [ 0.3323, -0.0244, -0.1360,  ...,  0.2456, -0.2400,  0.1328]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_values.bias': tensor([-0.1528,  0.0600,  0.0855,  ..., -0.1096,  0.1088,  0.2185],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_query.weight': tensor([[ 0.0587,  0.0670, -0.1146,  ..., -0.2434, -0.0790, -0.1637],\n",
       "         [ 0.0241,  0.0916,  0.1638,  ...,  0.0948,  0.0159, -0.2111],\n",
       "         [ 0.2725,  0.0554, -0.0481,  ...,  0.0247, -0.1354, -0.2389],\n",
       "         ...,\n",
       "         [-0.1547,  0.1963,  0.0953,  ...,  0.1492,  0.0555, -0.2155],\n",
       "         [-0.1432, -0.2502, -0.0406,  ...,  0.1307, -0.1010,  0.1482],\n",
       "         [ 0.0346,  0.0297,  0.2104,  ...,  0.0958,  0.0427,  0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_query.bias': tensor([ 0.0385, -0.0245,  0.0283,  ..., -0.2791, -0.0375,  0.2209],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.final_linear.weight': tensor([[-0.0576,  0.1973,  0.3860,  ...,  0.0765, -0.0016, -0.0147],\n",
       "         [ 0.2068,  0.3779, -0.3418,  ..., -0.0335, -0.2578, -0.1578],\n",
       "         [ 0.1189,  0.2546, -0.0859,  ..., -0.3020, -0.1877, -0.3271],\n",
       "         ...,\n",
       "         [ 0.0778,  0.1593, -0.0295,  ...,  0.2583,  0.0644, -0.0288],\n",
       "         [ 0.1534,  0.1674,  0.3032,  ..., -0.2220, -0.2607, -0.3271],\n",
       "         [-0.0537,  0.2104,  0.3301,  ...,  0.2390, -0.0082,  0.1754]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.final_linear.bias': tensor([ 0.1097, -0.2463, -0.2507,  ...,  0.0800,  0.3486, -0.2583],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_1.weight': tensor([0.4829, 0.4480, 0.4556,  ..., 0.5693, 0.4761, 0.5493],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_1.bias': tensor([ 0.0308,  0.0459,  0.0575,  ...,  0.0363,  0.0300, -0.0277],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_keys.weight': tensor([[ 0.0150, -0.1483,  0.0195,  ..., -0.0609,  0.2163, -0.0399],\n",
       "         [ 0.0737,  0.1042,  0.1449,  ..., -0.0804,  0.0560,  0.0888],\n",
       "         [ 0.0198, -0.0088, -0.1322,  ...,  0.1057, -0.1063,  0.0030],\n",
       "         ...,\n",
       "         [ 0.2419, -0.2389, -0.0453,  ...,  0.0304,  0.2489, -0.0426],\n",
       "         [-0.1217, -0.0621, -0.0611,  ..., -0.0334, -0.2382,  0.0494],\n",
       "         [ 0.1508,  0.0376, -0.2196,  ...,  0.0021, -0.0352,  0.0072]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_keys.bias': tensor([ 0.0108, -0.0240, -0.0222,  ..., -0.0309,  0.0018,  0.0179],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_values.weight': tensor([[ 0.0915, -0.2383,  0.2522,  ..., -0.1445,  0.1812, -0.0104],\n",
       "         [-0.0807, -0.5171,  0.2520,  ...,  0.1231, -0.4302, -0.0272],\n",
       "         [-0.3323, -0.1627, -0.3203,  ...,  0.1217,  0.1506, -0.0217],\n",
       "         ...,\n",
       "         [ 0.2469,  0.3311,  0.0141,  ...,  0.2886, -0.0831,  0.0104],\n",
       "         [-0.2668,  0.0880, -0.2100,  ...,  0.3708,  0.2345,  0.0215],\n",
       "         [-0.4988,  0.3843, -0.3296,  ..., -0.2578,  0.1772,  0.0237]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_values.bias': tensor([-0.0620, -0.0496, -0.1109,  ..., -0.0281, -0.0598, -0.0185],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_query.weight': tensor([[ 0.0280,  0.3601, -0.0068,  ..., -0.0675, -0.1942, -0.1337],\n",
       "         [ 0.0245, -0.2771,  0.0118,  ...,  0.1318,  0.0584, -0.0584],\n",
       "         [ 0.2629,  0.1715,  0.2456,  ..., -0.2177,  0.0575, -0.1232],\n",
       "         ...,\n",
       "         [ 0.1587,  0.0914, -0.1600,  ..., -0.0190,  0.1428,  0.0207],\n",
       "         [ 0.1343,  0.1017, -0.2053,  ..., -0.0431, -0.0784,  0.0717],\n",
       "         [ 0.4167,  0.2212,  0.1477,  ...,  0.2322,  0.1138,  0.1298]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_query.bias': tensor([-0.0859,  0.0497, -0.0948,  ..., -0.1085,  0.3074,  0.0983],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.final_linear.weight': tensor([[ 0.1483, -0.3293,  0.1842,  ...,  0.1281,  0.3018,  0.0837],\n",
       "         [-0.2546, -0.1025,  0.0375,  ..., -0.1661,  0.2649, -0.0537],\n",
       "         [ 0.5557, -0.2404,  0.2537,  ...,  0.2489, -0.4336, -0.2517],\n",
       "         ...,\n",
       "         [ 0.1147, -0.0643,  0.2102,  ...,  0.0982,  0.2448,  0.1059],\n",
       "         [ 0.1241, -0.3018, -0.0366,  ...,  0.0471, -0.0987, -0.0247],\n",
       "         [-0.1238,  0.0363,  0.0179,  ..., -0.1735,  0.0165,  0.0449]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.final_linear.bias': tensor([-0.4980, -0.1772, -0.2944,  ...,  0.3176,  0.3970, -0.3376],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_2.weight': tensor([0.2180, 0.2142, 0.2432,  ..., 0.2505, 0.1937, 0.5459],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_2.bias': tensor([ 0.0131, -0.0211, -0.0297,  ..., -0.0921, -0.0276, -0.1627],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_1.weight': tensor([[ 0.2133,  0.1367,  0.1583,  ...,  0.1154,  0.1157,  0.2507],\n",
       "         [ 0.5381,  0.2512,  0.0615,  ..., -0.1866,  0.0807, -0.4976],\n",
       "         [ 0.1731, -0.0155,  0.1274,  ..., -0.0911, -0.0814,  0.0748],\n",
       "         ...,\n",
       "         [-0.4023,  0.0764,  0.1492,  ...,  0.0858, -0.1229, -0.1460],\n",
       "         [ 0.3167, -0.4993, -0.1406,  ..., -0.0420, -0.0975, -0.1920],\n",
       "         [ 0.0118, -0.0053,  0.3694,  ..., -0.1689,  0.1758,  0.3420]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_1.bias': tensor([-0.0565, -0.1241,  0.1722,  ..., -0.1564, -0.1884, -0.1355],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_2.weight': tensor([[-0.2155,  0.0026, -0.0821,  ...,  0.2438,  0.4438, -0.1379],\n",
       "         [-0.0099,  0.0284,  0.1877,  ..., -0.3665, -0.3655, -0.4993],\n",
       "         [ 0.2686, -0.4487, -0.1062,  ..., -0.1671,  0.3542,  0.2520],\n",
       "         ...,\n",
       "         [-0.0320,  0.1042,  0.0439,  ...,  0.0439, -0.1384,  0.1189],\n",
       "         [-0.0164, -0.0094, -0.0580,  ..., -0.0873,  0.1727,  0.1772],\n",
       "         [-0.0598, -0.1796, -0.1490,  ...,  0.0716, -0.3953,  0.0061]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_2.bias': tensor([ 0.1031,  0.1510, -0.1302,  ...,  0.2443, -0.0541, -0.2505],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.layer_norm.weight': tensor([1.0381, 1.0693, 1.0654,  ..., 1.0059, 1.0098, 1.0000],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.layer_norm.bias': tensor([ 0.1394,  0.1179,  0.1831,  ..., -0.1677,  0.1306, -0.0412],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.layer_norm.weight': tensor([0.6274, 1.0703, 1.1914,  ..., 0.8398, 0.4060, 0.4321],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.layer_norm.bias': tensor([ 0.0264,  0.0236,  0.0949,  ...,  0.3755, -0.0079, -0.0789],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'tgt', 'data_task', 'decoder_start_token'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['vocab'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': tensor([[-0.0321,  0.0348,  0.0181,  ...,  0.0312, -0.0099, -0.0133],\n",
       "         [-0.0039,  0.0104, -0.0156,  ...,  0.0290, -0.0138, -0.0134],\n",
       "         [-0.0245, -0.0283, -0.0295,  ...,  0.9712, -0.0255, -0.0273],\n",
       "         ...,\n",
       "         [-0.0123, -0.0031, -0.0089,  ...,  0.0645, -0.0182, -0.0740],\n",
       "         [ 0.0085, -0.0088, -0.0091,  ...,  0.0571, -0.0035, -0.1298],\n",
       "         [-0.0076, -0.0107, -0.0051,  ...,  1.0264, -0.0338, -0.1175]],\n",
       "        dtype=torch.float16),\n",
       " 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float16)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['generator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config='', save_config=None, data={}, skip_empty_level='silent', save_data='', overwrite=False, n_sample=0, dump_transforms=False, src_vocab='', tgt_vocab='', share_vocab=True, src_feats_vocab=None, src_vocab_size=256206, tgt_vocab_size=256206, vocab_size_multiple=1, src_words_min_frequency=1, tgt_words_min_frequency=1, src_seq_length_trunc=None, tgt_seq_length_trunc=None, both_embeddings=None, src_embeddings=None, tgt_embeddings=None, embeddings_type=None, switchout_temperature=1.0, tokendrop_temperature=1.0, tokenmask_temperature=1.0, reversible_tokenization='joiner', prior_tokenization=False, src_subword_model='', tgt_subword_model='', src_subword_nbest=1, tgt_subword_nbest=1, src_subword_alpha=0.0, tgt_subword_alpha=0.0, src_subword_vocab='', tgt_subword_vocab='', src_vocab_threshold=0, tgt_vocab_threshold=0, src_subword_type='none', tgt_subword_type='none', src_onmttok_kwargs=\"{'mode': 'none'}\", tgt_onmttok_kwargs=\"{'mode': 'none'}\", src_seq_length=150, tgt_seq_length=150, src_prefix='', tgt_prefix='', permute_sent_ratio=0.0, rotate_ratio=0.0, insert_ratio=0.0, random_ratio=0.0, mask_ratio=0.0, mask_length='subword', poisson_lambda=3.0, replace_length=-1, src_word_vec_size=1024, tgt_word_vec_size=1024, word_vec_size=1024, share_decoder_embeddings=True, share_embeddings=True, position_encoding=True, position_encoding_type='SinusoidalConcat', update_vocab=False, feat_merge='concat', feat_vec_size=-1, feat_vec_exponent=0.7, model_task='seq2seq', model_type='text', model_dtype='fp16', encoder_type='transformer', decoder_type='transformer', freeze_encoder=False, freeze_decoder=False, layers=-1, enc_layers=12, dec_layers=12, hidden_size=1024, enc_hid_size=1024, dec_hid_size=1024, cnn_kernel_width=3, pos_ffn_activation_fn='relu', input_feed=1, bridge=False, rnn_type='LSTM', context_gate=None, bridge_extra_node=True, bidir_edges=True, state_dim=512, n_edge_types=2, n_node=2, n_steps=2, src_ggnn_size=0, global_attention='general', global_attention_function='softmax', self_attn_type='scaled-dot', max_relative_positions=0, heads=16, transformer_ff=4096, aan_useffn=False, add_qkvbias=True, lambda_align=0.0, alignment_layer=-3, alignment_heads=0, full_context_alignment=False, copy_attn=False, copy_attn_type='general', generator_function='softmax', copy_attn_force=False, reuse_copy_attn=False, copy_loss_by_seqlength=False, coverage_attn=False, lambda_coverage=0.0, lm_prior_model=None, lm_prior_lambda=0.0, lm_prior_tau=1.0, loss_scale=0, apex_opt_level='', data_type='text', save_model='nllb', save_checkpoint_steps=5000, keep_checkpoint=50, gpu_ranks=[0], world_size=1, gpu_backend='nccl', gpu_verbose_level=0, master_ip='localhost', master_port=10000, seed=1234, param_init=0.0, param_init_glorot=True, train_from='', reset_optim='none', pre_word_vecs_enc=None, pre_word_vecs_dec=None, freeze_word_vecs_enc=False, freeze_word_vecs_dec=False, num_workers=4, batch_size=8192, batch_size_multiple=1, batch_type='tokens', normalization='tokens', accum_count=[4], accum_steps=[0], valid_steps=5000, valid_batch_size=4096, train_steps=100000, single_pass=False, early_stopping=0, early_stopping_criteria=None, optim='', adagrad_accumulator_init=0, max_grad_norm=0.0, dropout=[0.1], attention_dropout=[0.1], dropout_steps=[0], truncated_decoder=0, adam_beta1=0.9, adam_beta2=0.98, label_smoothing=0.1, average_decay=0.0, average_every=1, learning_rate=5e-05, learning_rate_decay=0.5, start_decay_steps=50000, decay_steps=10000, decay_method='none', warmup_steps=4000, log_file='', log_file_level='0', verbose=False, train_eval_steps=200, train_metrics=[], valid_metrics=[], scoring_debug=False, dump_preds=None, report_every=100, exp_host='', exp='', tensorboard=False, tensorboard_log_dir='runs/onmt', bucket_size=262144, bucket_size_init=-1, bucket_size_increment=0, prefetch_factor=400, brnn=False, data_task='seq2seq', decoder_start_token='</s>', _all_transform={'filtertoolong'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['opt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the large TSV file from CC-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>en</th>\n",
       "      <th>zh</th>\n",
       "      <th>extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.249919</td>\n",
       "      <td>(b) The discussion of cumulative impacts shall...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.249479</td>\n",
       "      <td>And [the Lord] became impatient over the miser...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.249218</td>\n",
       "      <td>We saved the world, or at least stopped two wo...</td>\n",
       "      <td>,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.249163</td>\n",
       "      <td>To me, [differences] in their backgrounds, in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.248880</td>\n",
       "      <td>A. In having a foretaste in grace here of what...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.248351</td>\n",
       "      <td>You will then invade Rome, and Allah will enab...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.247962</td>\n",
       "      <td>Maybe tonight or tomorrow [Wednesday] I will s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.247731</td>\n",
       "      <td>They use what is before them, give thanks for it,</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.247479</td>\n",
       "      <td>God made men and women so they can bear childr...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.247374</td>\n",
       "      <td>'They make things happen on the stage; they in...</td>\n",
       "      <td>;;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.247193</td>\n",
       "      <td>(4) the provision(s) in the agreement claimed ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.247132</td>\n",
       "      <td>If Gods Son sets you free, you are free indeed.</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.246990</td>\n",
       "      <td>'But why should one servant return?'</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.246914</td>\n",
       "      <td>And mayest thou see thy childrens children; p...</td>\n",
       "      <td>128:6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.246892</td>\n",
       "      <td>The only thing these men were guilty of was wa...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.246682</td>\n",
       "      <td>But Mariam could not hear comfort in God's words.</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.246461</td>\n",
       "      <td>One of the ways of doing that [was] through t...</td>\n",
       "      <td>[]\\n1.2460833\\tCREATE TABLE...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.245138</td>\n",
       "      <td>(b) contain any other information the EPA may ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                                 en  \\\n",
       "0   1.249919  (b) The discussion of cumulative impacts shall...   \n",
       "1   1.249479  And [the Lord] became impatient over the miser...   \n",
       "2   1.249218  We saved the world, or at least stopped two wo...   \n",
       "3   1.249163  To me, [differences] in their backgrounds, in ...   \n",
       "4   1.248880  A. In having a foretaste in grace here of what...   \n",
       "5   1.248351  You will then invade Rome, and Allah will enab...   \n",
       "6   1.247962  Maybe tonight or tomorrow [Wednesday] I will s...   \n",
       "7   1.247731  They use what is before them, give thanks for it,   \n",
       "8   1.247479  God made men and women so they can bear childr...   \n",
       "9   1.247374  'They make things happen on the stage; they in...   \n",
       "10  1.247193  (4) the provision(s) in the agreement claimed ...   \n",
       "11  1.247132   If Gods Son sets you free, you are free indeed.   \n",
       "12  1.246990               'But why should one servant return?'   \n",
       "13  1.246914  And mayest thou see thy childrens children; p...   \n",
       "14  1.246892  The only thing these men were guilty of was wa...   \n",
       "15  1.246682  But Mariam could not hear comfort in God's words.   \n",
       "16  1.246461  One of the ways of doing that [was] through t...   \n",
       "17  1.245138  (b) contain any other information the EPA may ...   \n",
       "\n",
       "                                                   zh                  extra  \n",
       "0   ...                    NaN  \n",
       "1                                             NaN  \n",
       "2                               ,                    NaN  \n",
       "3   ...                    NaN  \n",
       "4   ...                    NaN  \n",
       "5                                                   NaN  \n",
       "6                                   []                    NaN  \n",
       "7                                                 NaN  \n",
       "8                                                NaN  \n",
       "9                             ;;                    NaN  \n",
       "10  ...                    NaN  \n",
       "11                                                     NaN  \n",
       "12                                                       NaN  \n",
       "13                     128:6                    NaN  \n",
       "14                                                   NaN  \n",
       "15                                                    NaN  \n",
       "16  []\\n1.2460833\\tCREATE TABLE...    \n",
       "17  ...                    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"en-zh.bitextf.tsv\",sep = '\\t', header=None, nrows=18, names =['id','en','zh', 'extra'])\n",
    "df\n",
    "# pd.read_table(\"en-zh.bitextf.tsv\", encoding='utf-8') \n",
    "# 'extra1','extra2','extra3','extra4','extra5','extra6','extra7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"en-zh.bitextf.tsv\",\"r\", encoding='utf-8') as f:\n",
    "    for i in range(21):\n",
    "        line = f.readline()\n",
    "        if (i > 18) & (len(line.split('\\t'))==3):\n",
    "            random_char = line.split('\\t')[2]\n",
    "print(random_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing the rewriting script\n",
    "# new_file = open('new_test.txt',\"a\", encoding='utf-8')\n",
    "\n",
    "# with open(\"en-zh.bitextf.tsv\",\"r\", encoding='utf-8') as f:\n",
    "    \n",
    "#     for i in range(21):\n",
    "#         line = f.readline()\n",
    "#         if (i > 10) & (len(line.split('\\t'))==3) & (random_char not in line):\n",
    "#             new_file.write(line)\n",
    "\n",
    "# new_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the rewriting script\n",
    "new_en_file = open('en-zh.bitextf-en-edited.en',\"a\", encoding='utf-8')\n",
    "new_zh_file = open('en-zh.bitextf-zh-edited.zh',\"a\", encoding='utf-8')\n",
    "\n",
    "with open(\"en-zh.bitextf.tsv\",\"r\", encoding='utf-8') as f:\n",
    "    while line:= f.readline():\n",
    "        if (len(line.split('\\t'))==3) & (random_char not in line):\n",
    "            new_en_file.write(line.split('\\t')[1])\n",
    "            new_zh_file.write(line.split('\\t')[2])\n",
    "\n",
    "new_en_file.close()\n",
    "new_zh_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"en-zh.bitextf-en-edited.en\", encoding='utf-8') as f:\n",
    "    en_str = f.read()\n",
    "with open(\"en-zh.bitextf-zh-edited.zh\", encoding='utf-8') as f:\n",
    "    zh_str = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_str.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = pd.series(en_str)\n",
    "zh_df = pd.series(zh_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using News Data  (600K data points)\n",
    "Pandas does not separate the lines properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news.en\", encoding='utf-8') as f:\n",
    "    en_str = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news.translatedto.zh\", encoding='utf-8') as f:\n",
    "    zh_str = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           52.76 - Geoff Boycott, England (16 innings, 68...\n",
       "1           In the immediate term, though, that lack of pr...\n",
       "2           What this group does is to take down various d...\n",
       "3           'i live 90% of my life in my head ': What Davi...\n",
       "4           The products highlight the city's heritage and...\n",
       "                                  ...                        \n",
       "19763863    Think of new asphalt on streets; these objects...\n",
       "19763864    Ottawa recalled G Matt O'Connor from the AHL t...\n",
       "19763865    Alvarez, who ruled as de facto president from ...\n",
       "19763866        I'm definitely headed in the right direction.\n",
       "19763867                                                     \n",
       "Length: 19763868, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "en_df = pd.Series(en_str.split('\\n'))\n",
    "en_df\n",
    "# 19763867 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            - Geoff Boycott 16686\n",
       "1            Brees 1065...\n",
       "2                            \n",
       "3                                           90%\n",
       "4                            \n",
       "                                  ...                        \n",
       "19763863                    \n",
       "19763864                      G  AHL \n",
       "19763865    2119731981-8519...\n",
       "19763866                                            \n",
       "19763867                                                     \n",
       "Length: 19763868, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_df = pd.Series(zh_str.split('\\n'))\n",
    "zh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"|||||||||||||||||||||||\"\n",
    "\n",
    "relevant_index = zh_df.str.contains(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131         And rarely do Republicans talk about how they ...\n",
       "178         It might strengthen the case for tweaking eggs...\n",
       "196         Once at the Sunday Times, Evans pushed his tal...\n",
       "197         Then, he took her into a company stockroom whe...\n",
       "224         It's what Newton was on about when he wrote \"H...\n",
       "                                  ...                        \n",
       "19763729    Israeli Prime Minister Benjamin Netanyahu inst...\n",
       "19763750    He expects to be interviewed for the position ...\n",
       "19763779    28 (UPI) -- Scarlett Johansson is the top-gros...\n",
       "19763814    The Seattle Seahawks and Pro Bowl defensive en...\n",
       "19763837    Zadran and his four cousins claimed a small ro...\n",
       "Length: 681491, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_en = en_df[relevant_index]\n",
    "output_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131                \n",
       "178             \n",
       "196              \n",
       "197           \n",
       "224                        \n",
       "                                  ...                        \n",
       "19763729    ...\n",
       "19763750                  Ryan \n",
       "19763779                       2016\n",
       "19763814     Pro BAT  Michae...\n",
       "19763837    12...\n",
       "Length: 681491, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_zh = zh_df[relevant_index]\n",
    "output_zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3950327                                                     \n",
       "14071985                                                    \n",
       "15433006                                                    \n",
       "1959741                                                     \n",
       "1167074                                                     \n",
       "                                  ...                        \n",
       "16590114    20145 Dockerill & ...\n",
       "16274096    20145 Dockerill & ...\n",
       "997379      & mdash ;& mdash ;&& mdas...\n",
       "1778781      Def  Russell Simmons & m...\n",
       "4249432     ( The Oxford Martin Schools of Fo...\n",
       "Length: 681491, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_zh.sort_values(key = lambda x: x.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And rarely do Republicans talk about how they ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might strengthen the case for tweaking eggs...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once at the Sunday Times, Evans pushed his tal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Then, he took her into a company stockroom whe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's what Newton was on about when he wrote \"H...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681486</th>\n",
       "      <td>Israeli Prime Minister Benjamin Netanyahu inst...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681487</th>\n",
       "      <td>He expects to be interviewed for the position ...</td>\n",
       "      <td> Ryan </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681488</th>\n",
       "      <td>28 (UPI) -- Scarlett Johansson is the top-gros...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681489</th>\n",
       "      <td>The Seattle Seahawks and Pro Bowl defensive en...</td>\n",
       "      <td> Pro BAT  Michae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681490</th>\n",
       "      <td>Zadran and his four cousins claimed a small ro...</td>\n",
       "      <td>12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681491 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0  \\\n",
       "0       And rarely do Republicans talk about how they ...   \n",
       "1       It might strengthen the case for tweaking eggs...   \n",
       "2       Once at the Sunday Times, Evans pushed his tal...   \n",
       "3       Then, he took her into a company stockroom whe...   \n",
       "4       It's what Newton was on about when he wrote \"H...   \n",
       "...                                                   ...   \n",
       "681486  Israeli Prime Minister Benjamin Netanyahu inst...   \n",
       "681487  He expects to be interviewed for the position ...   \n",
       "681488  28 (UPI) -- Scarlett Johansson is the top-gros...   \n",
       "681489  The Seattle Seahawks and Pro Bowl defensive en...   \n",
       "681490  Zadran and his four cousins claimed a small ro...   \n",
       "\n",
       "                                                        1  \n",
       "0                \n",
       "1             \n",
       "2              \n",
       "3           \n",
       "4                        \n",
       "...                                                   ...  \n",
       "681486  ...  \n",
       "681487                Ryan   \n",
       "681488                     2016  \n",
       "681489   Pro BAT  Michae...  \n",
       "681490  12...  \n",
       "\n",
       "[681491 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combined\n",
    "combined_df = pd.concat([output_en, output_zh], axis=1).reset_index(drop=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And rarely do Republicans talk about how they ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might strengthen the case for tweaking eggs...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once at the Sunday Times, Evans pushed his tal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Then, he took her into a company stockroom whe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's what Newton was on about when he wrote \"H...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681485</th>\n",
       "      <td>The spokesperson said Akdeniz feels a personal...</td>\n",
       "      <td> Akdeniz </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681486</th>\n",
       "      <td>Israeli Prime Minister Benjamin Netanyahu inst...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681488</th>\n",
       "      <td>28 (UPI) -- Scarlett Johansson is the top-gros...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681489</th>\n",
       "      <td>The Seattle Seahawks and Pro Bowl defensive en...</td>\n",
       "      <td> Pro BAT  Michae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681490</th>\n",
       "      <td>Zadran and his four cousins claimed a small ro...</td>\n",
       "      <td>12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601460 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0  \\\n",
       "0       And rarely do Republicans talk about how they ...   \n",
       "1       It might strengthen the case for tweaking eggs...   \n",
       "2       Once at the Sunday Times, Evans pushed his tal...   \n",
       "3       Then, he took her into a company stockroom whe...   \n",
       "4       It's what Newton was on about when he wrote \"H...   \n",
       "...                                                   ...   \n",
       "681485  The spokesperson said Akdeniz feels a personal...   \n",
       "681486  Israeli Prime Minister Benjamin Netanyahu inst...   \n",
       "681488  28 (UPI) -- Scarlett Johansson is the top-gros...   \n",
       "681489  The Seattle Seahawks and Pro Bowl defensive en...   \n",
       "681490  Zadran and his four cousins claimed a small ro...   \n",
       "\n",
       "                                                        1  \n",
       "0                \n",
       "1             \n",
       "2              \n",
       "3           \n",
       "4                        \n",
       "...                                                   ...  \n",
       "681485           Akdeniz   \n",
       "681486  ...  \n",
       "681488                     2016  \n",
       "681489   Pro BAT  Michae...  \n",
       "681490  12...  \n",
       "\n",
       "[601460 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And rarely do Republicans talk about how they ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might strengthen the case for tweaking eggs...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once at the Sunday Times, Evans pushed his tal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Then, he took her into a company stockroom whe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's what Newton was on about when he wrote \"H...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Facebook, Google, Microsoft, Twitter and Yahoo...</td>\n",
       "      <td>Facebook  Google </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Consumer Reports reviews sleeping aids and rem...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Ten Commandments was one of the biggest TV...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In an interview with the New York Times, Trump...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Banned in Burbank: Uncle Eddy's Big Time Burle...</td>\n",
       "      <td> Burbank  Burleskyun .1940...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  And rarely do Republicans talk about how they ...   \n",
       "1  It might strengthen the case for tweaking eggs...   \n",
       "2  Once at the Sunday Times, Evans pushed his tal...   \n",
       "3  Then, he took her into a company stockroom whe...   \n",
       "4  It's what Newton was on about when he wrote \"H...   \n",
       "5  Facebook, Google, Microsoft, Twitter and Yahoo...   \n",
       "6  Consumer Reports reviews sleeping aids and rem...   \n",
       "7  The Ten Commandments was one of the biggest TV...   \n",
       "8  In an interview with the New York Times, Trump...   \n",
       "9  Banned in Burbank: Uncle Eddy's Big Time Burle...   \n",
       "\n",
       "                                                   1  \n",
       "0           \n",
       "1        \n",
       "2         \n",
       "3      \n",
       "4                   \n",
       "5  Facebook  Google   \n",
       "6                                 \n",
       "7                                 \n",
       "8                 \n",
       "9   Burbank  Burleskyun .1940...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         And rarely do Republicans talk about how they ...\n",
       "1         It might strengthen the case for tweaking eggs...\n",
       "2         Once at the Sunday Times, Evans pushed his tal...\n",
       "3         Then, he took her into a company stockroom whe...\n",
       "4         It's what Newton was on about when he wrote \"H...\n",
       "                                ...                        \n",
       "681485    The spokesperson said Akdeniz feels a personal...\n",
       "681486    Israeli Prime Minister Benjamin Netanyahu inst...\n",
       "681488    28 (UPI) -- Scarlett Johansson is the top-gros...\n",
       "681489    The Seattle Seahawks and Pro Bowl defensive en...\n",
       "681490    Zadran and his four cousins claimed a small ro...\n",
       "Name: 0, Length: 601460, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                \n",
       "1             \n",
       "2              \n",
       "3           \n",
       "4                        \n",
       "                                ...                        \n",
       "681485             Akdeniz \n",
       "681486    ...\n",
       "681488                       2016\n",
       "681489     Pro BAT  Michae...\n",
       "681490    12...\n",
       "Name: 1, Length: 601460, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.iloc[:,1].str.contains(\"Facebook  Google \").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.iloc[:,0].to_csv(r'cc-matrix-enzh-0to30M.en', header=None, index=None, sep='\\n', mode='w')\n",
    "combined_df.iloc[:,1].to_csv(r'cc-matrix-enzh-0to30M.zh', header=None, index=None, sep='\\n', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_number = 300000\n",
    "\n",
    "with open(\"cc-matrix-enzh-0to30M.zh\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-300K.zh\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))\n",
    "with open(\"cc-matrix-enzh-0to30M.en\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-300K.en\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_number = 1000\n",
    "\n",
    "with open(\"cc-matrix-enzh-0to30M.zh\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-1K.zh\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))\n",
    "        \n",
    "with open(\"cc-matrix-enzh-0to30M.en\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-1K.en\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_number = 10\n",
    "\n",
    "with open(\"cc-matrix-enzh-0to30M.zh\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-10.zh\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))\n",
    "        \n",
    "with open(\"cc-matrix-enzh-0to30M.en\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-10.en\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_number = 1\n",
    "\n",
    "with open(\"cc-matrix-enzh-0to30M.zh\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-1.zh\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))\n",
    "with open(\"cc-matrix-enzh-0to30M.en\", encoding='utf-8') as f:\n",
    "    # zh_str = f.read()\n",
    "    head = [f.readline() for _ in range(lines_number)]\n",
    "\n",
    "    with open(\"cc-matrix-enzh-1.en\",\"w\", encoding='utf-8') as f2:\n",
    "        f2.write(\"\".join(head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to the Dataset that the model recognises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And rarely do Republicans talk about how they ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might strengthen the case for tweaking eggs...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once at the Sunday Times, Evans pushed his tal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Then, he took her into a company stockroom whe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's what Newton was on about when he wrote \"H...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  And rarely do Republicans talk about how they ...   \n",
       "1  It might strengthen the case for tweaking eggs...   \n",
       "2  Once at the Sunday Times, Evans pushed his tal...   \n",
       "3  Then, he took her into a company stockroom whe...   \n",
       "4  It's what Newton was on about when he wrote \"H...   \n",
       "\n",
       "                                                zh  \n",
       "0         \n",
       "1      \n",
       "2       \n",
       "3    \n",
       "4                 "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_table(\"cc-matrix-enzh-0to30M.en\",names=[\"en\"]),\n",
    "    pd.read_table(\"cc-matrix-enzh-0to30M.zh\",names=[\"zh\"])\n",
    "    ], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"|||||||||||||||||||||||\"\n",
    "pattern = \"|||||||||||||||||||||\"\n",
    "# pattern = \"||||||||||||||||||||\"\n",
    "\n",
    "filtered_df = df[df.zh.str.contains(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>zh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And rarely do Republicans talk about how they ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might strengthen the case for tweaking eggs...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Once at the Sunday Times, Evans pushed his tal...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Then, he took her into a company stockroom whe...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's what Newton was on about when he wrote \"H...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  And rarely do Republicans talk about how they ...   \n",
       "1  It might strengthen the case for tweaking eggs...   \n",
       "2  Once at the Sunday Times, Evans pushed his tal...   \n",
       "3  Then, he took her into a company stockroom whe...   \n",
       "4  It's what Newton was on about when he wrote \"H...   \n",
       "\n",
       "                                                zh  \n",
       "0         \n",
       "1      \n",
       "2       \n",
       "3    \n",
       "4                 "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary={}\n",
    "dictionary['translate'] = filtered_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translate'],\n",
       "    num_rows: 601460\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_hf_dataset = Dataset.from_dict(dictionary)\n",
    "filtered_hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translate'],\n",
       "        num_rows: 481168\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translate'],\n",
       "        num_rows: 120292\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_hf_dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190326"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translate'],\n",
       "        num_rows: 481168\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translate'],\n",
       "        num_rows: 120292\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': '{\"en\":\"It might strengthen the case for tweaking eggs in other ways, creating \"perfect\" babies made to order by hair or eye colour.\",\"zh\":\"\"}'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['translation'] = df.apply(lambda row: \"{\\\"en\\\":\\\"\"+row['en']+\"\\\",\\\"zh\\\":\\\"\"+row[\"zh\"]+\"\\\"}\",axis=1)\n",
    "# dataset = Dataset.from_pandas(filtered_df).remove_columns(['en', 'zh', '__index_level_0__'])\n",
    "# dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# new_tokens_str = \"|||||||||||||||||||||||\"\n",
    "# new_tokens_str = \"|||||||||||||||||||||\"\n",
    "# def trim_relevant_data(example):\n",
    "#   # print(example)\n",
    "#   if re.search(new_tokens_str, example['translation']['zh']):\n",
    "#     keep=True\n",
    "#   else:\n",
    "#     keep=False\n",
    "#   return keep\n",
    "\n",
    "# filtered_dataset = books.filter(trim_relevant_data)\n",
    "# splitted_data = dataset['train'].train_test_split(test_size=0.2)\n",
    "# splitted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking into the checkpoint issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From OMNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'generator', 'vocab', 'opt'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "omnt_checkpoint = torch.load('nllb-200-600M-onmt.pt', map_location=torch.device('cpu'))\n",
    "omnt_checkpoint.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config='', save_config=None, data={}, skip_empty_level='silent', save_data='', overwrite=False, n_sample=0, dump_transforms=False, src_vocab='', tgt_vocab='', share_vocab=True, src_feats_vocab=None, src_vocab_size=256206, tgt_vocab_size=256206, vocab_size_multiple=1, src_words_min_frequency=1, tgt_words_min_frequency=1, src_seq_length_trunc=None, tgt_seq_length_trunc=None, both_embeddings=None, src_embeddings=None, tgt_embeddings=None, embeddings_type=None, switchout_temperature=1.0, tokendrop_temperature=1.0, tokenmask_temperature=1.0, reversible_tokenization='joiner', prior_tokenization=False, src_subword_model='', tgt_subword_model='', src_subword_nbest=1, tgt_subword_nbest=1, src_subword_alpha=0.0, tgt_subword_alpha=0.0, src_subword_vocab='', tgt_subword_vocab='', src_vocab_threshold=0, tgt_vocab_threshold=0, src_subword_type='none', tgt_subword_type='none', src_onmttok_kwargs=\"{'mode': 'none'}\", tgt_onmttok_kwargs=\"{'mode': 'none'}\", src_seq_length=150, tgt_seq_length=150, src_prefix='', tgt_prefix='', permute_sent_ratio=0.0, rotate_ratio=0.0, insert_ratio=0.0, random_ratio=0.0, mask_ratio=0.0, mask_length='subword', poisson_lambda=3.0, replace_length=-1, src_word_vec_size=1024, tgt_word_vec_size=1024, word_vec_size=1024, share_decoder_embeddings=True, share_embeddings=True, position_encoding=True, position_encoding_type='SinusoidalConcat', update_vocab=False, feat_merge='concat', feat_vec_size=-1, feat_vec_exponent=0.7, model_task='seq2seq', model_type='text', model_dtype='fp16', encoder_type='transformer', decoder_type='transformer', freeze_encoder=False, freeze_decoder=False, layers=-1, enc_layers=12, dec_layers=12, hidden_size=1024, enc_hid_size=1024, dec_hid_size=1024, cnn_kernel_width=3, pos_ffn_activation_fn='relu', input_feed=1, bridge=False, rnn_type='LSTM', context_gate=None, bridge_extra_node=True, bidir_edges=True, state_dim=512, n_edge_types=2, n_node=2, n_steps=2, src_ggnn_size=0, global_attention='general', global_attention_function='softmax', self_attn_type='scaled-dot', max_relative_positions=0, heads=16, transformer_ff=4096, aan_useffn=False, add_qkvbias=True, lambda_align=0.0, alignment_layer=-3, alignment_heads=0, full_context_alignment=False, copy_attn=False, copy_attn_type='general', generator_function='softmax', copy_attn_force=False, reuse_copy_attn=False, copy_loss_by_seqlength=False, coverage_attn=False, lambda_coverage=0.0, lm_prior_model=None, lm_prior_lambda=0.0, lm_prior_tau=1.0, loss_scale=0, apex_opt_level='', data_type='text', save_model='nllb', save_checkpoint_steps=5000, keep_checkpoint=50, gpu_ranks=[0], world_size=1, gpu_backend='nccl', gpu_verbose_level=0, master_ip='localhost', master_port=10000, seed=1234, param_init=0.0, param_init_glorot=True, train_from='', reset_optim='none', pre_word_vecs_enc=None, pre_word_vecs_dec=None, freeze_word_vecs_enc=False, freeze_word_vecs_dec=False, num_workers=4, batch_size=8192, batch_size_multiple=1, batch_type='tokens', normalization='tokens', accum_count=[4], accum_steps=[0], valid_steps=5000, valid_batch_size=4096, train_steps=100000, single_pass=False, early_stopping=0, early_stopping_criteria=None, optim='', adagrad_accumulator_init=0, max_grad_norm=0.0, dropout=[0.1], attention_dropout=[0.1], dropout_steps=[0], truncated_decoder=0, adam_beta1=0.9, adam_beta2=0.98, label_smoothing=0.1, average_decay=0.0, average_every=1, learning_rate=5e-05, learning_rate_decay=0.5, start_decay_steps=50000, decay_steps=10000, decay_method='none', warmup_steps=4000, log_file='', log_file_level='0', verbose=False, train_eval_steps=200, train_metrics=[], valid_metrics=[], scoring_debug=False, dump_preds=None, report_every=100, exp_host='', exp='', tensorboard=False, tensorboard_log_dir='runs/onmt', bucket_size=262144, bucket_size_init=-1, bucket_size_increment=0, prefetch_factor=400, brnn=False, data_task='seq2seq', decoder_start_token='</s>', _all_transform={'filtertoolong'})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omnt_checkpoint['opt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['src', 'tgt', 'data_task', 'decoder_start_token'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omnt_checkpoint['vocab'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<blank>',\n",
       " '</s>',\n",
       " '<unk>',\n",
       " 'an',\n",
       " 'n',\n",
       " 'm',\n",
       " 't',\n",
       " 'k',\n",
       " 'a',\n",
       " 's',\n",
       " 'en',\n",
       " 'in',\n",
       " 'd',\n",
       " 'er',\n",
       " 'la',\n",
       " 'b',\n",
       " 'p',\n",
       " 'on',\n",
       " 'ar',\n",
       " 'at',\n",
       " 'is',\n",
       " 'le',\n",
       " 'e',\n",
       " 'un',\n",
       " 'li',\n",
       " 'o',\n",
       " 'v',\n",
       " 'h',\n",
       " 'c',\n",
       " 'i',\n",
       " 'ak',\n",
       " 'as',\n",
       " 'es',\n",
       " 'am',\n",
       " 'y',\n",
       " 'it',\n",
       " 'or',\n",
       " 'g',\n",
       " 'et',\n",
       " 'w',\n",
       " 'al',\n",
       " 'f',\n",
       " 'AT',\n",
       " 'IN',\n",
       " '<',\n",
       " 'ED',\n",
       " 'ATA',\n",
       " 'MIN',\n",
       " 'DATA',\n",
       " 'MINED',\n",
       " 'r',\n",
       " 'ir',\n",
       " 'ang',\n",
       " 'ti',\n",
       " 'l',\n",
       " 'ad',\n",
       " 'os',\n",
       " 'om',\n",
       " 'ur',\n",
       " 'el',\n",
       " 'j',\n",
       " 'na',\n",
       " 'us',\n",
       " 'em',\n",
       " 'ch',\n",
       " 'ik',\n",
       " 'um',\n",
       " 'ga',\n",
       " '\"',\n",
       " 'A',\n",
       " 'ta',\n",
       " 'M',\n",
       " 'il',\n",
       " '',\n",
       " 'im',\n",
       " 'ed',\n",
       " 'ek',\n",
       " 'u',\n",
       " 'de',\n",
       " 'wa',\n",
       " '.',\n",
       " 'la',\n",
       " 'S',\n",
       " 'N',\n",
       " 'id',\n",
       " 'te',\n",
       " 'ing',\n",
       " 'ay',\n",
       " '-',\n",
       " 'ku',\n",
       " 'ok',\n",
       " 'ra',\n",
       " 'ol',\n",
       " '1',\n",
       " '',\n",
       " 'le',\n",
       " 'ia',\n",
       " 'K',\n",
       " 'ka',\n",
       " 'z',\n",
       " 'uk',\n",
       " 'ha',\n",
       " 'ba',\n",
       " '(',\n",
       " 'ut',\n",
       " '',\n",
       " 'da',\n",
       " 'in',\n",
       " 'T',\n",
       " 'he',\n",
       " 'an',\n",
       " 'ma',\n",
       " '',\n",
       " 'B',\n",
       " 'ya',\n",
       " 'ie',\n",
       " 'I',\n",
       " 'ul',\n",
       " 're',\n",
       " '',\n",
       " 'P',\n",
       " 'D',\n",
       " '',\n",
       " 'ot',\n",
       " 'ana',\n",
       " 'E',\n",
       " 'sa',\n",
       " '',\n",
       " 'od',\n",
       " 'se',\n",
       " 'pr',\n",
       " '',\n",
       " 'ta',\n",
       " '',\n",
       " 'q',\n",
       " '',\n",
       " '',\n",
       " 'ent',\n",
       " 'ov',\n",
       " '2',\n",
       " '',\n",
       " '',\n",
       " 'hi',\n",
       " '',\n",
       " 'di',\n",
       " ',',\n",
       " 'ag',\n",
       " 'st',\n",
       " 'ci',\n",
       " 'di',\n",
       " 'ap',\n",
       " 'C',\n",
       " 'en',\n",
       " '',\n",
       " 'L',\n",
       " 'J',\n",
       " 'de',\n",
       " 'ni',\n",
       " 'un',\n",
       " 'ya',\n",
       " 'ba',\n",
       " 'ka',\n",
       " 'ng',\n",
       " '',\n",
       " '',\n",
       " 'H',\n",
       " 'ne',\n",
       " '',\n",
       " 'na',\n",
       " 'da',\n",
       " 'si',\n",
       " 'te',\n",
       " 'ho',\n",
       " 'ri',\n",
       " 'ng',\n",
       " 'ong',\n",
       " 'li',\n",
       " '',\n",
       " '',\n",
       " 'eng',\n",
       " 'bi',\n",
       " 'og',\n",
       " 'we',\n",
       " 'ma',\n",
       " 'aka',\n",
       " 'tu',\n",
       " 'ye',\n",
       " 'ara',\n",
       " '..',\n",
       " 'and',\n",
       " '',\n",
       " '{{',\n",
       " 'O',\n",
       " '',\n",
       " '',\n",
       " 'qu',\n",
       " 'ja',\n",
       " 'Y',\n",
       " 'ig',\n",
       " 'wa',\n",
       " 'se',\n",
       " 'to',\n",
       " 'ku',\n",
       " 'za',\n",
       " '',\n",
       " 'ti',\n",
       " 'zi',\n",
       " 'to',\n",
       " 'sa',\n",
       " 'eg',\n",
       " '{{',\n",
       " 'G',\n",
       " '',\n",
       " '\".',\n",
       " '',\n",
       " 'mu',\n",
       " '',\n",
       " '',\n",
       " 'si',\n",
       " 'op',\n",
       " '',\n",
       " 'be',\n",
       " 'ung',\n",
       " '',\n",
       " 'ou',\n",
       " 'va',\n",
       " '',\n",
       " 'ch',\n",
       " '',\n",
       " 'at',\n",
       " 'ina',\n",
       " '',\n",
       " 'th',\n",
       " '',\n",
       " 'al',\n",
       " '',\n",
       " '',\n",
       " \"'\",\n",
       " 'me',\n",
       " 'ni',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ati',\n",
       " 'ha',\n",
       " 'W',\n",
       " 'ud',\n",
       " 'is',\n",
       " 'ke',\n",
       " 'R',\n",
       " '',\n",
       " 'yo',\n",
       " 'ua',\n",
       " 'no',\n",
       " '',\n",
       " 'je',\n",
       " '',\n",
       " 'ata',\n",
       " 'am',\n",
       " 'V',\n",
       " 'U',\n",
       " 'ko',\n",
       " '',\n",
       " 'ke',\n",
       " '',\n",
       " '',\n",
       " 'ob',\n",
       " 'ter',\n",
       " '',\n",
       " 'ani',\n",
       " 'ce',\n",
       " 're',\n",
       " 'pa',\n",
       " 'ne',\n",
       " 'ere',\n",
       " 'bu',\n",
       " 'F',\n",
       " 'pe',\n",
       " 've',\n",
       " 'be',\n",
       " 'on',\n",
       " '',\n",
       " 'ar',\n",
       " '...',\n",
       " 'ak',\n",
       " '',\n",
       " 'va',\n",
       " '',\n",
       " 'ari',\n",
       " 'ist',\n",
       " 'lar',\n",
       " 'ama',\n",
       " '',\n",
       " 'ini',\n",
       " 'nga',\n",
       " 'tr',\n",
       " '',\n",
       " 'bo',\n",
       " '',\n",
       " 'hu',\n",
       " '',\n",
       " 'ant',\n",
       " 'je',\n",
       " 'ona',\n",
       " '',\n",
       " 'era',\n",
       " 'ki',\n",
       " 'pa',\n",
       " '',\n",
       " '20',\n",
       " 'per',\n",
       " 'ro',\n",
       " '',\n",
       " 'ca',\n",
       " '3',\n",
       " 'mo',\n",
       " 'mi',\n",
       " 'ny',\n",
       " 'ika',\n",
       " 'ji',\n",
       " 'ada',\n",
       " '',\n",
       " 'end',\n",
       " 'so',\n",
       " '',\n",
       " '',\n",
       " 'su',\n",
       " '',\n",
       " '',\n",
       " 'bi',\n",
       " '',\n",
       " '',\n",
       " 'isa',\n",
       " 'tu',\n",
       " 'es',\n",
       " 'el',\n",
       " 'ki',\n",
       " 'me',\n",
       " '',\n",
       " 'que',\n",
       " 'wo',\n",
       " 'er',\n",
       " '',\n",
       " 'st',\n",
       " 'ita',\n",
       " 'lo',\n",
       " 'wi',\n",
       " 'ug',\n",
       " 'the',\n",
       " '',\n",
       " 'for',\n",
       " '',\n",
       " 'ko',\n",
       " 'est',\n",
       " '',\n",
       " 'vi',\n",
       " '',\n",
       " '',\n",
       " 'do',\n",
       " 'ene',\n",
       " '',\n",
       " 'ga',\n",
       " 'con',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ye',\n",
       " '',\n",
       " 'ny',\n",
       " 'ane',\n",
       " '',\n",
       " 'ze',\n",
       " 'fa',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ira',\n",
       " 'vo',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'vi',\n",
       " '',\n",
       " 'up',\n",
       " '?',\n",
       " '',\n",
       " '',\n",
       " 'as',\n",
       " 'uma',\n",
       " 'po',\n",
       " '',\n",
       " 'ine',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'x',\n",
       " '',\n",
       " 'kan',\n",
       " 'ena',\n",
       " 'nd',\n",
       " '',\n",
       " 'bo',\n",
       " 'ic',\n",
       " 'go',\n",
       " 'ver',\n",
       " 'eh',\n",
       " '',\n",
       " 'ra',\n",
       " 'et',\n",
       " 'og',\n",
       " '',\n",
       " 'par',\n",
       " 'ho',\n",
       " 'asi',\n",
       " 'asa',\n",
       " '',\n",
       " '',\n",
       " 'th',\n",
       " '',\n",
       " 'ib',\n",
       " '',\n",
       " 'ja',\n",
       " 'qu',\n",
       " '',\n",
       " 'isi',\n",
       " 'so',\n",
       " 'any',\n",
       " 'ova',\n",
       " 'eni',\n",
       " 'ol',\n",
       " 'ele',\n",
       " '',\n",
       " 'ind',\n",
       " 'hi',\n",
       " '4',\n",
       " 'lo',\n",
       " '',\n",
       " 'men',\n",
       " 've',\n",
       " '19',\n",
       " 'oni',\n",
       " 'gi',\n",
       " '',\n",
       " 'lam',\n",
       " 'pr',\n",
       " '',\n",
       " 'za',\n",
       " 'po',\n",
       " 'com',\n",
       " '',\n",
       " 'of',\n",
       " '',\n",
       " '',\n",
       " 'ag',\n",
       " 'im',\n",
       " '',\n",
       " 'iri',\n",
       " 'olo',\n",
       " '00',\n",
       " '',\n",
       " 'du',\n",
       " 'are',\n",
       " 'no',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ts',\n",
       " 'han',\n",
       " 'iti',\n",
       " '',\n",
       " 'eri',\n",
       " '',\n",
       " 'lu',\n",
       " '',\n",
       " 'ab',\n",
       " 'ang',\n",
       " 'ore',\n",
       " 'ge',\n",
       " 'tr',\n",
       " '5',\n",
       " 'pi',\n",
       " '',\n",
       " 'dan',\n",
       " '',\n",
       " 'yi',\n",
       " '',\n",
       " 'ju',\n",
       " '',\n",
       " 'nd',\n",
       " '',\n",
       " 'man',\n",
       " 'ula',\n",
       " '',\n",
       " 'kan',\n",
       " 'iz',\n",
       " '',\n",
       " 'fa',\n",
       " 'una',\n",
       " 'adi',\n",
       " '',\n",
       " 'ate',\n",
       " '',\n",
       " '',\n",
       " 'um',\n",
       " 'aya',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'yang',\n",
       " 'ab',\n",
       " 'und',\n",
       " 'eb',\n",
       " 'ela',\n",
       " 'mi',\n",
       " '',\n",
       " 'ub',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Ma',\n",
       " 'Z',\n",
       " 'anga',\n",
       " 'sh',\n",
       " 'ond',\n",
       " 'ir',\n",
       " '',\n",
       " '',\n",
       " 'min',\n",
       " '',\n",
       " 'yo',\n",
       " 'ad',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ap',\n",
       " '..',\n",
       " 'and',\n",
       " 'one',\n",
       " 'til',\n",
       " 'om',\n",
       " 'An',\n",
       " ':1',\n",
       " '',\n",
       " 'eka',\n",
       " 'bu',\n",
       " '',\n",
       " 'ver',\n",
       " 'iz',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sam',\n",
       " '',\n",
       " 'lah',\n",
       " 'alo',\n",
       " 'kw',\n",
       " 'ru',\n",
       " '',\n",
       " 'go',\n",
       " 'il',\n",
       " '',\n",
       " '',\n",
       " 'die',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ri',\n",
       " '',\n",
       " 'fi',\n",
       " 'ake',\n",
       " 'em',\n",
       " 'he',\n",
       " '',\n",
       " '',\n",
       " 'van',\n",
       " 'ura',\n",
       " 'kon',\n",
       " '',\n",
       " '',\n",
       " 'ako',\n",
       " 'uka',\n",
       " 'ens',\n",
       " 'ost',\n",
       " '',\n",
       " '',\n",
       " 'oko',\n",
       " '',\n",
       " 'les',\n",
       " '',\n",
       " 'uri',\n",
       " '',\n",
       " 'lik',\n",
       " '',\n",
       " 'del',\n",
       " 'ann',\n",
       " 'ite',\n",
       " '',\n",
       " 'mat',\n",
       " 'ulu',\n",
       " 'ber',\n",
       " 'Na',\n",
       " 'av',\n",
       " 'les',\n",
       " 'kom',\n",
       " 'ano',\n",
       " 'ami',\n",
       " 'hat',\n",
       " 'n',\n",
       " 'lem',\n",
       " 'est',\n",
       " 'pas',\n",
       " '',\n",
       " 'ler',\n",
       " '6',\n",
       " 'or',\n",
       " 'ter',\n",
       " 'ik',\n",
       " 'ans',\n",
       " '...',\n",
       " 'af',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'yn',\n",
       " 'pe',\n",
       " 'co',\n",
       " '',\n",
       " 't',\n",
       " 'vo',\n",
       " 'ire',\n",
       " '',\n",
       " '',\n",
       " 'op',\n",
       " '',\n",
       " 'jo',\n",
       " 'for',\n",
       " 'aku',\n",
       " '',\n",
       " 'ala',\n",
       " '',\n",
       " 'r',\n",
       " 'ai',\n",
       " '',\n",
       " 'ui',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'den',\n",
       " 'med',\n",
       " 'ima',\n",
       " '',\n",
       " 'ete',\n",
       " '',\n",
       " '',\n",
       " 'gi',\n",
       " 'we',\n",
       " '',\n",
       " '',\n",
       " 'wan',\n",
       " 'ess',\n",
       " 'ge',\n",
       " '',\n",
       " ').',\n",
       " 'aki',\n",
       " 'ora',\n",
       " '',\n",
       " 'ber',\n",
       " 'Al',\n",
       " '',\n",
       " '',\n",
       " 'pro',\n",
       " 'mar',\n",
       " '',\n",
       " '',\n",
       " 'som',\n",
       " '',\n",
       " 'ish',\n",
       " 'r',\n",
       " 'det',\n",
       " 'n',\n",
       " '201',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'bil',\n",
       " 'ex',\n",
       " '',\n",
       " 'all',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ten',\n",
       " '',\n",
       " '\",',\n",
       " 'yd',\n",
       " 'des',\n",
       " '',\n",
       " '',\n",
       " 'ys',\n",
       " 'elo',\n",
       " '',\n",
       " 'zo',\n",
       " '[',\n",
       " 's',\n",
       " 'amb',\n",
       " '',\n",
       " 'nu',\n",
       " 'sp',\n",
       " 'sk',\n",
       " 'ente',\n",
       " 'In',\n",
       " '',\n",
       " 'mo',\n",
       " 'ord',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'n',\n",
       " 'atu',\n",
       " '',\n",
       " 'har',\n",
       " 'ell',\n",
       " '',\n",
       " 'ato',\n",
       " '',\n",
       " 'mak',\n",
       " '',\n",
       " 'itu',\n",
       " '',\n",
       " '',\n",
       " 'ck',\n",
       " '',\n",
       " 'ali',\n",
       " '',\n",
       " 'esu',\n",
       " 'ek',\n",
       " 'nh',\n",
       " 'ust',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sh',\n",
       " 'inn',\n",
       " '',\n",
       " 'n',\n",
       " 'int',\n",
       " '',\n",
       " 'ehova',\n",
       " 'ip',\n",
       " 'mas',\n",
       " '7',\n",
       " 'gu',\n",
       " 'eke',\n",
       " 'der',\n",
       " 'ay',\n",
       " 'ac',\n",
       " '',\n",
       " 'lan',\n",
       " '',\n",
       " 'ith',\n",
       " 'oku',\n",
       " '',\n",
       " '',\n",
       " 'ort',\n",
       " 'ca',\n",
       " '10',\n",
       " 'usa',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ise',\n",
       " 'eta',\n",
       " '',\n",
       " 'pi',\n",
       " 'kun',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ue',\n",
       " 'ino',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ach',\n",
       " 'it',\n",
       " '',\n",
       " 'ast',\n",
       " '8',\n",
       " '',\n",
       " 'tal',\n",
       " '',\n",
       " 'ons',\n",
       " '',\n",
       " 'lig',\n",
       " 'ila',\n",
       " 'nan',\n",
       " 'man',\n",
       " 'pan',\n",
       " '',\n",
       " 'by',\n",
       " 'ph',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'uh',\n",
       " 'ris',\n",
       " 'ran',\n",
       " 'per',\n",
       " '',\n",
       " '',\n",
       " 'ida',\n",
       " '',\n",
       " '',\n",
       " 'aw',\n",
       " 'las',\n",
       " 'ori',\n",
       " 'mem',\n",
       " 'oku',\n",
       " '!',\n",
       " 'uk',\n",
       " 'ade',\n",
       " 'od',\n",
       " '',\n",
       " '',\n",
       " 'oma',\n",
       " 'ile',\n",
       " 'zu',\n",
       " 'iv',\n",
       " 'art',\n",
       " 'ban',\n",
       " '',\n",
       " 'ende',\n",
       " 'ill',\n",
       " 'ji',\n",
       " '',\n",
       " 'Ch',\n",
       " '',\n",
       " 'che',\n",
       " '9',\n",
       " 'n',\n",
       " '',\n",
       " '',\n",
       " 'ob',\n",
       " 'kwa',\n",
       " '',\n",
       " 'tt',\n",
       " 'ts',\n",
       " 'imo',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'mga',\n",
       " '',\n",
       " 'kh',\n",
       " '',\n",
       " 'lu',\n",
       " '',\n",
       " 'gan',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'sk',\n",
       " '',\n",
       " '',\n",
       " '200',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ning',\n",
       " 'dis',\n",
       " '',\n",
       " 'ero',\n",
       " 'r',\n",
       " 'wu',\n",
       " '',\n",
       " '',\n",
       " 'cha',\n",
       " 'amp',\n",
       " 'n',\n",
       " 'wo',\n",
       " 'ser',\n",
       " 'ct',\n",
       " 'cu',\n",
       " 'ito',\n",
       " 'iko',\n",
       " 'ure',\n",
       " '',\n",
       " '',\n",
       " 'lit',\n",
       " 'Ne',\n",
       " '',\n",
       " 'ok',\n",
       " 'bir',\n",
       " 'ai',\n",
       " '',\n",
       " 'fi',\n",
       " 'ci',\n",
       " 'pag',\n",
       " '',\n",
       " 'az',\n",
       " 'du',\n",
       " '',\n",
       " 'co',\n",
       " 'fe',\n",
       " 'ly',\n",
       " 'kar',\n",
       " 'oka',\n",
       " '',\n",
       " 'ont',\n",
       " '',\n",
       " 'che',\n",
       " '',\n",
       " 'kas',\n",
       " '',\n",
       " 'nh',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'var',\n",
       " 'fu',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'iki',\n",
       " 'lim',\n",
       " 'der',\n",
       " 'Is',\n",
       " 'pre',\n",
       " '',\n",
       " 'yi',\n",
       " '',\n",
       " '',\n",
       " 'por',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'let',\n",
       " 'ah',\n",
       " 'ndi',\n",
       " '',\n",
       " '',\n",
       " 'Q',\n",
       " '',\n",
       " 'sem',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'het',\n",
       " 'ah',\n",
       " 'Se',\n",
       " 's',\n",
       " 'amo',\n",
       " 'os',\n",
       " '',\n",
       " 'Sa',\n",
       " 'chi',\n",
       " '',\n",
       " 'ose',\n",
       " 'oto',\n",
       " 'inga',\n",
       " '',\n",
       " '',\n",
       " 'vu',\n",
       " '',\n",
       " 'us',\n",
       " '',\n",
       " '',\n",
       " 'De',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'esi',\n",
       " '',\n",
       " ...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(omnt_checkpoint['vocab']['tgt']))\n",
    "omnt_checkpoint['vocab']['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder.embeddings.make_embedding.emb_luts.0.weight': tensor([[-0.0321,  0.0348,  0.0181,  ...,  0.0312, -0.0099, -0.0133],\n",
       "         [-0.0039,  0.0104, -0.0156,  ...,  0.0290, -0.0138, -0.0134],\n",
       "         [-0.0245, -0.0283, -0.0295,  ...,  0.9712, -0.0255, -0.0273],\n",
       "         ...,\n",
       "         [-0.0123, -0.0031, -0.0089,  ...,  0.0645, -0.0182, -0.0740],\n",
       "         [ 0.0085, -0.0088, -0.0091,  ...,  0.0571, -0.0035, -0.1298],\n",
       "         [-0.0076, -0.0107, -0.0051,  ...,  1.0264, -0.0338, -0.1175]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.embeddings.make_embedding.pe.pe': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.8415,  0.8317,  0.8218,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.9093,  0.9236,  0.9365,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.9563,  0.5417,  0.7653,  ...,  0.8688,  0.8733,  0.8777]],\n",
       " \n",
       "         [[ 0.2705,  0.9999,  0.9649,  ...,  0.8687,  0.8733,  0.8777]],\n",
       " \n",
       "         [[-0.6639,  0.5685,  0.3343,  ...,  0.8687,  0.8732,  0.8776]]]),\n",
       " 'encoder.transformer.0.self_attn.linear_keys.weight': tensor([[ 5.9570e-01,  6.5479e-01,  5.9863e-01,  ...,  1.2024e-01,\n",
       "          -1.4905e-01, -1.1023e-01],\n",
       "         [ 3.1909e-01, -1.8079e-01, -2.6294e-01,  ..., -2.0264e-01,\n",
       "           1.9861e-01,  4.2529e-01],\n",
       "         [ 5.2148e-01,  8.4229e-01,  9.9951e-01,  ...,  2.0679e-01,\n",
       "           2.0203e-01, -5.2261e-03],\n",
       "         ...,\n",
       "         [ 1.3794e-01, -1.1102e-01, -5.5176e-01,  ..., -3.5400e-03,\n",
       "           4.2267e-02, -3.9399e-05],\n",
       "         [-1.5588e-01,  6.3293e-02,  1.2901e-02,  ..., -3.8452e-01,\n",
       "           1.5308e-01,  2.8540e-01],\n",
       "         [-2.2595e-01, -9.3994e-02,  3.0981e-01,  ..., -1.6748e-01,\n",
       "          -7.5378e-02, -1.4185e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_keys.bias': tensor([ 0.0179,  0.0283,  0.0196,  ..., -0.0025, -0.0250,  0.0193],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_values.weight': tensor([[ 0.0630,  0.0343, -0.0231,  ..., -0.0668, -0.1157, -0.0081],\n",
       "         [ 0.0947,  0.0685,  0.0461,  ..., -0.0442, -0.1248, -0.0464],\n",
       "         [ 0.0397,  0.0829,  0.0338,  ...,  0.0314, -0.0782, -0.1476],\n",
       "         ...,\n",
       "         [-0.2808, -0.0279,  0.0878,  ...,  0.0007, -0.0660, -0.0214],\n",
       "         [ 0.0296,  0.0190, -0.0400,  ...,  0.0379, -0.0027, -0.2717],\n",
       "         [-0.0427, -0.0203, -0.0764,  ...,  0.0536, -0.0583,  0.1981]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_values.bias': tensor([-0.0758, -0.1368, -0.0085,  ..., -0.0319,  0.0159, -0.0054],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_query.weight': tensor([[ 0.1394, -0.0477, -0.5269,  ..., -0.0635,  0.2659,  0.1715],\n",
       "         [-0.2218, -0.3704, -0.5278,  ..., -0.2737, -0.0536, -0.3032],\n",
       "         [ 1.0117,  1.0215,  0.9995,  ..., -0.0361, -0.1837,  0.1039],\n",
       "         ...,\n",
       "         [-0.1182, -0.1311, -0.4141,  ...,  0.3547, -0.1899,  0.1781],\n",
       "         [-0.1536,  0.0272,  0.0038,  ...,  0.2732, -0.1216,  0.3218],\n",
       "         [-0.2279, -0.1813,  0.2534,  ...,  0.2791, -0.2869, -0.0817]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.linear_query.bias': tensor([ 0.0445, -0.6504,  0.0458,  ..., -0.0200, -0.2649, -0.0813],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.final_linear.weight': tensor([[-0.0432, -0.1025, -0.0201,  ...,  0.0115, -0.0321, -0.1892],\n",
       "         [-0.0038, -0.0169, -0.0073,  ...,  0.0214,  0.0050,  0.0173],\n",
       "         [ 0.0013, -0.0362,  0.0130,  ..., -0.0028, -0.0018,  0.0048],\n",
       "         ...,\n",
       "         [-0.0644,  0.3677,  0.1345,  ...,  0.2361, -0.3904,  0.1660],\n",
       "         [ 0.0199, -0.1136, -0.2612,  ..., -0.1603,  0.0699, -0.0349],\n",
       "         [-0.1918, -0.1236, -0.0550,  ...,  0.0294,  0.1755,  0.0011]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.self_attn.final_linear.bias': tensor([-1.2274e-01, -5.3802e-02, -8.2552e-05,  ..., -1.1182e-01,\n",
       "          1.1978e-02, -4.8340e-02], dtype=torch.float16),\n",
       " 'encoder.transformer.0.layer_norm.weight': tensor([0.1989, 0.7793, 1.0020,  ..., 0.0681, 0.1104, 0.1191],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.layer_norm.bias': tensor([ 0.0027,  0.0109,  0.0106,  ..., -0.0605,  0.0066,  0.0079],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_1.weight': tensor([[-0.0822, -0.0664, -0.0421,  ..., -0.2252, -0.0174, -0.0901],\n",
       "         [-0.2766,  0.0712, -0.0408,  ...,  0.0138,  0.1761,  0.0470],\n",
       "         [-0.0440,  0.0100, -0.1147,  ...,  0.3438, -0.1202, -0.3132],\n",
       "         ...,\n",
       "         [-0.0398, -0.0275, -0.0571,  ..., -0.1705, -0.0421,  0.1415],\n",
       "         [-0.0609, -0.7812, -1.0000,  ..., -0.1626,  0.0497,  0.0238],\n",
       "         [ 0.0217, -0.0949,  0.0983,  ...,  0.0842,  0.1940, -0.0874]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_1.bias': tensor([-0.3264, -0.1189, -0.1158,  ..., -0.1076, -0.3582,  0.1184],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_2.weight': tensor([[ 5.4474e-02, -3.5706e-02,  7.3608e-02,  ..., -6.0089e-02,\n",
       "          -4.7217e-01,  1.3208e-01],\n",
       "         [ 1.6308e-04,  2.6016e-02, -9.5901e-03,  ..., -2.8137e-02,\n",
       "          -1.6527e-03, -2.5024e-02],\n",
       "         [-5.9280e-03,  3.3844e-02, -2.1988e-02,  ...,  1.0384e-02,\n",
       "          -3.5498e-01,  1.5053e-02],\n",
       "         ...,\n",
       "         [-3.8116e-02, -2.1011e-02,  9.9854e-02,  ..., -1.0352e-01,\n",
       "           7.6103e-04, -2.3364e-01],\n",
       "         [ 2.1960e-01,  2.2803e-01, -4.5837e-02,  ..., -3.4943e-02,\n",
       "          -1.2585e-01,  8.1848e-02],\n",
       "         [-8.0322e-02, -2.6505e-02, -3.4448e-01,  ..., -8.9417e-02,\n",
       "          -2.1942e-02, -1.9287e-02]], dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.w_2.bias': tensor([-0.0136, -0.3655,  0.3784,  ..., -0.4990, -0.1392, -0.7456],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.layer_norm.weight': tensor([0.3259, 1.1016, 1.6602,  ..., 0.3540, 0.1896, 0.2242],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.0.feed_forward.layer_norm.bias': tensor([ 0.0026, -0.0082, -0.0087,  ...,  0.1504,  0.0718,  0.1245],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_keys.weight': tensor([[ 0.3132,  0.0303,  0.0594,  ..., -0.1047,  0.2419, -0.0555],\n",
       "         [-0.0422,  0.0921,  0.0128,  ..., -0.0507,  0.2769,  0.0223],\n",
       "         [ 0.4136,  0.1260, -0.0191,  ...,  0.1329, -0.0108, -0.2230],\n",
       "         ...,\n",
       "         [-0.1825,  0.0161, -0.1770,  ..., -0.0454,  0.0595, -0.0764],\n",
       "         [-0.0319, -0.1340,  0.1174,  ...,  0.0326,  0.0575, -0.1683],\n",
       "         [-0.1371, -0.0249,  0.2296,  ..., -0.0196,  0.2529,  0.0146]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_keys.bias': tensor([ 0.0179,  0.0086, -0.0042,  ..., -0.0084, -0.0040, -0.0065],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_values.weight': tensor([[-0.0923, -0.0101, -0.0208,  ..., -0.2000,  0.0222,  0.2756],\n",
       "         [ 0.0516, -0.0055,  0.0196,  ...,  0.0775,  0.0753,  0.2461],\n",
       "         [-0.0670, -0.0357, -0.0576,  ...,  0.0538, -0.1516, -0.2198],\n",
       "         ...,\n",
       "         [-0.3870,  0.1213, -0.1592,  ...,  0.2500,  0.0792, -0.0464],\n",
       "         [ 0.0688,  0.0403,  0.0655,  ...,  0.2209,  0.2373,  0.0286],\n",
       "         [-0.0528, -0.0808,  0.0141,  ...,  0.0310,  0.0302,  0.0488]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_values.bias': tensor([ 0.0793, -0.0319,  0.0125,  ...,  0.0307, -0.0509, -0.0137],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_query.weight': tensor([[ 0.2812,  0.1462,  0.0362,  ..., -0.0667,  0.0091,  0.1052],\n",
       "         [-0.1653,  0.0444, -0.0217,  ..., -0.1318, -0.0861, -0.2842],\n",
       "         [ 0.2281, -0.0016,  0.1289,  ...,  0.1704, -0.0197,  0.5918],\n",
       "         ...,\n",
       "         [-0.2090,  0.0235, -0.0010,  ..., -0.0251, -0.0866,  0.5020],\n",
       "         [-0.0695,  0.1296, -0.1885,  ..., -0.3889, -0.0210,  0.4143],\n",
       "         [ 0.3230, -0.0293, -0.0364,  ..., -0.0184,  0.3271,  0.4307]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.linear_query.bias': tensor([ 0.1562, -0.1987,  0.2474,  ..., -0.0505, -0.3267,  0.2563],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.final_linear.weight': tensor([[-0.1606,  0.1558, -0.1584,  ..., -0.0085,  0.0523, -0.3730],\n",
       "         [-0.0123,  0.0967,  0.0272,  ...,  0.0414,  0.1367,  0.1249],\n",
       "         [ 0.0454, -0.0834, -0.0182,  ...,  0.0917, -0.2466,  0.0072],\n",
       "         ...,\n",
       "         [-0.1824, -0.0740,  0.1194,  ...,  0.0551, -0.1820, -0.1041],\n",
       "         [ 0.2206, -0.1924,  0.2886,  ..., -0.0296, -0.3135, -0.0388],\n",
       "         [ 0.0279,  0.1779, -0.1296,  ..., -0.4524,  0.0889, -0.1515]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.self_attn.final_linear.bias': tensor([-0.5601, -0.4797,  0.5430,  ..., -0.7354, -0.2346, -0.3242],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.layer_norm.weight': tensor([0.2800, 0.6963, 1.0000,  ..., 0.1310, 0.1289, 0.0534],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.layer_norm.bias': tensor([-0.0067, -0.0167,  0.0038,  ..., -0.0364,  0.0032,  0.0068],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_1.weight': tensor([[ 0.0288,  0.0228, -0.0608,  ..., -0.0198, -0.1741,  0.0707],\n",
       "         [ 0.1438,  0.0527,  0.0828,  ..., -0.2949, -0.1907, -0.1910],\n",
       "         [ 0.0360,  0.2744,  0.0928,  ..., -0.1534,  0.1022, -0.0169],\n",
       "         ...,\n",
       "         [ 0.1482,  0.1733, -0.1611,  ..., -0.0764,  0.1055, -0.1361],\n",
       "         [ 0.2598,  0.2203,  0.1808,  ..., -0.0300,  0.2542,  0.1102],\n",
       "         [ 0.2976,  0.0646,  0.2065,  ..., -0.0663, -0.1564, -0.0345]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_1.bias': tensor([-0.0112, -0.2332, -0.1604,  ..., -0.1494, -0.0759, -0.0137],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_2.weight': tensor([[ 0.0429,  0.0976,  0.2073,  ..., -0.2070,  0.0483, -0.0598],\n",
       "         [ 0.0475,  0.0685, -0.1361,  ..., -0.0488,  0.0395,  0.2761],\n",
       "         [-0.0568, -0.0254,  0.1608,  ...,  0.1666,  0.0410,  0.0114],\n",
       "         ...,\n",
       "         [ 0.1724,  0.2063,  0.0209,  ...,  0.3467,  0.2316,  0.0891],\n",
       "         [ 0.1193,  0.0363, -0.2162,  ..., -0.0956,  0.0388,  0.0544],\n",
       "         [-0.1222,  0.2642, -0.2076,  ..., -0.0162, -0.0597, -0.1100]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.w_2.bias': tensor([-0.4980, -0.6235,  0.3506,  ..., -0.8696,  0.0837,  0.0706],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.layer_norm.weight': tensor([0.3640, 0.5825, 0.7876,  ..., 0.3674, 0.2639, 0.7192],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.1.feed_forward.layer_norm.bias': tensor([-0.0160, -0.1505,  0.0006,  ...,  0.2961,  0.1514,  0.3875],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_keys.weight': tensor([[-0.3447, -0.4392, -0.2729,  ...,  0.1851,  0.1113, -0.1281],\n",
       "         [-0.5283, -0.3757, -0.2126,  ...,  0.0692, -0.0856,  0.1705],\n",
       "         [ 0.0643, -0.1009,  0.0264,  ..., -0.1879, -0.1941, -0.0309],\n",
       "         ...,\n",
       "         [ 0.1146, -0.1388,  0.0802,  ...,  0.0249, -0.2125, -0.0556],\n",
       "         [ 0.0025,  0.0030,  0.4084,  ...,  0.2128,  0.1897,  0.1888],\n",
       "         [-0.2020, -0.0406, -0.2024,  ...,  0.0584,  0.1917,  0.2167]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_keys.bias': tensor([-0.0259, -0.0300,  0.0098,  ...,  0.0023,  0.0161, -0.0312],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_values.weight': tensor([[ 0.0021,  0.0291,  0.2048,  ...,  0.3103, -0.0507, -0.1099],\n",
       "         [ 0.0806,  0.0523, -0.0200,  ...,  0.1108, -0.0761,  0.0262],\n",
       "         [-0.0192,  0.1956,  0.0440,  ..., -0.2407, -0.1000, -0.0016],\n",
       "         ...,\n",
       "         [ 0.0179,  0.0394, -0.0177,  ...,  0.1243,  0.0283,  0.0198],\n",
       "         [ 0.0754, -0.0627, -0.0371,  ...,  0.2119, -0.3503,  0.0305],\n",
       "         [ 0.1018,  0.2954,  0.0267,  ...,  0.0017,  0.0053, -0.0506]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_values.bias': tensor([ 0.1757, -0.1736,  0.0048,  ...,  0.0027, -0.0123,  0.0012],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_query.weight': tensor([[-0.2394, -0.2335, -0.0950,  ...,  0.1547,  0.1436,  0.1914],\n",
       "         [-0.0340, -0.1176, -0.3926,  ...,  0.1010, -0.0010, -0.0776],\n",
       "         [ 0.1042, -0.2820,  0.0054,  ..., -0.1914,  0.0817,  0.1759],\n",
       "         ...,\n",
       "         [-0.0563, -0.0400,  0.0502,  ..., -0.0404,  0.2847,  0.0385],\n",
       "         [ 0.1459, -0.0163,  0.0189,  ...,  0.0794,  0.2352,  0.1910],\n",
       "         [ 0.1403,  0.0652,  0.1050,  ..., -0.0582, -0.0510, -0.1772]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.linear_query.bias': tensor([-0.1339,  0.7612,  0.0226,  ...,  0.0240,  0.1281,  0.1191],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.final_linear.weight': tensor([[ 0.3418, -0.0677,  0.2137,  ...,  0.0499,  0.2649,  0.1776],\n",
       "         [-0.3020, -0.0951,  0.0147,  ...,  0.0165,  0.0594,  0.0526],\n",
       "         [-0.2974,  0.2010,  0.0136,  ...,  0.1761,  0.2007, -0.0710],\n",
       "         ...,\n",
       "         [ 0.0853,  0.2075,  0.0961,  ..., -0.2235, -0.2292,  0.0688],\n",
       "         [-0.0068, -0.0393, -0.1675,  ..., -0.1058, -0.2266, -0.1720],\n",
       "         [ 0.2888,  0.1907,  0.2939,  ...,  0.1801,  0.4055,  0.1396]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.self_attn.final_linear.bias': tensor([-0.3291,  0.1842, -0.0803,  ..., -0.4951, -0.2440, -0.1320],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.layer_norm.weight': tensor([0.2551, 0.3916, 0.4587,  ..., 0.1593, 0.1455, 0.0640],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.layer_norm.bias': tensor([ 0.0016, -0.0094,  0.0044,  ..., -0.0253,  0.0004, -0.1724],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_1.weight': tensor([[-0.0267, -0.2546, -0.1114,  ...,  0.0208, -0.4014, -0.0889],\n",
       "         [ 0.1504,  0.1133, -0.3638,  ..., -0.0380, -0.0839, -0.0189],\n",
       "         [-0.3149,  0.2098, -0.0369,  ..., -0.0750,  0.1387, -0.1759],\n",
       "         ...,\n",
       "         [ 0.1409,  0.0983,  0.0416,  ...,  0.1759, -0.0855,  0.1470],\n",
       "         [-0.1570,  0.0397, -0.2314,  ..., -0.1272,  0.0359,  0.0133],\n",
       "         [-0.1584, -0.0536, -0.2089,  ..., -0.1642, -0.5425, -0.1512]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_1.bias': tensor([-0.0205, -0.1761, -0.1024,  ..., -0.1119, -0.2397, -0.1015],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_2.weight': tensor([[ 0.2343,  0.1005, -0.0427,  ..., -0.0775, -0.1626, -0.0025],\n",
       "         [-0.2034, -0.2035, -0.0301,  ..., -0.2466,  0.1137,  0.2327],\n",
       "         [ 0.0221,  0.0497,  0.0061,  ...,  0.0156,  0.4207,  0.0813],\n",
       "         ...,\n",
       "         [ 0.0395,  0.2274,  0.0329,  ...,  0.0589,  0.1022, -0.2118],\n",
       "         [-0.0251, -0.1895,  0.0290,  ...,  0.5098,  0.1008, -0.3828],\n",
       "         [ 0.3801,  0.1416, -0.0853,  ...,  0.0865,  0.0880, -0.0945]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.w_2.bias': tensor([-0.2042, -0.3538,  0.0340,  ..., -0.5020, -0.2240, -0.4961],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.layer_norm.weight': tensor([0.4373, 0.5439, 0.6646,  ..., 0.4412, 0.3557, 0.5312],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.2.feed_forward.layer_norm.bias': tensor([ 0.0157, -0.1758,  0.0136,  ...,  0.3103,  0.2247,  0.3567],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_keys.weight': tensor([[ 0.1273,  0.2241, -0.0561,  ..., -0.1205,  0.2671,  0.1118],\n",
       "         [-0.1213,  0.0095, -0.0512,  ..., -0.0240,  0.2441,  0.0936],\n",
       "         [-0.1697, -0.1659,  0.1774,  ...,  0.1174, -0.1907,  0.1812],\n",
       "         ...,\n",
       "         [-0.2524, -0.0491, -0.2900,  ..., -0.0951,  0.3584,  0.0298],\n",
       "         [ 0.3196, -0.3335,  0.0198,  ..., -0.2542,  0.2593, -0.2198],\n",
       "         [-0.2167, -0.0964, -0.0109,  ...,  0.1262,  0.2217,  0.2588]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_keys.bias': tensor([ 0.0045, -0.0249,  0.0055,  ...,  0.0129,  0.0192, -0.0107],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_values.weight': tensor([[-0.1000, -0.0194, -0.0435,  ..., -0.2358,  0.0946,  0.0695],\n",
       "         [ 0.0120,  0.0917, -0.1650,  ...,  0.1097, -0.0242, -0.0247],\n",
       "         [ 0.0066, -0.0302,  0.0870,  ..., -0.0209,  0.4578, -0.0189],\n",
       "         ...,\n",
       "         [ 0.3220, -0.0787, -0.2520,  ...,  0.1698,  0.2107,  0.0212],\n",
       "         [ 0.0778,  0.0969,  0.0474,  ...,  0.1864, -0.0052, -0.0772],\n",
       "         [-0.0798,  0.2871,  0.1097,  ..., -0.0649,  0.0545,  0.0087]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_values.bias': tensor([-0.0052,  0.1276, -0.0572,  ..., -0.1461, -0.2104, -0.0482],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_query.weight': tensor([[ 0.1786, -0.3074, -0.1509,  ...,  0.1709, -0.3638, -0.1603],\n",
       "         [-0.1456, -0.0075, -0.0852,  ..., -0.1757,  0.4004,  0.3643],\n",
       "         [ 0.1526,  0.0436, -0.1224,  ...,  0.0580,  0.4180, -0.2462],\n",
       "         ...,\n",
       "         [-0.2957, -0.0009, -0.4045,  ...,  0.2405, -0.2418,  0.0562],\n",
       "         [-0.1401, -0.1481, -0.1549,  ..., -0.3357,  0.0062, -0.2097],\n",
       "         [ 0.1744, -0.2991, -0.4023,  ...,  0.0531, -0.3079,  0.1447]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.linear_query.bias': tensor([ 0.3250,  0.2773,  0.2637,  ...,  0.4526, -0.1826,  0.5928],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.final_linear.weight': tensor([[ 0.2375,  0.4453, -0.1666,  ..., -0.0097, -0.2749,  0.2230],\n",
       "         [-0.1320,  0.1287, -0.1155,  ..., -0.0981, -0.1682,  0.0881],\n",
       "         [ 0.2158, -0.1592,  0.2389,  ..., -0.2021,  0.0601,  0.0741],\n",
       "         ...,\n",
       "         [-0.2094,  0.2705,  0.3247,  ..., -0.3774, -0.0038,  0.0504],\n",
       "         [ 0.1333, -0.0093,  0.0922,  ..., -0.2559, -0.2120, -0.0821],\n",
       "         [ 0.1238, -0.1958, -0.2073,  ...,  0.0613,  0.0382, -0.0040]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.self_attn.final_linear.bias': tensor([-0.1768,  0.0324, -0.4902,  ..., -0.1864, -0.1381, -0.0352],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.layer_norm.weight': tensor([0.2632, 0.3484, 0.3823,  ..., 0.1754, 0.1694, 0.0759],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.layer_norm.bias': tensor([-0.0017, -0.0178,  0.0143,  ..., -0.0205, -0.0016, -0.1876],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_1.weight': tensor([[ 0.2700,  0.1938,  0.2998,  ...,  0.1562,  0.1998,  0.3589],\n",
       "         [ 0.1078,  0.3862,  0.1381,  ..., -0.1604, -0.1088,  0.1871],\n",
       "         [-0.0421,  0.3840, -0.1287,  ...,  0.0122,  0.1149, -0.0363],\n",
       "         ...,\n",
       "         [ 0.0747,  0.2203, -0.2174,  ..., -0.3176, -0.0036, -0.1372],\n",
       "         [ 0.1874,  0.1069, -0.1216,  ..., -0.2939,  0.4365,  0.1703],\n",
       "         [ 0.1702,  0.2842,  0.0290,  ...,  0.0687, -0.0826,  0.0793]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_1.bias': tensor([-0.0987, -0.1757, -0.0022,  ..., -0.2773, -0.2390, -0.1774],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_2.weight': tensor([[-0.0603, -0.1033,  0.0816,  ..., -0.3188, -0.2788, -0.1556],\n",
       "         [ 0.0388,  0.0523, -0.2107,  ..., -0.2145,  0.0859,  0.1127],\n",
       "         [-0.0334, -0.1051, -0.0261,  ...,  0.1476, -0.2554, -0.1295],\n",
       "         ...,\n",
       "         [-0.0571, -0.1379, -0.1825,  ..., -0.0071, -0.1080, -0.2607],\n",
       "         [-0.2651, -0.1130,  0.1184,  ..., -0.3130,  0.2365, -0.1627],\n",
       "         [-0.2324, -0.0607,  0.2191,  ...,  0.4524,  0.0908,  0.0570]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.w_2.bias': tensor([-0.1322, -0.2524, -0.2625,  ..., -0.6270, -0.4980,  0.1598],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.layer_norm.weight': tensor([0.5571, 0.6401, 0.6841,  ..., 0.5356, 0.4375, 0.5571],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.3.feed_forward.layer_norm.bias': tensor([ 0.0726, -0.2047,  0.0892,  ...,  0.3430,  0.1608,  0.3596],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_keys.weight': tensor([[-0.1092, -0.0028, -0.1350,  ..., -0.1427,  0.2861, -0.0529],\n",
       "         [ 0.1046,  0.1780, -0.0298,  ..., -0.0937,  0.0679, -0.0216],\n",
       "         [-0.1721, -0.1276,  0.2137,  ...,  0.0411, -0.0165, -0.1064],\n",
       "         ...,\n",
       "         [ 0.1192,  0.1671,  0.2939,  ...,  0.1614, -0.0975,  0.0159],\n",
       "         [-0.1638, -0.1135, -0.0382,  ...,  0.0856, -0.1583, -0.0257],\n",
       "         [-0.1689,  0.3257, -0.1021,  ...,  0.0256,  0.0517,  0.1899]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_keys.bias': tensor([ 0.0186, -0.0253, -0.0241,  ...,  0.0240,  0.0197,  0.0040],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_values.weight': tensor([[-0.0698, -0.0300,  0.1226,  ..., -0.2991,  0.0958,  0.0717],\n",
       "         [ 0.1055,  0.0383, -0.1597,  ..., -0.2573,  0.1906,  0.0244],\n",
       "         [ 0.0713, -0.3877, -0.1547,  ...,  0.0464, -0.0274,  0.0415],\n",
       "         ...,\n",
       "         [ 0.0169,  0.1136, -0.2030,  ..., -0.1438,  0.3379,  0.1071],\n",
       "         [-0.2815,  0.1594,  0.4478,  ...,  0.1702, -0.4883,  0.0009],\n",
       "         [-0.2661, -0.0815,  0.4202,  ..., -0.1316, -0.3354,  0.0138]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_values.bias': tensor([-0.0147, -0.1171,  0.1478,  ..., -0.0172, -0.0030, -0.1357],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_query.weight': tensor([[-0.3167,  0.2019,  0.2131,  ...,  0.0332, -0.3059, -0.3101],\n",
       "         [ 0.0149, -0.0750,  0.2404,  ..., -0.1279, -0.1794,  0.1234],\n",
       "         [-0.0178, -0.0139, -0.2239,  ..., -0.1698, -0.0556, -0.1077],\n",
       "         ...,\n",
       "         [-0.1376,  0.0729, -0.2188,  ...,  0.0415, -0.1272,  0.3601],\n",
       "         [ 0.0909,  0.0670, -0.0636,  ..., -0.1163, -0.2096, -0.0964],\n",
       "         [ 0.2123, -0.3875, -0.1823,  ..., -0.0737, -0.0089, -0.1017]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.linear_query.bias': tensor([-0.1918,  0.3306,  0.0953,  ..., -0.0160, -0.1255,  0.0032],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.final_linear.weight': tensor([[ 0.3052,  0.0142, -0.2898,  ...,  0.0723,  0.0241,  0.1895],\n",
       "         [-0.2295, -0.2798, -0.0404,  ...,  0.1388,  0.2332,  0.2834],\n",
       "         [ 0.1124,  0.0247,  0.2905,  ...,  0.0372, -0.3989, -0.0923],\n",
       "         ...,\n",
       "         [ 0.0914,  0.4182,  0.0561,  ..., -0.3076, -0.0513,  0.0178],\n",
       "         [-0.0081, -0.1631,  0.3223,  ...,  0.0817, -0.0063,  0.0272],\n",
       "         [-0.0464,  0.0386, -0.3821,  ..., -0.2686,  0.2832, -0.3052]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.self_attn.final_linear.bias': tensor([-0.2148, -0.2712, -0.4692,  ..., -0.4463, -0.2773, -0.1874],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.layer_norm.weight': tensor([0.2480, 0.2932, 0.3071,  ..., 0.1970, 0.1952, 0.0856],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.layer_norm.bias': tensor([ 0.0061, -0.0186,  0.0067,  ..., -0.0136,  0.0044, -0.1420],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_1.weight': tensor([[-0.0947, -0.3777,  0.1453,  ...,  0.2079,  0.1239, -0.1075],\n",
       "         [-0.0224, -0.1260,  0.0084,  ..., -0.1088, -0.1128,  0.4102],\n",
       "         [-0.1868,  0.2651, -0.2267,  ..., -0.2732,  0.2051,  0.1484],\n",
       "         ...,\n",
       "         [-0.1461, -0.2017,  0.1912,  ..., -0.0526, -0.1860,  0.0266],\n",
       "         [ 0.3555,  0.1292, -0.0576,  ..., -0.0812, -0.0305, -0.1492],\n",
       "         [ 0.0394, -0.0345,  0.0431,  ...,  0.0626,  0.0320,  0.5259]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_1.bias': tensor([-0.1158, -0.1146, -0.0953,  ..., -0.0958, -0.1493,  0.1250],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_2.weight': tensor([[ 9.1736e-02, -3.4851e-02,  6.6711e-02,  ...,  1.7236e-01,\n",
       "          -2.4426e-01, -1.8814e-02],\n",
       "         [ 2.3706e-01,  1.6125e-01, -1.7261e-01,  ...,  1.8347e-01,\n",
       "           3.2921e-03,  2.4902e-02],\n",
       "         [ 1.3171e-01,  1.8689e-01, -5.2910e-03,  ..., -8.6365e-02,\n",
       "          -4.3640e-02,  3.5248e-03],\n",
       "         ...,\n",
       "         [-3.4094e-04, -2.9468e-01,  1.6211e-01,  ...,  2.6520e-02,\n",
       "          -4.6265e-02,  5.0537e-02],\n",
       "         [-2.1143e-01, -1.3879e-01,  4.9731e-01,  ...,  7.4158e-03,\n",
       "           2.5854e-01,  2.4811e-02],\n",
       "         [-8.2092e-02,  2.2675e-02, -2.8735e-01,  ...,  6.6528e-02,\n",
       "           2.5195e-01,  3.7183e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.w_2.bias': tensor([-0.0294, -0.0543, -0.1670,  ..., -0.4087, -0.3076, -0.2484],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.layer_norm.weight': tensor([0.8389, 0.8896, 0.9126,  ..., 0.8003, 0.6929, 0.9141],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.4.feed_forward.layer_norm.bias': tensor([ 0.0629, -0.1814,  0.1497,  ...,  0.3884,  0.2186,  0.6089],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_keys.weight': tensor([[-0.1027,  0.1290,  0.2034,  ...,  0.0239,  0.0739,  0.1147],\n",
       "         [ 0.0134,  0.0109,  0.0040,  ..., -0.1880, -0.0925,  0.1240],\n",
       "         [ 0.1074, -0.2524,  0.1588,  ..., -0.0675, -0.1399, -0.1630],\n",
       "         ...,\n",
       "         [-0.1376,  0.0674, -0.1263,  ..., -0.0240, -0.1779,  0.2888],\n",
       "         [-0.0420, -0.0428, -0.0071,  ...,  0.1560,  0.2296, -0.0860],\n",
       "         [ 0.2198,  0.2279, -0.0904,  ..., -0.0740,  0.1239, -0.1846]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_keys.bias': tensor([-0.0248, -0.0112,  0.0246,  ...,  0.0078,  0.0279, -0.0154],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_values.weight': tensor([[-6.2683e-02,  4.0723e-01,  3.0078e-01,  ...,  2.5342e-01,\n",
       "           3.8208e-01, -1.4209e-01],\n",
       "         [ 2.1057e-01, -4.9731e-01, -5.0195e-01,  ...,  4.3604e-01,\n",
       "          -2.5562e-01,  7.9468e-02],\n",
       "         [ 2.2192e-01, -4.8315e-01, -4.9951e-01,  ...,  2.4561e-01,\n",
       "          -1.2524e-01, -8.5876e-02],\n",
       "         ...,\n",
       "         [ 2.9297e-03,  1.6528e-01,  1.7249e-01,  ...,  2.3157e-01,\n",
       "          -8.5205e-02, -1.6647e-02],\n",
       "         [ 1.7163e-01, -5.5176e-01,  1.1542e-01,  ..., -2.9545e-03,\n",
       "           3.3618e-01,  3.1757e-04],\n",
       "         [-1.7358e-01,  1.0901e-01,  3.8971e-02,  ..., -3.2129e-01,\n",
       "          -6.4148e-02,  9.6985e-02]], dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_values.bias': tensor([ 0.2517,  0.0800, -0.1105,  ...,  0.1067,  0.0918, -0.2163],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_query.weight': tensor([[-0.0835, -0.2556,  0.1780,  ..., -0.0013,  0.0685,  0.1277],\n",
       "         [-0.0474,  0.0945,  0.0859,  ..., -0.0839, -0.2522,  0.3069],\n",
       "         [-0.1220,  0.1346,  0.0013,  ..., -0.1627,  0.1812, -0.3811],\n",
       "         ...,\n",
       "         [-0.5020, -0.2435, -0.0367,  ..., -0.1248, -0.0159,  0.0864],\n",
       "         [-0.0185, -0.1132, -0.1614,  ...,  0.0128, -0.2505,  0.0236],\n",
       "         [ 0.0471, -0.0351,  0.2712,  ..., -0.0532, -0.0487,  0.1573]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.linear_query.bias': tensor([-0.1298,  0.3081, -0.0649,  ...,  0.3333, -0.2089, -0.3911],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.final_linear.weight': tensor([[-0.1759, -0.2527, -0.4905,  ..., -0.1455,  0.0436,  0.0316],\n",
       "         [-0.0808,  0.3103, -0.0531,  ...,  0.2908, -0.4807, -0.0984],\n",
       "         [-0.2214, -0.2119,  0.0950,  ...,  0.3025,  0.3235,  0.0836],\n",
       "         ...,\n",
       "         [-0.1042, -0.2352, -0.2393,  ..., -0.0567, -0.1390, -0.5044],\n",
       "         [ 0.1320, -0.2820,  0.1831,  ..., -0.0705,  0.1049,  0.4670],\n",
       "         [ 0.1141, -0.1040,  0.2449,  ...,  0.2822, -0.1600,  0.0797]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.self_attn.final_linear.bias': tensor([-0.2974,  0.1377, -0.3240,  ..., -0.3740, -0.3955, -0.0625],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.layer_norm.weight': tensor([0.2593, 0.2888, 0.2932,  ..., 0.2134, 0.1947, 0.1024],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.layer_norm.bias': tensor([ 0.0130, -0.0358,  0.0096,  ..., -0.0243, -0.0059, -0.1379],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_1.weight': tensor([[-0.1627,  0.4009,  0.3484,  ..., -0.4468,  0.2238,  0.0247],\n",
       "         [-0.2316, -0.2040,  0.2120,  ...,  0.0018,  0.2175, -0.0315],\n",
       "         [ 0.0982,  0.2788, -0.5264,  ...,  0.2260, -0.1183, -0.1161],\n",
       "         ...,\n",
       "         [-0.1323, -0.2255,  0.0363,  ..., -0.2161, -0.0649, -0.0839],\n",
       "         [ 0.0827,  0.3855,  0.0304,  ..., -0.1301,  0.0207,  0.0511],\n",
       "         [ 0.1125,  0.0268,  0.0286,  ..., -0.0140, -0.2603,  0.0757]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_1.bias': tensor([-0.3113, -0.2347, -0.2471,  ...,  0.0296, -0.0106, -0.1477],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_2.weight': tensor([[ 0.1118, -0.0317,  0.3906,  ...,  0.1901,  0.0196,  0.1421],\n",
       "         [ 0.2644, -0.2418, -0.0213,  ...,  0.2583, -0.1804,  0.0911],\n",
       "         [ 0.1860,  0.1185, -0.1493,  ..., -0.0756, -0.0252, -0.0974],\n",
       "         ...,\n",
       "         [-0.0878,  0.0639,  0.0248,  ...,  0.1627, -0.0352,  0.0266],\n",
       "         [-0.2057,  0.3218,  0.3306,  ...,  0.0302, -0.1030, -0.1403],\n",
       "         [-0.3589,  0.0693,  0.3821,  ...,  0.0552,  0.0178,  0.1909]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.w_2.bias': tensor([-0.1635,  0.1593,  0.2888,  ..., -0.3391, -0.1981,  0.2345],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.layer_norm.weight': tensor([1.0498, 1.0732, 1.0986,  ..., 1.0576, 0.9355, 1.1182],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.5.feed_forward.layer_norm.bias': tensor([ 0.0972, -0.2222,  0.1204,  ...,  0.2439, -0.0014,  0.7427],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_keys.weight': tensor([[-0.0706, -0.0345,  0.2610,  ..., -0.1284,  0.0302, -0.1357],\n",
       "         [ 0.1028,  0.0043, -0.1156,  ..., -0.1282, -0.1825, -0.1663],\n",
       "         [-0.2213, -0.1600,  0.1575,  ...,  0.2169, -0.0125,  0.1002],\n",
       "         ...,\n",
       "         [-0.0800, -0.0073, -0.0764,  ..., -0.1770, -0.0122, -0.1235],\n",
       "         [ 0.1169,  0.0127, -0.1982,  ..., -0.0235,  0.0922,  0.0699],\n",
       "         [-0.4729, -0.2825,  0.0516,  ...,  0.0944,  0.0304,  0.3552]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_keys.bias': tensor([-0.0212,  0.0140,  0.0011,  ...,  0.0077,  0.0287, -0.0167],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_values.weight': tensor([[-0.1652,  0.3330,  0.3162,  ..., -0.2389,  0.2849, -0.0800],\n",
       "         [-0.1203,  0.2966, -0.1333,  ..., -0.2632,  0.3467,  0.0620],\n",
       "         [ 0.1744, -0.0900,  0.2561,  ..., -0.0182,  0.3352, -0.1104],\n",
       "         ...,\n",
       "         [-0.5029, -0.0768,  0.3154,  ..., -0.1250, -0.3794,  0.0287],\n",
       "         [ 0.2097,  0.2666, -0.5264,  ..., -0.3022,  0.2620, -0.2422],\n",
       "         [-0.3618,  0.1602,  0.1276,  ...,  0.1013, -0.4070, -0.0555]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_values.bias': tensor([-0.1273,  0.0925, -0.0681,  ...,  0.1183,  0.1335,  0.1152],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_query.weight': tensor([[ 5.8380e-02,  1.7212e-01,  1.0687e-01,  ...,  7.8491e-02,\n",
       "           2.8854e-02,  3.4326e-01],\n",
       "         [ 3.1348e-01,  1.0724e-01, -2.2888e-03,  ..., -3.3398e-03,\n",
       "          -2.1375e-01,  2.3218e-01],\n",
       "         [-1.6968e-01, -1.7670e-02,  1.2512e-01,  ...,  4.8615e-02,\n",
       "          -2.1106e-01, -2.4805e-01],\n",
       "         ...,\n",
       "         [-4.3365e-02,  4.7638e-02,  7.3303e-02,  ..., -3.2837e-02,\n",
       "           5.4840e-02, -1.5967e-01],\n",
       "         [ 7.6599e-02,  1.3269e-01, -4.7241e-02,  ...,  1.3574e-01,\n",
       "          -1.0687e-01, -2.5854e-01],\n",
       "         [ 1.8738e-02,  1.0598e-04,  3.7262e-02,  ...,  1.2688e-02,\n",
       "           3.1647e-02, -2.9468e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.linear_query.bias': tensor([-0.4375,  0.0213,  0.2203,  ..., -0.4126, -0.1324,  0.9414],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.final_linear.weight': tensor([[ 0.4932, -0.2959, -0.2666,  ..., -0.0205,  0.1765, -0.2189],\n",
       "         [ 0.2407,  0.2262,  0.1125,  ..., -0.0656,  0.1926,  0.0654],\n",
       "         [ 0.2922,  0.1119,  0.3481,  ...,  0.2129,  0.0788,  0.0352],\n",
       "         ...,\n",
       "         [-0.1580,  0.1183,  0.0581,  ..., -0.2288, -0.0887, -0.0232],\n",
       "         [-0.0381,  0.1404, -0.0415,  ..., -0.2959,  0.0758, -0.3286],\n",
       "         [-0.5059,  0.4998, -0.0927,  ...,  0.3774, -0.2629, -0.5054]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.self_attn.final_linear.bias': tensor([-0.0626,  0.2250, -0.1521,  ..., -0.4531, -0.2175,  0.0847],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.layer_norm.weight': tensor([0.2781, 0.3113, 0.3044,  ..., 0.2424, 0.2245, 0.1198],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.layer_norm.bias': tensor([ 0.0091, -0.0322,  0.0044,  ..., -0.0353, -0.0171, -0.1396],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_1.weight': tensor([[ 0.5049, -0.2141,  0.1185,  ...,  0.0346, -0.0762, -0.2939],\n",
       "         [-0.1039,  0.0520, -0.2483,  ..., -0.2549,  0.0668,  0.0578],\n",
       "         [-0.1609, -0.0087,  0.0487,  ...,  0.0201, -0.0370, -0.1423],\n",
       "         ...,\n",
       "         [-0.2238,  0.2118,  0.5020,  ..., -0.2603, -0.5088, -0.1318],\n",
       "         [ 0.0547, -0.1289, -0.1384,  ..., -0.3176, -0.0857,  0.4788],\n",
       "         [-0.1636, -0.1747,  0.0696,  ...,  0.1959, -0.3271, -0.2164]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_1.bias': tensor([-0.2440, -0.1483, -0.1898,  ..., -0.2588, -0.2106, -0.1549],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_2.weight': tensor([[-0.1581, -0.0368,  0.2334,  ..., -0.3040,  0.1361,  0.1009],\n",
       "         [ 0.2061,  0.0373, -0.1328,  ...,  0.4993, -0.0421, -0.2350],\n",
       "         [ 0.0025,  0.0223, -0.1836,  ...,  0.1327, -0.1272,  0.0468],\n",
       "         ...,\n",
       "         [-0.1857,  0.1321, -0.2494,  ..., -0.3591, -0.0569,  0.1892],\n",
       "         [-0.3350, -0.0670,  0.2271,  ...,  0.2461, -0.0009, -0.2045],\n",
       "         [ 0.0830,  0.0142,  0.1000,  ..., -0.2190,  0.0870,  0.2712]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.w_2.bias': tensor([-0.2479, -0.1766,  0.3108,  ..., -0.2715,  0.1544, -0.0607],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.layer_norm.weight': tensor([1.2949, 1.2705, 1.2734,  ..., 1.2637, 1.1494, 1.0869],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.6.feed_forward.layer_norm.bias': tensor([ 0.1816, -0.1693,  0.0043,  ...,  0.1831, -0.1348,  0.7734],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_keys.weight': tensor([[ 0.0403,  0.2040, -0.1902,  ...,  0.1509, -0.1453, -0.1630],\n",
       "         [-0.0783, -0.0748, -0.1115,  ...,  0.1044, -0.0614, -0.2024],\n",
       "         [-0.0826, -0.0220,  0.1033,  ...,  0.1572, -0.1219,  0.0381],\n",
       "         ...,\n",
       "         [-0.1497, -0.0581, -0.2620,  ..., -0.0068, -0.0917,  0.1129],\n",
       "         [-0.3176,  0.1254,  0.0963,  ...,  0.0521, -0.0949, -0.0911],\n",
       "         [ 0.0673, -0.1017, -0.2588,  ...,  0.0936,  0.1602,  0.0665]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_keys.bias': tensor([ 0.0198,  0.0307,  0.0190,  ...,  0.0079, -0.0173, -0.0075],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_values.weight': tensor([[ 0.6250,  0.3130, -0.0906,  ...,  0.1709,  0.1100,  0.0266],\n",
       "         [-0.3528,  0.0912, -0.4282,  ...,  0.2196, -0.1589, -0.0099],\n",
       "         [-0.0517, -0.0556, -0.1302,  ...,  0.4043, -0.1920,  0.2158],\n",
       "         ...,\n",
       "         [-0.0071, -0.0645, -0.3860,  ..., -0.0900,  0.0782, -0.0291],\n",
       "         [ 0.0308,  0.2062, -0.3958,  ...,  0.0598,  0.4902, -0.1539],\n",
       "         [ 0.4363, -0.0987, -0.4602,  ...,  0.1437,  0.0404,  0.0533]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_values.bias': tensor([ 0.0676,  0.4995, -0.2866,  ..., -0.1379, -0.1763,  0.2477],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_query.weight': tensor([[ 0.0831,  0.0398,  0.1328,  ...,  0.0081, -0.0090,  0.0434],\n",
       "         [-0.1038,  0.0436, -0.0704,  ..., -0.0676,  0.1190, -0.1210],\n",
       "         [ 0.0927,  0.0960,  0.0286,  ...,  0.0106,  0.1908,  0.1411],\n",
       "         ...,\n",
       "         [ 0.0671,  0.2081,  0.0379,  ...,  0.1769,  0.0137,  0.0703],\n",
       "         [-0.0284,  0.0137,  0.2231,  ..., -0.0323,  0.2351,  0.2407],\n",
       "         [ 0.0638,  0.0581, -0.0652,  ...,  0.0352,  0.0883,  0.0115]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.linear_query.bias': tensor([-0.0459,  0.5107,  0.0079,  ...,  0.2482,  0.0854,  0.0585],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.final_linear.weight': tensor([[-0.3962,  0.1968,  0.2440,  ..., -0.2708,  0.0613,  0.5044],\n",
       "         [-0.1608, -0.2025,  0.0812,  ...,  0.4180,  0.1942,  0.0641],\n",
       "         [ 0.1642, -0.0959,  0.0797,  ...,  0.0237, -0.0937,  0.5010],\n",
       "         ...,\n",
       "         [-0.1365, -0.1866,  0.0842,  ..., -0.2437, -0.0931,  0.2573],\n",
       "         [-0.1290,  0.1565,  0.2512,  ..., -0.3945,  0.0866, -0.0850],\n",
       "         [-0.3518,  0.4900,  0.2866,  ...,  0.2408,  0.2727, -0.0621]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.self_attn.final_linear.bias': tensor([-0.1945, -0.0603, -0.1410,  ..., -0.2971, -0.3428, -0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.layer_norm.weight': tensor([0.2864, 0.2981, 0.3025,  ..., 0.2600, 0.2637, 0.1532],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.layer_norm.bias': tensor([ 0.0018, -0.0353,  0.0016,  ..., -0.0442, -0.0206, -0.0556],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_1.weight': tensor([[ 0.3796, -0.2915,  0.0097,  ..., -0.1077,  0.2246,  0.0941],\n",
       "         [ 0.2150,  0.0715, -0.2764,  ..., -0.3174, -0.0606, -0.1829],\n",
       "         [-0.1274,  0.3252,  0.2388,  ..., -0.0192, -0.5010,  0.2556],\n",
       "         ...,\n",
       "         [-0.1538,  0.1974,  0.0007,  ...,  0.4119,  0.2036, -0.1060],\n",
       "         [ 0.1875, -0.0032, -0.2629,  ..., -0.0845,  0.0578,  0.1394],\n",
       "         [ 0.0598, -0.2800,  0.1261,  ..., -0.0494,  0.1498, -0.3682]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_1.bias': tensor([-0.1786,  0.0657, -0.2452,  ..., -0.1400, -0.1942, -0.2534],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_2.weight': tensor([[-0.0225,  0.0469,  0.5161,  ..., -0.0067, -0.4446,  0.1309],\n",
       "         [-0.1541,  0.0912, -0.1689,  ..., -0.0529, -0.1357, -0.1484],\n",
       "         [-0.1372,  0.0805, -0.4978,  ..., -0.1472,  0.0931,  0.0875],\n",
       "         ...,\n",
       "         [ 0.3457,  0.2556,  0.1699,  ...,  0.0536,  0.0854,  0.0499],\n",
       "         [ 0.2449, -0.0298,  0.0054,  ...,  0.1077, -0.1932, -0.1685],\n",
       "         [-0.1469, -0.0487, -0.0607,  ...,  0.0502, -0.5054,  0.0828]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.w_2.bias': tensor([-0.1750, -0.2800,  0.2668,  ..., -0.0279,  0.1831,  0.1775],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.layer_norm.weight': tensor([1.4658, 1.5234, 1.4697,  ..., 1.4619, 1.3975, 1.0264],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.7.feed_forward.layer_norm.bias': tensor([ 0.2140, -0.1531, -0.1310,  ...,  0.1624, -0.3196,  0.5806],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_keys.weight': tensor([[-0.0688, -0.0091, -0.1277,  ..., -0.0792, -0.1315,  0.2549],\n",
       "         [ 0.0327, -0.0327,  0.1985,  ..., -0.1526, -0.1306, -0.0013],\n",
       "         [ 0.0291, -0.2593,  0.0817,  ..., -0.0741,  0.0684, -0.0975],\n",
       "         ...,\n",
       "         [ 0.1205,  0.0697, -0.0167,  ...,  0.0344, -0.0850,  0.0958],\n",
       "         [-0.0356, -0.0033,  0.0279,  ...,  0.2449,  0.3352,  0.3486],\n",
       "         [-0.0198, -0.0017, -0.0009,  ..., -0.1373,  0.0296,  0.0921]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_keys.bias': tensor([ 0.0190,  0.0186,  0.0075,  ..., -0.0027,  0.0239, -0.0230],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_values.weight': tensor([[ 2.1698e-02,  5.0391e-01, -6.3599e-02,  ...,  3.4375e-01,\n",
       "          -5.6732e-02, -2.5439e-01],\n",
       "         [-5.0098e-01,  4.8828e-01, -3.9917e-01,  ..., -6.4163e-03,\n",
       "           2.7271e-01,  5.1239e-02],\n",
       "         [ 5.0342e-01, -2.5781e-01, -9.2224e-02,  ..., -2.5854e-01,\n",
       "           3.8013e-01,  2.5391e-01],\n",
       "         ...,\n",
       "         [-2.3806e-04, -2.4878e-01, -3.6865e-01,  ...,  1.6638e-01,\n",
       "           4.3030e-02,  1.0706e-01],\n",
       "         [-7.1472e-02,  5.3406e-02,  3.3667e-01,  ..., -4.8535e-01,\n",
       "          -4.1321e-02, -2.5244e-01],\n",
       "         [ 5.5518e-01, -6.1310e-02,  4.2041e-01,  ...,  2.2180e-01,\n",
       "           1.3086e-01, -1.9629e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_values.bias': tensor([ 0.0462, -0.1036, -0.0646,  ..., -0.1625,  0.0988,  0.0123],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_query.weight': tensor([[ 0.0249, -0.0852, -0.0412,  ...,  0.1812,  0.1111,  0.2671],\n",
       "         [-0.0025,  0.0505, -0.0931,  ...,  0.1137, -0.0060, -0.0775],\n",
       "         [ 0.2181,  0.0528,  0.0793,  ...,  0.2654,  0.0399, -0.0110],\n",
       "         ...,\n",
       "         [-0.0602,  0.0107, -0.1671,  ...,  0.1301,  0.2366,  0.0963],\n",
       "         [-0.0008,  0.1672,  0.2468,  ..., -0.1220, -0.1705, -0.0371],\n",
       "         [-0.1020,  0.0135,  0.0702,  ..., -0.0245,  0.1068, -0.0165]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.linear_query.bias': tensor([ 0.4907, -0.1603, -0.2605,  ...,  0.0511,  0.5312,  0.1677],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.final_linear.weight': tensor([[ 0.5000, -0.0681,  0.1069,  ..., -0.0848, -0.1550,  0.4285],\n",
       "         [-0.2615,  0.5898,  0.2981,  ..., -0.0019, -0.3152, -0.5073],\n",
       "         [-0.1832,  0.0960,  0.3252,  ..., -0.1443, -0.3098,  0.2847],\n",
       "         ...,\n",
       "         [-0.0236,  0.0312,  0.1584,  ..., -0.2113, -0.5024,  0.0351],\n",
       "         [ 0.4995,  0.0998,  0.1969,  ...,  0.3953,  0.0782, -0.1827],\n",
       "         [ 0.4517, -0.3076, -0.0215,  ...,  0.5000, -0.2598,  0.3438]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.self_attn.final_linear.bias': tensor([ 0.1201,  0.2529, -0.2769,  ..., -0.3010,  0.0786, -0.0475],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.layer_norm.weight': tensor([0.3359, 0.3503, 0.3406,  ..., 0.3118, 0.3076, 0.1715],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.layer_norm.bias': tensor([ 0.0137, -0.0487, -0.0163,  ..., -0.0402, -0.0260, -0.1025],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_1.weight': tensor([[-0.3015, -0.1304,  0.0669,  ..., -0.0325, -0.2152, -0.0944],\n",
       "         [-0.2681, -0.3765,  0.2029,  ...,  0.0684, -0.3738,  0.5010],\n",
       "         [ 0.1047, -0.2003, -0.0580,  ...,  0.0778, -0.3823,  0.1543],\n",
       "         ...,\n",
       "         [ 0.2312, -0.0673, -0.2435,  ..., -0.1077,  0.1111,  0.4194],\n",
       "         [-0.0049, -0.4768,  0.1390,  ...,  0.1024,  0.1753,  0.2595],\n",
       "         [-0.2419, -0.3213, -0.1992,  ..., -0.2561, -0.0931,  0.1797]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_1.bias': tensor([ 0.0402, -0.1921,  0.0009,  ..., -0.1022, -0.2727, -0.0250],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_2.weight': tensor([[ 2.2571e-01,  5.2917e-02,  3.8025e-02,  ...,  1.0181e-01,\n",
       "          -2.2070e-01,  8.1055e-02],\n",
       "         [-2.0561e-03, -7.6782e-02,  1.0541e-01,  ...,  3.5132e-01,\n",
       "          -4.7266e-01,  1.1688e-01],\n",
       "         [ 7.1564e-03, -2.0728e-01, -2.0337e-01,  ...,  1.1371e-01,\n",
       "          -2.3010e-01,  1.0876e-01],\n",
       "         ...,\n",
       "         [-2.3773e-02,  1.3578e-04, -8.6914e-02,  ...,  7.0740e-02,\n",
       "          -2.6953e-01,  2.6047e-02],\n",
       "         [ 9.0515e-02, -1.7542e-01,  3.3740e-01,  ...,  2.4524e-01,\n",
       "           1.2427e-01, -1.3501e-01],\n",
       "         [-9.7717e-02, -6.4453e-02,  9.1858e-02,  ...,  1.1902e-02,\n",
       "          -2.8101e-01,  2.2546e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.w_2.bias': tensor([-0.2666, -0.3450,  0.4014,  ..., -0.3533,  0.4529,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.layer_norm.weight': tensor([1.7168, 1.6738, 1.7178,  ..., 1.6064, 1.6738, 1.0039],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.8.feed_forward.layer_norm.bias': tensor([ 0.3455, -0.1840, -0.2661,  ...,  0.2267, -0.2754,  0.4849],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_keys.weight': tensor([[-0.0934,  0.0262,  0.0886,  ...,  0.1398,  0.0416,  0.0706],\n",
       "         [ 0.0422, -0.0273,  0.0023,  ...,  0.0563, -0.0426, -0.0468],\n",
       "         [ 0.0401,  0.0974, -0.2075,  ...,  0.0203, -0.0175, -0.0652],\n",
       "         ...,\n",
       "         [-0.1060,  0.0012, -0.0681,  ...,  0.2020, -0.1016, -0.1328],\n",
       "         [-0.0526,  0.1748, -0.0415,  ...,  0.1202,  0.0574, -0.2179],\n",
       "         [-0.1506, -0.1725,  0.0459,  ..., -0.1196, -0.1444, -0.0065]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_keys.bias': tensor([ 0.0083,  0.0081,  0.0163,  ..., -0.0311,  0.0125, -0.0013],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_values.weight': tensor([[-0.2930, -0.3538,  0.0164,  ...,  0.4600,  0.1323, -0.1270],\n",
       "         [ 0.0593, -0.1552, -0.1039,  ..., -0.1021, -0.5010, -0.3408],\n",
       "         [ 0.5088, -0.0402, -0.3328,  ...,  0.3240,  0.4419, -0.1626],\n",
       "         ...,\n",
       "         [ 0.1453,  0.3970, -0.5234,  ..., -0.2471, -0.4275, -0.0396],\n",
       "         [ 0.2164,  0.4973, -0.1378,  ...,  0.0124, -0.0421,  0.1594],\n",
       "         [-0.1237, -0.2634, -0.2815,  ...,  0.0323,  0.0985, -0.0444]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_values.bias': tensor([-0.0606,  0.2057,  0.1285,  ...,  0.0414, -0.0179, -0.1126],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_query.weight': tensor([[ 0.0533, -0.0367, -0.0298,  ..., -0.1113, -0.1151,  0.0941],\n",
       "         [-0.1364,  0.1113, -0.1127,  ..., -0.2859,  0.1389,  0.1482],\n",
       "         [-0.0801, -0.3044, -0.0587,  ...,  0.1190,  0.0527, -0.0526],\n",
       "         ...,\n",
       "         [ 0.0027,  0.0098,  0.0071,  ..., -0.0561, -0.0421,  0.0130],\n",
       "         [-0.0845, -0.0067,  0.0457,  ..., -0.0438,  0.0351,  0.0575],\n",
       "         [ 0.0757,  0.1078,  0.1119,  ...,  0.0146, -0.0102,  0.1037]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.linear_query.bias': tensor([-0.0395,  0.2544,  0.0701,  ..., -0.0873, -0.4170,  0.1514],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.final_linear.weight': tensor([[ 0.1595,  0.1053,  0.3035,  ..., -0.3784, -0.0549, -0.2336],\n",
       "         [-0.2150, -0.3525,  0.2207,  ..., -0.0771, -0.3467,  0.3674],\n",
       "         [ 0.0105,  0.2457,  0.1207,  ...,  0.3616, -0.4292,  0.0353],\n",
       "         ...,\n",
       "         [ 0.5269, -0.0899, -0.2500,  ...,  0.1394, -0.0237,  0.4280],\n",
       "         [ 0.0251, -0.3645,  0.2576,  ..., -0.2942, -0.0091, -0.1046],\n",
       "         [-0.3721,  0.2549, -0.1851,  ...,  0.2076, -0.0285, -0.1213]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.self_attn.final_linear.bias': tensor([ 0.1194,  0.1234, -0.3315,  ..., -0.1862, -0.2507, -0.3210],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.layer_norm.weight': tensor([0.3367, 0.3257, 0.3416,  ..., 0.3267, 0.3186, 0.2015],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.layer_norm.bias': tensor([-0.0108, -0.0378, -0.0120,  ..., -0.0397, -0.0296,  0.0007],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_1.weight': tensor([[-0.0850, -0.0334,  0.3296,  ..., -0.1797,  0.3176, -0.1475],\n",
       "         [ 0.2062,  0.0526,  0.4924,  ...,  0.3694,  0.2479, -0.2455],\n",
       "         [-0.1028, -0.2615, -0.3381,  ...,  0.1091, -0.3706,  0.1146],\n",
       "         ...,\n",
       "         [ 0.1309, -0.0182, -0.2957,  ...,  0.1622,  0.2084,  0.1324],\n",
       "         [-0.0830, -0.2047, -0.0750,  ..., -0.1594, -0.1129, -0.0185],\n",
       "         [ 0.2568,  0.1365, -0.0729,  ...,  0.1531,  0.0869,  0.1686]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_1.bias': tensor([-0.0652, -0.2603, -0.2491,  ..., -0.2477, -0.1270,  0.0648],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_2.weight': tensor([[ 0.0651, -0.1250,  0.2908,  ..., -0.2876,  0.0086, -0.3081],\n",
       "         [-0.4285,  0.4309, -0.1884,  ..., -0.0551, -0.2028, -0.0470],\n",
       "         [ 0.1276, -0.3735, -0.4778,  ..., -0.2922,  0.0392,  0.0829],\n",
       "         ...,\n",
       "         [-0.3789,  0.1226,  0.0482,  ...,  0.4937,  0.3669, -0.0059],\n",
       "         [-0.2620,  0.1331, -0.2130,  ..., -0.1647, -0.0382,  0.0402],\n",
       "         [-0.1763, -0.3599,  0.0088,  ..., -0.2683, -0.1316,  0.0857]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.w_2.bias': tensor([-0.2073, -0.3306,  0.3516,  ..., -0.1648,  0.4053,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.layer_norm.weight': tensor([1.8896, 1.8975, 1.8369,  ..., 1.7158, 1.8867, 1.0020],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.9.feed_forward.layer_norm.bias': tensor([ 0.3481, -0.0704, -0.3877,  ...,  0.0132, -0.2754,  0.4976],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_keys.weight': tensor([[ 0.0754, -0.0750, -0.0309,  ..., -0.0340,  0.1871, -0.0750],\n",
       "         [-0.1177,  0.2014,  0.1215,  ...,  0.3188, -0.0710, -0.0375],\n",
       "         [ 0.1743, -0.0444,  0.1678,  ..., -0.1851,  0.1493,  0.0254],\n",
       "         ...,\n",
       "         [-0.1746, -0.0400,  0.0757,  ...,  0.1132, -0.1665,  0.1760],\n",
       "         [ 0.0428, -0.0995, -0.0690,  ...,  0.0299, -0.1648,  0.1179],\n",
       "         [-0.0603,  0.0314, -0.0255,  ...,  0.0553,  0.0923,  0.2301]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_keys.bias': tensor([ 0.0078, -0.0056, -0.0106,  ..., -0.0212, -0.0186, -0.0229],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_values.weight': tensor([[-0.1522,  0.2383,  0.1865,  ...,  0.2905,  0.0820,  0.0166],\n",
       "         [ 0.2666,  0.1146, -0.0781,  ...,  0.1699, -0.3335,  0.1304],\n",
       "         [-0.4468, -0.3083,  0.0360,  ..., -0.0930, -0.3240, -0.0488],\n",
       "         ...,\n",
       "         [ 0.0994, -0.2683,  0.5088,  ..., -0.0464, -0.1176,  0.3032],\n",
       "         [ 0.2908,  0.2324, -0.0009,  ..., -0.1620,  0.3689,  0.2500],\n",
       "         [ 0.0656, -0.1532, -0.0412,  ...,  0.4946, -0.2261, -0.2732]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_values.bias': tensor([-0.0977, -0.1240,  0.0131,  ..., -0.0121,  0.0525, -0.0734],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_query.weight': tensor([[-0.1930,  0.0522,  0.0082,  ...,  0.0521,  0.0998, -0.0263],\n",
       "         [-0.0575,  0.1549, -0.1658,  ..., -0.1860,  0.2107, -0.1044],\n",
       "         [-0.0764,  0.0324,  0.0944,  ...,  0.1270, -0.0540, -0.0314],\n",
       "         ...,\n",
       "         [-0.0464, -0.0764,  0.0583,  ...,  0.2264,  0.1029,  0.0735],\n",
       "         [ 0.0351, -0.0892, -0.0684,  ...,  0.1586,  0.0099, -0.1727],\n",
       "         [-0.0319, -0.0603, -0.1011,  ..., -0.3140,  0.0933, -0.0415]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.linear_query.bias': tensor([-0.3320,  0.1873,  0.0091,  ...,  0.1371,  0.0784, -0.0020],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.final_linear.weight': tensor([[-0.5034, -0.2983,  0.0629,  ...,  0.0390, -0.5015, -0.2040],\n",
       "         [ 0.1003,  0.1798,  0.1031,  ..., -0.3835,  0.0084,  0.5010],\n",
       "         [ 0.1758,  0.1630, -0.2917,  ...,  0.0962,  0.4963,  0.5000],\n",
       "         ...,\n",
       "         [ 0.1755,  0.3667,  0.3611,  ..., -0.2289,  0.1060, -0.2825],\n",
       "         [-0.2671, -0.4214, -0.3074,  ..., -0.2625, -0.3059,  0.0285],\n",
       "         [ 0.4990,  0.3005, -0.4709,  ...,  0.2185, -0.4902,  0.2612]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.self_attn.final_linear.bias': tensor([-0.0365,  0.1382, -0.2482,  ..., -0.3245, -0.1206, -0.3130],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.layer_norm.weight': tensor([0.3611, 0.3506, 0.3416,  ..., 0.3398, 0.3438, 0.2307],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.layer_norm.bias': tensor([-0.0012, -0.0452, -0.0125,  ..., -0.0408, -0.0147,  0.0466],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_1.weight': tensor([[ 0.1156, -0.0344,  0.1548,  ..., -0.2179,  0.3853, -0.0242],\n",
       "         [ 0.3975, -0.1139,  0.0091,  ..., -0.0827,  0.4434, -0.1761],\n",
       "         [ 0.3960,  0.0216, -0.0314,  ...,  0.0225, -0.2169, -0.0543],\n",
       "         ...,\n",
       "         [ 0.1395, -0.3721,  0.1024,  ..., -0.0687,  0.1179, -0.2325],\n",
       "         [-0.1383, -0.0200,  0.1689,  ...,  0.2786, -0.1664, -0.4736],\n",
       "         [-0.0500, -0.1879,  0.0883,  ...,  0.0870,  0.1624, -0.0334]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_1.bias': tensor([-0.1774, -0.2493,  0.0089,  ...,  0.0812, -0.1042, -0.0112],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_2.weight': tensor([[ 0.0633,  0.3196, -0.3215,  ..., -0.1116,  0.1827,  0.2673],\n",
       "         [ 0.0570, -0.2937, -0.0856,  ...,  0.1217, -0.1844,  0.2048],\n",
       "         [-0.4844, -0.1295, -0.0923,  ...,  0.0325, -0.0368, -0.0098],\n",
       "         ...,\n",
       "         [-0.0031,  0.2913, -0.1672,  ...,  0.0862,  0.0590, -0.1099],\n",
       "         [-0.2598,  0.1019,  0.2947,  ..., -0.1364, -0.1061,  0.0092],\n",
       "         [ 0.1287, -0.1024,  0.1221,  ..., -0.0401,  0.0828, -0.0964]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.w_2.bias': tensor([-0.1252, -0.2593,  0.1232,  ...,  0.0485,  0.2494,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.layer_norm.weight': tensor([1.7891, 1.7773, 1.8184,  ..., 1.7373, 1.7686, 1.0000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.10.feed_forward.layer_norm.bias': tensor([ 0.3123, -0.1324, -0.2803,  ..., -0.2485, -0.1224,  0.3059],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_keys.weight': tensor([[ 0.0086, -0.0414, -0.3499,  ...,  0.1313,  0.1610,  0.0051],\n",
       "         [ 0.1420,  0.0161, -0.0805,  ...,  0.0367,  0.0750, -0.0147],\n",
       "         [ 0.1501,  0.0788, -0.0873,  ..., -0.0138,  0.0100, -0.0401],\n",
       "         ...,\n",
       "         [-0.2258,  0.1349, -0.0797,  ...,  0.0210, -0.0510, -0.0725],\n",
       "         [ 0.0133, -0.2283, -0.1971,  ...,  0.2808, -0.1448,  0.1022],\n",
       "         [-0.2223,  0.0643, -0.2065,  ..., -0.0892,  0.0763,  0.0452]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_keys.bias': tensor([-0.0247, -0.0124,  0.0158,  ...,  0.0298,  0.0184, -0.0053],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_values.weight': tensor([[-0.3228, -0.2213, -0.4314,  ..., -0.1243,  0.0023, -0.1805],\n",
       "         [-0.2544,  0.2683,  0.0088,  ..., -0.3044,  0.3425, -0.0644],\n",
       "         [ 0.0420,  0.0554, -0.0193,  ..., -0.2462,  0.1820, -0.2064],\n",
       "         ...,\n",
       "         [-0.3894,  0.0691, -0.2698,  ...,  0.0479,  0.0766,  0.0311],\n",
       "         [-0.5674, -0.0828, -0.1783,  ..., -0.1588,  0.3806, -0.0439],\n",
       "         [ 0.2032,  0.0678, -0.4326,  ..., -0.1093, -0.0641,  0.1697]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_values.bias': tensor([ 0.0423,  0.0190, -0.0619,  ..., -0.0843,  0.0345, -0.0243],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_query.weight': tensor([[ 0.1095, -0.1726,  0.1010,  ..., -0.0748, -0.0682, -0.0528],\n",
       "         [ 0.0183, -0.0203,  0.2111,  ...,  0.5200,  0.1798, -0.0073],\n",
       "         [ 0.1667,  0.0603, -0.1227,  ...,  0.1139,  0.0238,  0.0292],\n",
       "         ...,\n",
       "         [-0.1715,  0.1740,  0.0278,  ..., -0.0693,  0.1809, -0.0255],\n",
       "         [-0.0011, -0.0814,  0.0205,  ...,  0.0806, -0.0358,  0.1978],\n",
       "         [ 0.0307, -0.0151,  0.0194,  ..., -0.1848, -0.0357,  0.0113]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.linear_query.bias': tensor([-0.0655,  0.1114, -0.0804,  ..., -0.0082,  0.4026, -0.2406],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.final_linear.weight': tensor([[-0.1425, -0.1304,  0.2463,  ...,  0.2605,  0.0704,  0.5000],\n",
       "         [-0.3113,  0.3472,  0.5015,  ...,  0.2778,  0.4353,  0.2678],\n",
       "         [-0.1364, -0.0914, -0.2534,  ..., -0.2903, -0.2021,  0.0350],\n",
       "         ...,\n",
       "         [-0.3306, -0.3472,  0.4177,  ...,  0.0071, -0.5371, -0.0557],\n",
       "         [ 0.4880, -0.2247, -0.1022,  ...,  0.0623, -0.1614, -0.0088],\n",
       "         [-0.0360, -0.0154,  0.0797,  ...,  0.0604, -0.0828,  0.0997]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.self_attn.final_linear.bias': tensor([-0.0739, -0.0063, -0.0346,  ..., -0.2489, -0.1971, -0.2751],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.layer_norm.weight': tensor([0.3723, 0.3530, 0.3521,  ..., 0.3430, 0.3640, 0.5117],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.layer_norm.bias': tensor([ 0.0076, -0.0373, -0.0152,  ..., -0.0352,  0.0002,  0.1772],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_1.weight': tensor([[ 2.5732e-01, -1.6187e-01, -4.4678e-01,  ...,  5.9845e-02,\n",
       "          -3.4668e-01, -6.9824e-02],\n",
       "         [ 1.7688e-01, -1.4697e-01,  3.6548e-01,  ..., -4.4287e-01,\n",
       "          -1.0376e-01, -8.9600e-02],\n",
       "         [-2.4670e-01,  2.3022e-01,  3.3618e-01,  ..., -1.1487e-01,\n",
       "          -3.8867e-01,  1.1646e-01],\n",
       "         ...,\n",
       "         [-1.4368e-01, -6.0242e-02,  3.1592e-01,  ...,  7.5500e-02,\n",
       "           1.4355e-01,  8.1177e-02],\n",
       "         [ 4.7302e-02,  3.1885e-01,  1.1621e-01,  ..., -6.1920e-02,\n",
       "          -9.5032e-02,  5.9395e-03],\n",
       "         [-3.4888e-01, -3.6890e-01, -3.6548e-01,  ...,  2.2339e-01,\n",
       "           2.6584e-04,  1.1902e-01]], dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_1.bias': tensor([-0.2379, -0.0254, -0.0665,  ..., -0.1392, -0.1793, -0.1711],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_2.weight': tensor([[-0.0247, -0.5405,  0.3447,  ...,  0.0279,  0.1028,  0.2759],\n",
       "         [ 0.1445,  0.2554,  0.0915,  ..., -0.1010, -0.0536,  0.1388],\n",
       "         [-0.0830, -0.0148, -0.2334,  ..., -0.0434, -0.1500,  0.2351],\n",
       "         ...,\n",
       "         [-0.4978,  0.0639, -0.3618,  ..., -0.0822,  0.0499,  0.0111],\n",
       "         [-0.1675, -0.2073, -0.1583,  ..., -0.1167, -0.0303,  0.3142],\n",
       "         [-0.0075,  0.0165,  0.0419,  ..., -0.0137,  0.0292, -0.0189]],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.w_2.bias': tensor([-0.0811, -0.1230,  0.0258,  ...,  0.1039,  0.1157,  0.2913],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.layer_norm.weight': tensor([1.3672, 1.2451, 1.1787,  ..., 1.4297, 1.2148, 1.0000],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.transformer.11.feed_forward.layer_norm.bias': tensor([ 0.1785, -0.0873, -0.0390,  ..., -0.2549,  0.0047, -0.2499],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.layer_norm.weight': tensor([0.4553, 0.4626, 0.4673,  ..., 0.4241, 0.4702, 0.7456],\n",
       "        dtype=torch.float16),\n",
       " 'encoder.layer_norm.bias': tensor([ 0.0014, -0.0053,  0.0018,  ..., -0.0308,  0.0012, -0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.embeddings.make_embedding.emb_luts.0.weight': tensor([[-0.0321,  0.0348,  0.0181,  ...,  0.0312, -0.0099, -0.0133],\n",
       "         [-0.0039,  0.0104, -0.0156,  ...,  0.0290, -0.0138, -0.0134],\n",
       "         [-0.0245, -0.0283, -0.0295,  ...,  0.9712, -0.0255, -0.0273],\n",
       "         ...,\n",
       "         [-0.0123, -0.0031, -0.0089,  ...,  0.0645, -0.0182, -0.0740],\n",
       "         [ 0.0085, -0.0088, -0.0091,  ...,  0.0571, -0.0035, -0.1298],\n",
       "         [-0.0076, -0.0107, -0.0051,  ...,  1.0264, -0.0338, -0.1175]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.embeddings.make_embedding.pe.pe': tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.8415,  0.8317,  0.8218,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 0.9093,  0.9236,  0.9365,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.9563,  0.5417,  0.7653,  ...,  0.8688,  0.8733,  0.8777]],\n",
       " \n",
       "         [[ 0.2705,  0.9999,  0.9649,  ...,  0.8687,  0.8733,  0.8777]],\n",
       " \n",
       "         [[-0.6639,  0.5685,  0.3343,  ...,  0.8687,  0.8732,  0.8776]]]),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_keys.weight': tensor([[ 0.2527, -0.0136, -0.0460,  ...,  0.0115,  0.2996, -0.2917],\n",
       "         [-0.2238, -0.0130,  0.0161,  ..., -0.0285, -0.1180, -0.1647],\n",
       "         [-0.0419,  0.1165,  0.0529,  ..., -0.1235, -0.1420, -0.0377],\n",
       "         ...,\n",
       "         [-0.1418, -0.2262, -0.2668,  ..., -0.4019,  0.1725, -0.4397],\n",
       "         [ 0.8843,  0.7051, -0.0199,  ...,  0.0214, -0.0945, -0.0924],\n",
       "         [ 0.5151,  0.7905,  0.5708,  ..., -0.1842,  0.1663, -0.4202]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_keys.bias': tensor([ 0.0171,  0.0190, -0.0028,  ...,  0.0214,  0.0051,  0.0162],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_values.weight': tensor([[ 0.1139, -0.0122,  0.0055,  ..., -0.0195, -0.0603, -0.2316],\n",
       "         [-0.0013,  0.0484, -0.0739,  ...,  0.0040,  0.0352,  0.0255],\n",
       "         [ 0.0599, -0.0119, -0.0344,  ...,  0.0804,  0.0247, -0.1047],\n",
       "         ...,\n",
       "         [-0.0121, -0.1064, -0.1040,  ...,  0.1565, -0.1312, -0.0582],\n",
       "         [ 0.0189, -0.0357, -0.0127,  ...,  0.1639, -0.0505,  0.2944],\n",
       "         [ 0.0603,  0.0012, -0.0043,  ...,  0.0229, -0.0510, -0.0253]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_values.bias': tensor([-0.1753, -0.0671,  0.0499,  ...,  0.0657, -0.1055,  0.1422],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_query.weight': tensor([[-0.0608, -0.0219, -0.0292,  ..., -0.2030,  0.2261,  0.2169],\n",
       "         [ 0.1031,  0.2079, -0.1537,  ...,  0.4563, -0.2065, -0.2493],\n",
       "         [-0.0536, -0.1057,  0.1284,  ...,  0.4861,  0.1749,  0.3396],\n",
       "         ...,\n",
       "         [-0.5005, -0.5000, -0.5034,  ...,  0.0190,  0.0634,  0.2839],\n",
       "         [ 0.7227,  0.9077,  0.5024,  ..., -0.3882,  0.0387, -0.2537],\n",
       "         [ 0.4541,  0.6118,  0.9834,  ...,  0.1675, -0.1345,  0.0667]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.linear_query.bias': tensor([ 0.1714, -0.2122,  0.0087,  ..., -0.0495, -0.3044, -0.4622],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.final_linear.weight': tensor([[-0.0922, -0.0627,  0.0594,  ..., -0.0709, -0.0629,  0.0347],\n",
       "         [-0.0212,  0.0095,  0.0910,  ..., -0.0070,  0.0226,  0.1028],\n",
       "         [ 0.0100, -0.0276,  0.0167,  ...,  0.0674,  0.0024, -0.0916],\n",
       "         ...,\n",
       "         [-0.0880, -0.1554, -0.0174,  ...,  0.0215, -0.1620,  0.0854],\n",
       "         [-0.1394,  0.1870,  0.1448,  ...,  0.1100, -0.1603,  0.1107],\n",
       "         [-0.1072,  0.2668,  0.0040,  ..., -0.1271, -0.0542,  0.1467]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.self_attn.final_linear.bias': tensor([-0.1847, -0.5151, -0.2632,  ...,  0.0610,  0.0335,  0.0851],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_1.weight': tensor([0.2671, 1.0840, 1.7480,  ..., 0.0716, 0.1120, 0.1166],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_1.bias': tensor([-0.0013,  0.0142,  0.0267,  ...,  0.0082,  0.0058,  0.0043],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_keys.weight': tensor([[ 2.7686e-01,  1.1139e-01,  1.2846e-03,  ...,  1.1462e-01,\n",
       "          -3.6523e-01,  2.1698e-02],\n",
       "         [ 3.3984e-01,  5.4596e-02,  1.8262e-01,  ..., -1.6614e-01,\n",
       "           5.4962e-02,  9.5703e-02],\n",
       "         [-3.4485e-02,  3.1982e-02,  2.4927e-01,  ...,  1.3464e-01,\n",
       "          -1.5210e-01,  2.5131e-02],\n",
       "         ...,\n",
       "         [ 1.2830e-01, -9.8999e-02, -4.3060e-02,  ..., -1.1230e-01,\n",
       "           4.0527e-02,  3.7445e-02],\n",
       "         [-6.1572e-01,  3.0398e-05, -5.9692e-02,  ..., -2.1881e-02,\n",
       "           9.4528e-03,  9.6970e-03],\n",
       "         [-4.3845e-04, -4.5288e-02,  7.2693e-02,  ..., -2.0020e-02,\n",
       "          -1.5234e-01, -4.1809e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_keys.bias': tensor([-0.0035,  0.0259,  0.0131,  ...,  0.0161, -0.0030, -0.0134],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_values.weight': tensor([[-2.2168e-01,  1.9531e-01, -2.2302e-01,  ..., -1.5430e-01,\n",
       "          -1.2484e-03, -3.5038e-03],\n",
       "         [-3.2806e-02, -1.0162e-01, -2.2998e-01,  ...,  1.2439e-01,\n",
       "           1.1713e-01,  2.1912e-02],\n",
       "         [ 8.3557e-02, -7.8430e-03,  4.4479e-03,  ..., -7.7515e-02,\n",
       "           1.2612e-04,  6.9237e-03],\n",
       "         ...,\n",
       "         [-1.2396e-01, -4.8584e-02,  6.2744e-02,  ...,  1.0675e-01,\n",
       "          -1.0156e-01, -3.1647e-02],\n",
       "         [ 1.4001e-01, -7.8613e-02, -2.6871e-02,  ..., -1.4417e-01,\n",
       "           1.5289e-02,  5.5725e-02],\n",
       "         [ 7.7400e-03,  1.3008e-02,  1.4258e-01,  ..., -1.0828e-01,\n",
       "           1.8225e-01, -2.6154e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_values.bias': tensor([ 0.0178, -0.0514, -0.0856,  ..., -0.0892, -0.1333,  0.0561],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_query.weight': tensor([[ 0.0181,  0.1831, -0.3489,  ...,  0.0055,  0.0179,  0.3159],\n",
       "         [-0.0963,  0.0248, -0.2091,  ..., -0.0937, -0.1661,  0.0223],\n",
       "         [-0.3262,  0.1173,  0.0812,  ..., -0.0140, -0.0066,  0.2837],\n",
       "         ...,\n",
       "         [ 0.1371, -0.1003,  0.0622,  ...,  0.0039, -0.0370, -0.1047],\n",
       "         [-0.5054,  0.0831, -0.1569,  ..., -0.0121,  0.0830, -0.0902],\n",
       "         [-0.2988, -0.0426,  0.0012,  ...,  0.2725,  0.2629, -0.3853]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.linear_query.bias': tensor([-0.0820,  0.0203,  0.0393,  ...,  0.0010, -0.1102, -0.0185],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.final_linear.weight': tensor([[ 5.9479e-02,  5.2246e-02,  1.3879e-01,  ..., -9.1675e-02,\n",
       "          -2.8214e-02,  1.6602e-02],\n",
       "         [ 4.7424e-02,  9.0332e-02, -1.6830e-02,  ..., -4.2999e-02,\n",
       "           5.8899e-02, -5.5199e-03],\n",
       "         [ 5.9357e-02, -1.4062e-01,  1.0791e-01,  ...,  7.4707e-02,\n",
       "          -3.4363e-02, -7.2876e-02],\n",
       "         ...,\n",
       "         [-1.1938e-01, -1.7102e-01, -6.7566e-02,  ...,  5.9052e-02,\n",
       "           5.6091e-02,  7.9163e-02],\n",
       "         [ 2.0984e-01,  8.2825e-02,  1.6260e-01,  ...,  4.7180e-02,\n",
       "          -1.4214e-02,  1.7029e-01],\n",
       "         [ 4.0222e-02,  1.0779e-01, -3.9624e-01,  ...,  9.2896e-02,\n",
       "          -4.1656e-02, -9.8169e-05]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.context_attn.final_linear.bias': tensor([-0.2084,  0.1163, -0.0021,  ..., -0.0227,  0.0979,  0.2081],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_2.weight': tensor([0.1486, 0.3196, 0.3987,  ..., 0.1199, 0.0912, 0.0984],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.layer_norm_2.bias': tensor([-0.0154, -0.0182, -0.0321,  ..., -0.0105, -0.0070, -0.0171],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_1.weight': tensor([[ 0.1344,  0.7622,  0.2412,  ...,  0.2900, -0.2639, -0.3789],\n",
       "         [-0.0172,  0.1448, -0.2893,  ...,  0.1109, -0.2581, -0.0345],\n",
       "         [ 0.1434, -0.1132,  0.1077,  ..., -0.1946,  0.0080, -0.4224],\n",
       "         ...,\n",
       "         [-0.0646,  0.4250, -0.0431,  ..., -0.1595, -0.1165,  0.3054],\n",
       "         [ 0.2461, -0.0331,  0.0623,  ...,  0.1078,  0.2034, -0.1764],\n",
       "         [ 0.3833, -0.1958, -0.3770,  ...,  0.0027, -0.2030, -0.2375]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_1.bias': tensor([-0.2781, -0.0742, -0.0874,  ..., -0.0566, -0.0241, -0.2001],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_2.weight': tensor([[-0.1371, -0.1132,  0.0466,  ...,  0.2681, -0.0298, -0.1131],\n",
       "         [ 0.2164, -0.0201, -0.0924,  ...,  0.1089, -0.1300, -0.1272],\n",
       "         [ 0.0881,  0.0721, -0.0802,  ..., -0.0063,  0.0746,  0.1890],\n",
       "         ...,\n",
       "         [ 0.1101,  0.0833, -0.1298,  ..., -0.0008, -0.0935, -0.0485],\n",
       "         [-0.3896,  0.1687, -0.1404,  ...,  0.0498,  0.0757,  0.1858],\n",
       "         [-0.2925, -0.0252,  0.2664,  ...,  0.1076,  0.4316,  0.0273]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.w_2.bias': tensor([ 9.9304e-02,  5.1483e-02,  2.4277e-02,  ..., -4.9146e-01,\n",
       "         -1.7102e-01, -5.7220e-06], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.layer_norm.weight': tensor([0.2993, 0.6899, 0.8115,  ..., 0.2859, 0.1858, 0.2041],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.0.feed_forward.layer_norm.bias': tensor([-0.0114, -0.0121, -0.0416,  ...,  0.0494,  0.0188,  0.0542],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_keys.weight': tensor([[ 0.1534, -0.1125, -0.1119,  ..., -0.1871,  0.2374,  0.0232],\n",
       "         [ 0.3218, -0.1428,  0.0255,  ..., -0.1315, -0.0137,  0.1196],\n",
       "         [-0.1437, -0.1470, -0.0161,  ..., -0.2886,  0.1324, -0.1108],\n",
       "         ...,\n",
       "         [-0.1249,  0.1697,  0.4082,  ..., -0.3542, -0.2754, -0.1086],\n",
       "         [ 0.4036, -0.0794,  0.0101,  ..., -0.0826,  0.5649, -0.0558],\n",
       "         [-0.0320,  0.0214, -0.0146,  ...,  0.2869, -0.0469, -0.2600]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_keys.bias': tensor([-0.0115,  0.0259, -0.0176,  ...,  0.0260,  0.0236,  0.0175],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_values.weight': tensor([[ 0.1611,  0.2081,  0.1771,  ..., -0.2059, -0.0025,  0.0425],\n",
       "         [ 0.0439, -0.1763, -0.0055,  ..., -0.1410, -0.0632, -0.1220],\n",
       "         [ 0.1693,  0.2229,  0.4146,  ...,  0.0634,  0.0104,  0.1014],\n",
       "         ...,\n",
       "         [ 0.0663, -0.0892, -0.1144,  ..., -0.2166, -0.0717,  0.0168],\n",
       "         [ 0.0919,  0.2917, -0.1696,  ..., -0.0205, -0.2695,  0.1384],\n",
       "         [-0.1870,  0.1490, -0.2499,  ..., -0.0961, -0.0006,  0.1333]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_values.bias': tensor([ 0.0769, -0.0881, -0.1488,  ..., -0.0063, -0.0072,  0.0170],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_query.weight': tensor([[-0.0667,  0.2040,  0.0103,  ..., -0.0268, -0.1711,  0.0939],\n",
       "         [-0.2396,  0.3296, -0.2190,  ...,  0.1805,  0.2666, -0.0803],\n",
       "         [ 0.0565,  0.0851, -0.0085,  ...,  0.4153,  0.1097, -0.0129],\n",
       "         ...,\n",
       "         [-0.0325, -0.0953,  0.1277,  ..., -0.4856, -0.5068,  0.2008],\n",
       "         [ 0.0311, -0.1217, -0.0499,  ...,  0.2189, -0.4949,  0.3477],\n",
       "         [-0.2493,  0.1967,  0.4160,  ..., -0.4136, -0.1923,  0.0126]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.linear_query.bias': tensor([ 0.0458, -0.0001,  0.0027,  ..., -0.0262, -0.0651,  0.0208],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.final_linear.weight': tensor([[-0.1395,  0.1007, -0.2021,  ..., -0.2854,  0.2642,  0.0026],\n",
       "         [-0.2791,  0.3120, -0.3350,  ...,  0.0471, -0.1516,  0.1459],\n",
       "         [ 0.2573, -0.1997,  0.0403,  ...,  0.0028,  0.0232, -0.1825],\n",
       "         ...,\n",
       "         [ 0.4160,  0.3020, -0.0767,  ...,  0.2146, -0.3484,  0.1781],\n",
       "         [-0.0596, -0.2515,  0.1478,  ...,  0.0984, -0.0452,  0.0968],\n",
       "         [-0.3391,  0.4890, -0.1302,  ...,  0.3733, -0.3181, -0.0583]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.self_attn.final_linear.bias': tensor([-0.1322, -0.5068, -0.3179,  ..., -0.4104,  0.5020,  0.0186],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_1.weight': tensor([0.2335, 0.3899, 0.4363,  ..., 0.1646, 0.1715, 0.1766],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_1.bias': tensor([ 0.0122,  0.0031,  0.0142,  ..., -0.0172,  0.0160,  0.0054],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_keys.weight': tensor([[ 3.3398e-01,  3.1158e-02,  4.3152e-02,  ..., -1.9287e-01,\n",
       "          -1.6858e-01,  4.2175e-02],\n",
       "         [ 3.4515e-02, -1.7725e-01, -7.6660e-02,  ..., -5.5206e-02,\n",
       "          -6.0150e-02, -2.6245e-01],\n",
       "         [-1.0291e-01, -2.0947e-01,  4.8615e-02,  ..., -1.3843e-01,\n",
       "           1.7810e-01, -4.2267e-02],\n",
       "         ...,\n",
       "         [ 3.3081e-02,  8.9050e-02, -9.6863e-02,  ..., -4.3579e-02,\n",
       "          -4.2603e-02,  7.5928e-02],\n",
       "         [ 1.0266e-01, -3.2788e-01, -1.7285e-01,  ..., -2.2192e-01,\n",
       "           2.8801e-04,  2.7344e-01],\n",
       "         [ 3.6304e-01, -2.3499e-01, -4.5776e-01,  ...,  1.2268e-01,\n",
       "           1.1481e-01, -2.8976e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_keys.bias': tensor([-0.0274, -0.0099, -0.0295,  ...,  0.0261, -0.0028, -0.0228],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_values.weight': tensor([[-0.0637, -0.1584,  0.0154,  ..., -0.1114, -0.0318, -0.0013],\n",
       "         [ 0.2046,  0.1764, -0.1729,  ..., -0.3098,  0.1407, -0.0028],\n",
       "         [ 0.0202,  0.1407,  0.1124,  ...,  0.0605, -0.0785, -0.0263],\n",
       "         ...,\n",
       "         [ 0.1542,  0.1243,  0.1514,  ...,  0.1077, -0.0696,  0.0235],\n",
       "         [-0.1639, -0.0312,  0.2416,  ...,  0.0569,  0.0289,  0.0510],\n",
       "         [-0.0209,  0.0379,  0.0607,  ...,  0.0742,  0.1700, -0.0098]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_values.bias': tensor([ 0.0453, -0.0273, -0.0125,  ..., -0.0927, -0.0215,  0.1722],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_query.weight': tensor([[-0.0729, -0.0311, -0.1705,  ...,  0.1267,  0.0778, -0.0111],\n",
       "         [ 0.0575,  0.2003,  0.1246,  ...,  0.1231, -0.0115,  0.0741],\n",
       "         [ 0.1191,  0.1030, -0.2544,  ...,  0.0974,  0.0105, -0.0771],\n",
       "         ...,\n",
       "         [-0.5625, -0.1671,  0.2000,  ..., -0.2129,  0.0068,  0.2164],\n",
       "         [ 0.0772, -0.0503,  0.0390,  ..., -0.3298, -0.1742,  0.3379],\n",
       "         [ 0.0915,  0.0277, -0.4065,  ..., -0.1199,  0.4858, -0.0520]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.linear_query.bias': tensor([-0.2184, -0.5171, -0.0284,  ..., -0.0183,  0.0548,  0.1344],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.final_linear.weight': tensor([[-0.0327,  0.3237, -0.1772,  ...,  0.2573, -0.1348,  0.1152],\n",
       "         [ 0.0838,  0.0265, -0.2900,  ...,  0.2081,  0.1089,  0.0315],\n",
       "         [ 0.1299,  0.1479,  0.1301,  ..., -0.1229, -0.1685,  0.0691],\n",
       "         ...,\n",
       "         [-0.1422,  0.1223,  0.1954,  ..., -0.1614, -0.1797,  0.1772],\n",
       "         [ 0.0510,  0.0167, -0.0936,  ..., -0.1155, -0.2397,  0.1880],\n",
       "         [-0.3721, -0.2397,  0.0360,  ...,  0.0610, -0.0598,  0.0428]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.context_attn.final_linear.bias': tensor([-0.0711,  0.3042, -0.3445,  ..., -0.2491,  0.4126,  0.2225],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_2.weight': tensor([0.1310, 0.2273, 0.2188,  ..., 0.1075, 0.1068, 0.0997],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.layer_norm_2.bias': tensor([-0.0150, -0.0313, -0.0118,  ...,  0.0090,  0.0072, -0.0125],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_1.weight': tensor([[ 0.0250,  0.2991, -0.1091,  ..., -0.1277, -0.1576,  0.0674],\n",
       "         [ 0.2976, -0.1415,  0.4507,  ..., -0.1866,  0.1283,  0.0190],\n",
       "         [ 0.3267, -0.0324,  0.1790,  ..., -0.1440, -0.3320, -0.0600],\n",
       "         ...,\n",
       "         [ 0.1567,  0.0956,  0.1346,  ..., -0.3232, -0.1976, -0.3655],\n",
       "         [ 0.4209,  0.2257,  0.0028,  ..., -0.1316, -0.3711,  0.0569],\n",
       "         [ 0.1774, -0.2188,  0.1565,  ..., -0.2905,  0.0203, -0.2708]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_1.bias': tensor([-0.1600, -0.0608, -0.1709,  ..., -0.2771, -0.2356, -0.0980],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_2.weight': tensor([[-0.2366, -0.0439, -0.2294,  ...,  0.1348,  0.0668, -0.1799],\n",
       "         [ 0.1781,  0.1968,  0.0236,  ..., -0.1300, -0.2268,  0.2125],\n",
       "         [-0.0632,  0.1316,  0.0245,  ...,  0.0402,  0.0947, -0.1364],\n",
       "         ...,\n",
       "         [ 0.0862,  0.2155, -0.0999,  ..., -0.3252, -0.0651,  0.0750],\n",
       "         [ 0.1539,  0.5024,  0.3135,  ..., -0.2551,  0.0806, -0.0781],\n",
       "         [ 0.0167,  0.2075,  0.0334,  ..., -0.1337,  0.0619,  0.1277]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.w_2.bias': tensor([ 0.0667,  0.1331,  0.1181,  ..., -0.2947, -0.1676, -0.1841],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.layer_norm.weight': tensor([0.3525, 0.4556, 0.4563,  ..., 0.3020, 0.2478, 0.2815],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.1.feed_forward.layer_norm.bias': tensor([-0.0249, -0.0007, -0.0149,  ...,  0.0699,  0.0163,  0.0864],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_keys.weight': tensor([[-0.3308,  0.3665,  0.0386,  ...,  0.1205, -0.4648,  0.2186],\n",
       "         [ 0.0590,  0.1039,  0.0496,  ...,  0.1836, -0.3901,  0.3811],\n",
       "         [-0.4600, -0.1686,  0.0210,  ...,  0.0736,  0.1978,  0.0778],\n",
       "         ...,\n",
       "         [-0.5742, -0.1058, -0.0801,  ...,  0.3740, -0.0912, -0.0032],\n",
       "         [ 0.2705, -0.2336,  0.1692,  ..., -0.0341, -0.2332,  0.3018],\n",
       "         [ 0.0272, -0.0501,  0.1230,  ..., -0.1545, -0.0927, -0.0757]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_keys.bias': tensor([ 0.0152,  0.0089,  0.0074,  ...,  0.0129, -0.0011,  0.0167],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_values.weight': tensor([[-0.0995, -0.1671, -0.5259,  ..., -0.2869, -0.1268,  0.0750],\n",
       "         [ 0.0398, -0.0916, -0.0912,  ..., -0.1322, -0.2208,  0.1377],\n",
       "         [ 0.3433,  0.0499,  0.0323,  ...,  0.1874, -0.1367,  0.1506],\n",
       "         ...,\n",
       "         [ 0.0250,  0.0933,  0.0583,  ...,  0.0499, -0.1655, -0.2617],\n",
       "         [ 0.1227, -0.1143,  0.0930,  ...,  0.0697,  0.1770,  0.0898],\n",
       "         [ 0.0276,  0.1170, -0.1428,  ..., -0.0865,  0.0061, -0.1729]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_values.bias': tensor([-0.0004,  0.0150,  0.0520,  ...,  0.0121,  0.0303, -0.0188],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_query.weight': tensor([[-0.3401,  0.2352,  0.4128,  ...,  0.2554, -0.1636, -0.0297],\n",
       "         [ 0.1205, -0.1771, -0.1298,  ..., -0.0942,  0.0591, -0.1454],\n",
       "         [-0.0718, -0.0007,  0.0856,  ..., -0.1609,  0.2598, -0.0106],\n",
       "         ...,\n",
       "         [-0.0469, -0.1349,  0.0050,  ...,  0.1782,  0.1202, -0.1854],\n",
       "         [ 0.0954,  0.0739, -0.3987,  ...,  0.0170,  0.0279,  0.0166],\n",
       "         [-0.0461,  0.4138, -0.0368,  ..., -0.1155, -0.2113, -0.0650]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.linear_query.bias': tensor([-0.0418, -0.0768,  0.0216,  ..., -0.0235,  0.2318, -0.0897],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.final_linear.weight': tensor([[-1.5540e-01, -1.6052e-01,  9.6558e-02,  ...,  9.5215e-02,\n",
       "          -5.2490e-01, -1.0329e-04],\n",
       "         [-1.7261e-01,  1.2408e-01,  8.1604e-02,  ..., -2.1411e-01,\n",
       "          -1.5759e-01,  1.6846e-01],\n",
       "         [-2.4548e-01, -2.9126e-01, -7.3509e-03,  ..., -1.0956e-01,\n",
       "          -1.0693e-01, -7.5806e-02],\n",
       "         ...,\n",
       "         [ 2.4243e-01, -2.2388e-01,  3.2446e-01,  ..., -3.1104e-01,\n",
       "           1.0699e-01, -3.1201e-01],\n",
       "         [-4.9121e-01,  1.8164e-01,  1.7285e-01,  ..., -5.4102e-01,\n",
       "           1.8896e-01, -1.7456e-01],\n",
       "         [-1.4868e-01, -4.2686e-03, -1.5247e-01,  ..., -2.5244e-01,\n",
       "           2.0667e-01, -1.2164e-01]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.self_attn.final_linear.bias': tensor([-0.4189,  0.2380, -0.4163,  ..., -0.5039, -0.1493,  0.4475],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_1.weight': tensor([0.2588, 0.3323, 0.3691,  ..., 0.1847, 0.1929, 0.1981],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_1.bias': tensor([ 0.0080,  0.0052,  0.0182,  ..., -0.0058,  0.0125, -0.0036],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_keys.weight': tensor([[ 3.9368e-03,  1.2466e-02, -1.2500e-01,  ..., -4.4922e-01,\n",
       "           1.3086e-01, -1.2421e-01],\n",
       "         [-4.1553e-01, -2.4854e-01,  6.1249e-02,  ..., -1.4575e-01,\n",
       "           1.7358e-01, -3.6469e-02],\n",
       "         [ 2.8638e-01,  1.9629e-01, -1.6016e-01,  ...,  2.6993e-02,\n",
       "           1.7017e-01, -1.0522e-01],\n",
       "         ...,\n",
       "         [ 4.3457e-01, -1.6064e-01,  2.1777e-01,  ...,  7.3486e-02,\n",
       "          -2.4500e-01,  2.2827e-02],\n",
       "         [ 8.1360e-02,  3.6682e-02, -1.1883e-03,  ..., -8.8074e-02,\n",
       "          -5.0568e-02, -5.5603e-02],\n",
       "         [ 3.4475e-04,  4.4116e-01, -6.1188e-02,  ...,  6.7322e-02,\n",
       "           1.3672e-01, -5.3192e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_keys.bias': tensor([ 0.0274,  0.0169, -0.0277,  ..., -0.0282, -0.0058, -0.0312],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_values.weight': tensor([[ 0.0640, -0.0147, -0.0991,  ..., -0.4907, -0.1158,  0.0133],\n",
       "         [-0.0900, -0.2211, -0.1050,  ..., -0.0369,  0.0284, -0.0867],\n",
       "         [ 0.2096, -0.0718, -0.1810,  ..., -0.0245,  0.1345,  0.0412],\n",
       "         ...,\n",
       "         [-0.1543, -0.3372, -0.2124,  ...,  0.0370, -0.2200, -0.0192],\n",
       "         [-0.0036,  0.1351, -0.0414,  ..., -0.2722, -0.1978,  0.0154],\n",
       "         [-0.0208,  0.1348, -0.2732,  ...,  0.0633,  0.1826,  0.0693]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_values.bias': tensor([-0.0737,  0.0847,  0.0364,  ...,  0.0214,  0.0005, -0.0131],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_query.weight': tensor([[-0.4275,  0.0265,  0.0817,  ..., -0.0469,  0.2341,  0.2118],\n",
       "         [ 0.3743,  0.1727,  0.0540,  ..., -0.3494,  0.1705, -0.0107],\n",
       "         [-0.1183, -0.0934,  0.1401,  ..., -0.1702,  0.0417, -0.0448],\n",
       "         ...,\n",
       "         [ 0.1122,  0.2097,  0.0602,  ...,  0.1998, -0.2957,  0.0191],\n",
       "         [ 0.2045, -0.2030, -0.1022,  ..., -0.0297, -0.2910,  0.0159],\n",
       "         [-0.4851,  0.4463,  0.0319,  ...,  0.0139, -0.0826, -0.0349]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.linear_query.bias': tensor([-0.0117,  0.0652, -0.1204,  ...,  0.0750,  0.0415, -0.0578],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.final_linear.weight': tensor([[-5.6915e-02,  1.0187e-01, -2.7832e-01,  ...,  2.2229e-01,\n",
       "          -3.0542e-01, -7.3204e-03],\n",
       "         [ 7.6111e-02,  1.6968e-01, -1.3794e-01,  ..., -8.0750e-02,\n",
       "          -4.1077e-02,  4.9683e-02],\n",
       "         [-4.5776e-02, -2.0325e-01, -1.5405e-01,  ..., -2.6611e-01,\n",
       "           2.3071e-01, -2.0093e-01],\n",
       "         ...,\n",
       "         [ 3.4741e-01,  2.8296e-01,  3.5187e-02,  ...,  3.4546e-02,\n",
       "           7.2754e-02,  1.6708e-02],\n",
       "         [-2.9907e-01,  3.6499e-02, -2.6807e-01,  ..., -3.5181e-01,\n",
       "          -2.1741e-01, -3.6224e-02],\n",
       "         [-2.3279e-01,  3.2013e-02,  2.1243e-04,  ..., -2.9346e-01,\n",
       "           4.3140e-01,  1.1359e-01]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.context_attn.final_linear.bias': tensor([-0.1670,  0.2517,  0.0768,  ..., -0.3137, -0.0340, -0.1135],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_2.weight': tensor([0.1266, 0.1838, 0.1929,  ..., 0.1061, 0.0986, 0.1010],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.layer_norm_2.bias': tensor([-0.0076, -0.0356, -0.0011,  ..., -0.0028, -0.0035, -0.0181],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_1.weight': tensor([[-0.1963, -0.0854,  0.0271,  ..., -0.0640, -0.1954,  0.2534],\n",
       "         [-0.3438,  0.1814, -0.1447,  ..., -0.3826, -0.0184, -0.3777],\n",
       "         [ 0.0417,  0.0775,  0.2869,  ...,  0.1899,  0.0681, -0.3806],\n",
       "         ...,\n",
       "         [-0.2186, -0.0697, -0.2954,  ..., -0.0013, -0.0532, -0.4646],\n",
       "         [-0.1605,  0.4458,  0.0753,  ...,  0.0030, -0.1979,  0.0666],\n",
       "         [ 0.1459,  0.1836,  0.0529,  ...,  0.0804, -0.0881,  0.0609]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_1.bias': tensor([-0.1088, -0.2505, -0.1223,  ..., -0.2303, -0.1230, -0.0989],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_2.weight': tensor([[-0.1610, -0.3735, -0.0555,  ...,  0.2761, -0.0305, -0.1532],\n",
       "         [-0.0477, -0.2759,  0.1680,  ...,  0.0407, -0.1489, -0.1984],\n",
       "         [-0.0375, -0.1848, -0.0933,  ...,  0.1871,  0.2727, -0.1232],\n",
       "         ...,\n",
       "         [-0.0792, -0.1058, -0.3218,  ...,  0.0746,  0.1451,  0.1779],\n",
       "         [-0.0492, -0.1247,  0.2181,  ...,  0.3079, -0.0853,  0.2299],\n",
       "         [ 0.4763,  0.1882, -0.0437,  ..., -0.0560, -0.4338, -0.0142]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.w_2.bias': tensor([-0.1108, -0.2070, -0.0164,  ..., -0.2815, -0.0843, -0.2876],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.layer_norm.weight': tensor([0.3970, 0.4524, 0.4319,  ..., 0.3435, 0.3228, 0.3274],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.2.feed_forward.layer_norm.bias': tensor([-0.0156,  0.0081,  0.0066,  ...,  0.0600, -0.0039,  0.0792],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_keys.weight': tensor([[-0.0989,  0.3494,  0.1242,  ..., -0.0166, -0.2554, -0.0117],\n",
       "         [-0.0774, -0.2800,  0.0182,  ..., -0.2566, -0.0605, -0.3606],\n",
       "         [ 0.1135, -0.0656,  0.0745,  ...,  0.1853, -0.1089, -0.1870],\n",
       "         ...,\n",
       "         [-0.1294, -0.1048, -0.0658,  ...,  0.0122, -0.0033, -0.1639],\n",
       "         [-0.0522,  0.1150, -0.0699,  ..., -0.0789,  0.0958,  0.0314],\n",
       "         [-0.1689,  0.0449,  0.0771,  ..., -0.0376, -0.2283, -0.1467]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_keys.bias': tensor([-0.0116, -0.0057, -0.0070,  ...,  0.0291, -0.0091, -0.0291],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_values.weight': tensor([[-0.1167, -0.2267, -0.1385,  ..., -0.1125,  0.1224, -0.4749],\n",
       "         [-0.1150, -0.0827, -0.2052,  ...,  0.1290, -0.1851,  0.3667],\n",
       "         [ 0.0052,  0.1235,  0.1295,  ..., -0.2764,  0.4204,  0.4370],\n",
       "         ...,\n",
       "         [ 0.3010, -0.2048, -0.3379,  ..., -0.2324,  0.0846,  0.2581],\n",
       "         [-0.4292, -0.1766,  0.1385,  ...,  0.1300,  0.1146,  0.2145],\n",
       "         [ 0.2388, -0.5005, -0.0915,  ..., -0.0520, -0.3730,  0.1678]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_values.bias': tensor([-0.0255,  0.0488,  0.0688,  ...,  0.0421, -0.0326,  0.0906],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_query.weight': tensor([[ 0.2737, -0.1266,  0.1499,  ...,  0.0596,  0.1345,  0.2371],\n",
       "         [-0.0415,  0.2070,  0.0330,  ..., -0.1792,  0.1012,  0.2859],\n",
       "         [-0.0612,  0.1016,  0.1646,  ..., -0.2700, -0.0338, -0.0159],\n",
       "         ...,\n",
       "         [ 0.1676, -0.0497,  0.4077,  ..., -0.0945,  0.0942, -0.0088],\n",
       "         [-0.1548, -0.1628, -0.3193,  ...,  0.2554, -0.0501,  0.0714],\n",
       "         [ 0.2166,  0.1407, -0.0704,  ...,  0.0569,  0.3152, -0.0768]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.linear_query.bias': tensor([ 0.0457,  0.1059,  0.3831,  ...,  0.3333,  0.0374, -0.0630],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.final_linear.weight': tensor([[-0.1353, -0.2498,  0.0072,  ...,  0.0026,  0.3059,  0.0142],\n",
       "         [ 0.0606, -0.2023,  0.1234,  ...,  0.5112, -0.1735,  0.4958],\n",
       "         [ 0.0301,  0.1292,  0.4243,  ..., -0.1786, -0.1874,  0.2764],\n",
       "         ...,\n",
       "         [ 0.1820,  0.1312,  0.3752,  ..., -0.4602,  0.6631, -0.1891],\n",
       "         [ 0.1621, -0.3711,  0.2749,  ...,  0.4641,  0.3682, -0.2791],\n",
       "         [-0.3870,  0.2444,  0.1794,  ..., -0.2311,  0.4253, -0.3052]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.self_attn.final_linear.bias': tensor([-0.3191, -0.0130, -0.3569,  ..., -0.4990, -0.2812,  0.3171],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_1.weight': tensor([0.2649, 0.2991, 0.3367,  ..., 0.1940, 0.2025, 0.2090],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_1.bias': tensor([ 0.0098,  0.0048,  0.0200,  ..., -0.0096,  0.0063, -0.0139],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_keys.weight': tensor([[-0.1865, -0.0974,  0.1832,  ..., -0.2744, -0.0507, -0.1809],\n",
       "         [ 0.3071, -0.1432,  0.2676,  ...,  0.0955, -0.1697,  0.0543],\n",
       "         [ 0.0473,  0.2034,  0.2032,  ..., -0.0693, -0.2028,  0.1306],\n",
       "         ...,\n",
       "         [-0.2595,  0.1549, -0.1284,  ..., -0.0772, -0.1320,  0.1205],\n",
       "         [-0.1119,  0.0875,  0.0643,  ...,  0.0091, -0.0217, -0.0189],\n",
       "         [ 0.0364,  0.2268,  0.0769,  ..., -0.1428,  0.0320,  0.0672]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_keys.bias': tensor([-0.0310,  0.0280,  0.0024,  ...,  0.0099, -0.0284, -0.0260],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_values.weight': tensor([[ 2.4078e-02,  2.6733e-01,  2.0782e-02,  ...,  1.9263e-01,\n",
       "           1.7105e-02,  2.2621e-03],\n",
       "         [ 1.1975e-01,  6.5063e-02, -1.6510e-02,  ..., -3.9642e-02,\n",
       "           1.5393e-01,  4.3671e-02],\n",
       "         [ 2.0248e-02,  1.1452e-02,  8.4961e-02,  ..., -2.9495e-02,\n",
       "          -1.4844e-01,  1.0025e-02],\n",
       "         ...,\n",
       "         [ 2.6025e-01,  3.3112e-02,  6.1096e-02,  ...,  1.0437e-01,\n",
       "           3.6987e-01, -4.9896e-03],\n",
       "         [-7.1680e-01, -2.0828e-02, -1.8994e-01,  ...,  4.0741e-02,\n",
       "           2.2595e-01,  1.6713e-04],\n",
       "         [ 2.0004e-02,  2.5366e-01,  2.1960e-01,  ..., -1.0065e-01,\n",
       "           6.7871e-02,  1.7929e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_values.bias': tensor([-0.0029,  0.0220, -0.1296,  ...,  0.0403,  0.0458,  0.0118],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_query.weight': tensor([[-0.0173,  0.0173,  0.1548,  ...,  0.4448,  0.2622, -0.3184],\n",
       "         [ 0.0507,  0.5000,  0.1766,  ...,  0.2209, -0.3264, -0.1075],\n",
       "         [ 0.0124, -0.0648,  0.1494,  ..., -0.2532,  0.1809, -0.1466],\n",
       "         ...,\n",
       "         [ 0.2498, -0.0932, -0.2915,  ..., -0.2399, -0.0685,  0.0255],\n",
       "         [ 0.0212,  0.2756,  0.0865,  ...,  0.0206, -0.1403,  0.0765],\n",
       "         [ 0.0407,  0.2849, -0.2264,  ..., -0.1996,  0.0529,  0.0208]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.linear_query.bias': tensor([-0.1206,  0.1025,  0.0757,  ..., -0.0092, -0.0883, -0.1151],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.final_linear.weight': tensor([[ 0.0876, -0.1027,  0.1193,  ...,  0.2145,  0.0585, -0.1265],\n",
       "         [ 0.0244,  0.0413, -0.1685,  ...,  0.0888,  0.1541, -0.0012],\n",
       "         [-0.1416, -0.0668, -0.3159,  ..., -0.0815,  0.0106, -0.0503],\n",
       "         ...,\n",
       "         [ 0.0349, -0.1460, -0.0229,  ...,  0.1868, -0.0360,  0.0837],\n",
       "         [ 0.1722,  0.0825, -0.0028,  ...,  0.3721,  0.1023,  0.1249],\n",
       "         [-0.0881,  0.0850, -0.1405,  ..., -0.2732,  0.2292, -0.1927]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.context_attn.final_linear.bias': tensor([ 0.1139,  0.2313,  0.3328,  ...,  0.1598,  0.1838, -0.0592],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_2.weight': tensor([0.1249, 0.1664, 0.1544,  ..., 0.0951, 0.1037, 0.1024],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.layer_norm_2.bias': tensor([-0.0096, -0.0279, -0.0147,  ..., -0.0196,  0.0010, -0.0201],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_1.weight': tensor([[ 0.2854, -0.1564,  0.2632,  ...,  0.3538,  0.1858, -0.2240],\n",
       "         [ 0.1320, -0.0382,  0.1373,  ...,  0.0072, -0.1225,  0.2688],\n",
       "         [-0.0849, -0.1731,  0.4026,  ..., -0.0120,  0.2983, -0.0650],\n",
       "         ...,\n",
       "         [-0.2664, -0.1324,  0.2439,  ...,  0.1598,  0.0373,  0.1060],\n",
       "         [-0.0652,  0.0218,  0.0721,  ..., -0.0628, -0.5562, -0.1991],\n",
       "         [ 0.0721,  0.0939, -0.2037,  ..., -0.0305, -0.1075, -0.0715]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_1.bias': tensor([-0.1403, -0.0063, -0.0494,  ...,  0.0057, -0.2385, -0.1196],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_2.weight': tensor([[-3.0322e-01, -6.6833e-02,  1.0114e-01,  ..., -5.2452e-04,\n",
       "           4.5197e-02,  2.4658e-02],\n",
       "         [ 7.6111e-02, -1.4819e-01,  2.0898e-01,  ..., -1.3293e-01,\n",
       "           1.6663e-02,  5.0812e-02],\n",
       "         [ 1.4941e-01, -1.0266e-01, -1.2354e-01,  ..., -6.5327e-04,\n",
       "          -8.2458e-02, -1.0616e-04],\n",
       "         ...,\n",
       "         [ 8.2153e-02,  1.2646e-01, -1.3855e-01,  ...,  7.0679e-02,\n",
       "          -1.0352e-01, -8.3435e-02],\n",
       "         [-2.7199e-03,  3.4009e-01, -2.1057e-01,  ..., -4.7485e-01,\n",
       "           7.7454e-02, -3.9380e-01],\n",
       "         [ 2.1704e-01,  3.9139e-03,  8.0872e-02,  ..., -1.1017e-01,\n",
       "          -1.6699e-01, -2.3010e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.w_2.bias': tensor([-0.1926, -0.1788,  0.1004,  ..., -0.1218,  0.0177, -0.1982],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.layer_norm.weight': tensor([0.4517, 0.4846, 0.4919,  ..., 0.3994, 0.3762, 0.3960],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.3.feed_forward.layer_norm.bias': tensor([0.0141, 0.0581, 0.0347,  ..., 0.0001, 0.0165, 0.0414],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_keys.weight': tensor([[ 0.2207,  0.1823, -0.0239,  ..., -0.0892, -0.2250, -0.0438],\n",
       "         [-0.1675,  0.0461, -0.2908,  ..., -0.0573,  0.2861, -0.1185],\n",
       "         [-0.2162,  0.2639,  0.0948,  ...,  0.0665,  0.1389,  0.2520],\n",
       "         ...,\n",
       "         [-0.0280, -0.0919,  0.0092,  ...,  0.2295, -0.2079,  0.0559],\n",
       "         [ 0.1720,  0.1978, -0.1338,  ..., -0.3010,  0.5542,  0.1371],\n",
       "         [ 0.1345,  0.1317, -0.1661,  ...,  0.0614, -0.0829, -0.2491]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_keys.bias': tensor([ 0.0078,  0.0124, -0.0312,  ..., -0.0085, -0.0288, -0.0269],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_values.weight': tensor([[-0.2673,  0.0440,  0.2004,  ...,  0.0255, -0.0587,  0.0551],\n",
       "         [ 0.0173, -0.0415, -0.1914,  ...,  0.2194, -0.2268,  0.0632],\n",
       "         [-0.3674, -0.1038,  0.1384,  ...,  0.1515,  0.1569, -0.2007],\n",
       "         ...,\n",
       "         [ 0.0292,  0.3396, -0.3240,  ...,  0.2029,  0.3286,  0.3315],\n",
       "         [ 0.1886, -0.2532,  0.0946,  ..., -0.0008,  0.2737,  0.4102],\n",
       "         [ 0.4709, -0.1427, -0.1335,  ..., -0.3120, -0.1081,  0.0392]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_values.bias': tensor([ 0.0049,  0.0786,  0.0156,  ..., -0.0225, -0.0117, -0.1213],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_query.weight': tensor([[-0.1050, -0.0892, -0.0248,  ..., -0.2117,  0.2351, -0.1338],\n",
       "         [-0.0142, -0.0568, -0.2524,  ...,  0.1010, -0.2367,  0.1089],\n",
       "         [ 0.0411, -0.0777,  0.0359,  ..., -0.0947,  0.0923,  0.1312],\n",
       "         ...,\n",
       "         [-0.0166,  0.0511, -0.0418,  ...,  0.2347,  0.0373,  0.0219],\n",
       "         [-0.3071, -0.1300,  0.0977,  ..., -0.3276, -0.2328, -0.2103],\n",
       "         [-0.0814, -0.2233,  0.1093,  ..., -0.1879, -0.1793, -0.1509]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.linear_query.bias': tensor([-0.1097, -0.2244,  0.1980,  ..., -0.0424,  0.0051, -0.0490],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.final_linear.weight': tensor([[-0.2305, -0.0163,  0.1232,  ...,  0.3679,  0.2944, -0.0201],\n",
       "         [ 0.2825, -0.3196,  0.0299,  ...,  0.3411,  0.2332, -0.2466],\n",
       "         [ 0.1153, -0.1301, -0.1711,  ...,  0.0217, -0.2856, -0.2861],\n",
       "         ...,\n",
       "         [-0.2355,  0.1714,  0.0613,  ..., -0.0398, -0.2347,  0.0804],\n",
       "         [ 0.1771, -0.1948,  0.1324,  ...,  0.2856, -0.0511, -0.0304],\n",
       "         [ 0.0372,  0.3025, -0.4363,  ...,  0.2578, -0.0452, -0.1451]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.self_attn.final_linear.bias': tensor([-0.2571, -0.0980, -0.3325,  ..., -0.5020, -0.4917,  0.4910],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_1.weight': tensor([0.2859, 0.3113, 0.3257,  ..., 0.2101, 0.2292, 0.2230],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_1.bias': tensor([ 0.0132,  0.0039,  0.0213,  ..., -0.0128,  0.0103, -0.0153],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_keys.weight': tensor([[-0.3931,  0.0401,  0.1293,  ..., -0.1195, -0.0222,  0.0602],\n",
       "         [ 0.2490, -0.2781, -0.0809,  ..., -0.0480,  0.1019, -0.0571],\n",
       "         [-0.1403,  0.0654, -0.0033,  ...,  0.0448,  0.0354,  0.1317],\n",
       "         ...,\n",
       "         [-0.1971, -0.1921, -0.2170,  ...,  0.2629,  0.1705, -0.0448],\n",
       "         [ 0.0312, -0.1581,  0.1361,  ..., -0.0624, -0.0419,  0.0023],\n",
       "         [-0.0662,  0.0148, -0.1705,  ..., -0.0999, -0.0140, -0.0345]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_keys.bias': tensor([ 0.0095,  0.0270,  0.0019,  ...,  0.0180, -0.0116,  0.0144],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_values.weight': tensor([[ 0.0465,  0.1771, -0.3411,  ..., -0.0360, -0.1864,  0.0047],\n",
       "         [ 0.0253, -0.0935,  0.0439,  ...,  0.2808,  0.1083, -0.0020],\n",
       "         [ 0.0543, -0.3330, -0.0420,  ..., -0.2228,  0.1534,  0.0454],\n",
       "         ...,\n",
       "         [-0.1678, -0.2131, -0.0310,  ..., -0.1007,  0.1016, -0.0550],\n",
       "         [-0.1109,  0.0102,  0.1556,  ...,  0.1377, -0.0242,  0.0895],\n",
       "         [ 0.0603,  0.3479,  0.2795,  ...,  0.0861, -0.2308, -0.0095]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_values.bias': tensor([-0.0964, -0.0339,  0.0177,  ..., -0.0941, -0.0497, -0.0724],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_query.weight': tensor([[-0.1450, -0.3315, -0.1952,  ...,  0.0352,  0.0111,  0.0752],\n",
       "         [-0.0774, -0.0184, -0.0053,  ...,  0.1453,  0.0826,  0.3909],\n",
       "         [-0.2399, -0.0374, -0.0986,  ..., -0.2700,  0.3972,  0.3582],\n",
       "         ...,\n",
       "         [-0.0827, -0.0493, -0.0366,  ...,  0.0909, -0.2639,  0.0032],\n",
       "         [ 0.1049,  0.1342,  0.3726,  ..., -0.0033,  0.0166,  0.1332],\n",
       "         [-0.2563, -0.3057, -0.1438,  ..., -0.1454, -0.0888, -0.0361]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.linear_query.bias': tensor([ 0.0404,  0.1339, -0.0085,  ...,  0.1522,  0.0819,  0.0841],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.final_linear.weight': tensor([[ 0.0031, -0.0746,  0.2087,  ..., -0.1304, -0.2308, -0.2993],\n",
       "         [-0.0189, -0.2008, -0.2449,  ..., -0.1711, -0.0311,  0.1272],\n",
       "         [-0.2607,  0.1437, -0.4104,  ...,  0.0939, -0.0751,  0.2810],\n",
       "         ...,\n",
       "         [ 0.0663, -0.4783,  0.0988,  ..., -0.0980,  0.1279, -0.1688],\n",
       "         [-0.1671, -0.1387,  0.1354,  ..., -0.2666, -0.3020, -0.0603],\n",
       "         [ 0.0801, -0.0495,  0.4460,  ...,  0.1710, -0.0508, -0.0991]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.context_attn.final_linear.bias': tensor([ 0.1298,  0.2185,  0.3086,  ...,  0.0321, -0.1702, -0.3853],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_2.weight': tensor([0.1193, 0.1481, 0.1348,  ..., 0.0941, 0.1001, 0.0947],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.layer_norm_2.bias': tensor([-0.0073, -0.0116, -0.0107,  ..., -0.0408, -0.0026, -0.0193],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_1.weight': tensor([[-0.4097, -0.2700,  0.0737,  ...,  0.0936,  0.0958,  0.2720],\n",
       "         [ 0.0781, -0.1074,  0.0117,  ...,  0.2820,  0.2788, -0.1580],\n",
       "         [-0.2754, -0.2556,  0.0128,  ...,  0.2820,  0.0628,  0.0275],\n",
       "         ...,\n",
       "         [ 0.1747,  0.2019,  0.3281,  ...,  0.3142,  0.0674,  0.1089],\n",
       "         [-0.1899, -0.1687,  0.3840,  ..., -0.1477, -0.3643,  0.2465],\n",
       "         [ 0.4243,  0.2018, -0.3101,  ...,  0.2864, -0.1592,  0.0157]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_1.bias': tensor([-0.2307,  0.0841, -0.3652,  ..., -0.2961, -0.1600, -0.1461],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_2.weight': tensor([[-0.0831, -0.1288,  0.0689,  ..., -0.2583, -0.0450,  0.1154],\n",
       "         [-0.3525, -0.0558, -0.0667,  ..., -0.2041,  0.1604, -0.0671],\n",
       "         [-0.1544, -0.0462, -0.3406,  ...,  0.0112,  0.2053,  0.0386],\n",
       "         ...,\n",
       "         [ 0.2124, -0.1754, -0.0749,  ...,  0.2812,  0.3555,  0.1595],\n",
       "         [-0.0262, -0.1567,  0.1155,  ...,  0.2015, -0.0365,  0.1342],\n",
       "         [ 0.1613,  0.0448,  0.0573,  ...,  0.3638, -0.1046,  0.0436]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.w_2.bias': tensor([-0.1475, -0.1466,  0.2227,  ..., -0.0585,  0.1493,  0.0556],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.layer_norm.weight': tensor([0.5186, 0.5400, 0.5186,  ..., 0.4551, 0.4565, 0.4644],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.4.feed_forward.layer_norm.bias': tensor([ 0.0312,  0.1107,  0.0245,  ..., -0.1113, -0.0250,  0.0216],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_keys.weight': tensor([[-6.5857e-02,  2.0251e-01, -5.7465e-02,  ...,  4.4647e-02,\n",
       "          -1.0632e-01,  7.2449e-02],\n",
       "         [ 1.3733e-02, -1.0150e-01, -2.9434e-02,  ...,  1.1426e-01,\n",
       "           1.4832e-01,  8.0338e-03],\n",
       "         [ 1.1176e-01, -4.4739e-02, -8.9355e-02,  ..., -5.9605e-06,\n",
       "          -1.0858e-01, -2.6672e-02],\n",
       "         ...,\n",
       "         [-2.2217e-01, -1.2128e-01, -5.0537e-02,  ...,  1.6589e-01,\n",
       "          -1.8567e-01, -5.2338e-02],\n",
       "         [ 5.4565e-02,  7.6027e-03, -1.1421e-02,  ..., -1.1682e-01,\n",
       "           5.4169e-02,  2.6636e-01],\n",
       "         [-1.3696e-01, -3.6450e-01,  2.5366e-01,  ..., -3.2410e-02,\n",
       "          -1.6187e-01,  9.6558e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_keys.bias': tensor([-0.0155,  0.0081, -0.0183,  ..., -0.0101, -0.0080,  0.0053],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_values.weight': tensor([[ 0.3101, -0.0659, -0.4985,  ..., -0.0261,  0.1904, -0.0820],\n",
       "         [ 0.1340, -0.1665, -0.0553,  ..., -0.0634,  0.3303, -0.4929],\n",
       "         [-0.5005, -0.4053,  0.0614,  ...,  0.1809, -0.4783,  0.2988],\n",
       "         ...,\n",
       "         [-0.0119, -0.3416, -0.1237,  ...,  0.0163, -0.1481, -0.0235],\n",
       "         [-0.2915,  0.0356, -0.1187,  ..., -0.1050, -0.2200,  0.3716],\n",
       "         [-0.2551,  0.0391,  0.1863,  ..., -0.0909, -0.0381,  0.0756]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_values.bias': tensor([-0.0251, -0.0740,  0.1063,  ..., -0.0436,  0.0135,  0.0956],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_query.weight': tensor([[-0.0420, -0.3079, -0.0490,  ...,  0.1382,  0.0266,  0.1229],\n",
       "         [-0.0640,  0.0458,  0.1144,  ...,  0.1064, -0.1210, -0.0217],\n",
       "         [ 0.1219, -0.0167,  0.0353,  ..., -0.0523, -0.1027,  0.1458],\n",
       "         ...,\n",
       "         [ 0.3435, -0.0014,  0.2062,  ...,  0.0873, -0.1273, -0.0268],\n",
       "         [-0.1941,  0.1359, -0.2434,  ...,  0.2717,  0.1084,  0.2108],\n",
       "         [-0.1007,  0.1511, -0.1353,  ...,  0.1998, -0.2651, -0.3638]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.linear_query.bias': tensor([-0.0583, -0.0863,  0.0507,  ..., -0.0739,  0.1298,  0.1917],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.final_linear.weight': tensor([[ 0.2006, -0.1216,  0.1897,  ...,  0.0042,  0.0221, -0.0220],\n",
       "         [-0.2788,  0.2749,  0.3147,  ..., -0.3538, -0.1953,  0.1487],\n",
       "         [-0.1451,  0.3015, -0.4993,  ..., -0.1499,  0.0264, -0.0385],\n",
       "         ...,\n",
       "         [-0.3020,  0.2366, -0.0396,  ..., -0.0085, -0.3369, -0.0049],\n",
       "         [ 0.2009, -0.1084, -0.2537,  ..., -0.3242, -0.2581,  0.1196],\n",
       "         [ 0.4978, -0.2510,  0.3047,  ..., -0.0637,  0.0760, -0.1024]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.self_attn.final_linear.bias': tensor([-0.2795,  0.4678, -0.2693,  ..., -0.4160, -0.0284,  0.2915],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_1.weight': tensor([0.2969, 0.3320, 0.3101,  ..., 0.2297, 0.2537, 0.2499],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_1.bias': tensor([ 0.0145,  0.0063,  0.0268,  ..., -0.0158,  0.0065, -0.0284],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_keys.weight': tensor([[ 0.0375, -0.0067,  0.0670,  ..., -0.3262, -0.0666,  0.0624],\n",
       "         [-0.0308,  0.0286, -0.1774,  ..., -0.1131, -0.0634,  0.1097],\n",
       "         [-0.0727,  0.0724, -0.2861,  ...,  0.2018,  0.0775, -0.0070],\n",
       "         ...,\n",
       "         [-0.1735, -0.0476, -0.1813,  ..., -0.2632, -0.2131, -0.0457],\n",
       "         [ 0.2214, -0.1711,  0.0067,  ..., -0.3740,  0.2871, -0.0119],\n",
       "         [-0.2520, -0.1650,  0.0536,  ..., -0.2666, -0.4377,  0.1949]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_keys.bias': tensor([ 0.0144, -0.0133,  0.0258,  ...,  0.0226, -0.0057, -0.0240],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_values.weight': tensor([[ 0.1630, -0.0317,  0.1660,  ..., -0.4785, -0.2400, -0.0245],\n",
       "         [ 0.0836, -0.0155,  0.2700,  ...,  0.0586, -0.1124,  0.0049],\n",
       "         [-0.0585,  0.0667, -0.0399,  ..., -0.2175, -0.0422, -0.0768],\n",
       "         ...,\n",
       "         [ 0.2810,  0.2720, -0.0113,  ..., -0.2407, -0.2625,  0.0165],\n",
       "         [ 0.1631,  0.1704,  0.0071,  ..., -0.2157, -0.0864,  0.0110],\n",
       "         [ 0.0294,  0.1296,  0.1190,  ...,  0.1326, -0.0536,  0.0583]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_values.bias': tensor([ 0.0158, -0.1880,  0.0825,  ..., -0.0160, -0.0419, -0.0264],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_query.weight': tensor([[ 0.0022,  0.1277, -0.0131,  ...,  0.0833, -0.0323, -0.1841],\n",
       "         [ 0.1743,  0.0327, -0.2566,  ..., -0.0372, -0.0149,  0.1061],\n",
       "         [ 0.2786,  0.0632,  0.1578,  ...,  0.1000,  0.0400,  0.3135],\n",
       "         ...,\n",
       "         [-0.1490, -0.1283, -0.1852,  ...,  0.0140, -0.1982,  0.0712],\n",
       "         [-0.0038,  0.1048, -0.1748,  ...,  0.1429,  0.2014, -0.0426],\n",
       "         [ 0.2123,  0.0413, -0.0383,  ...,  0.0410, -0.1842,  0.3259]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.linear_query.bias': tensor([-0.0406, -0.0256,  0.0312,  ..., -0.0875,  0.0524,  0.0250],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.final_linear.weight': tensor([[ 0.0500, -0.2297, -0.2686,  ...,  0.1371, -0.0784,  0.0501],\n",
       "         [ 0.3943,  0.1156,  0.1155,  ...,  0.1086, -0.0457,  0.1461],\n",
       "         [-0.0682, -0.1912, -0.1614,  ...,  0.2607,  0.1146, -0.2332],\n",
       "         ...,\n",
       "         [-0.2773, -0.2771,  0.3865,  ..., -0.0358,  0.0470, -0.2032],\n",
       "         [-0.0219,  0.0157, -0.1818,  ..., -0.1792, -0.1313,  0.1989],\n",
       "         [ 0.0125,  0.2400, -0.2211,  ..., -0.0269, -0.1218, -0.4712]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.context_attn.final_linear.bias': tensor([ 0.1956,  0.0657,  0.3936,  ...,  0.0127, -0.3669, -0.3601],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_2.weight': tensor([0.1075, 0.1220, 0.1219,  ..., 0.0916, 0.0882, 0.0904],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.layer_norm_2.bias': tensor([-0.0060, -0.0189, -0.0099,  ..., -0.0571, -0.0138, -0.0278],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_1.weight': tensor([[ 0.0246, -0.1316,  0.0693,  ...,  0.0710,  0.0610, -0.1390],\n",
       "         [-0.0105,  0.1313, -0.1672,  ...,  0.0849,  0.3064, -0.0118],\n",
       "         [-0.0682,  0.0808,  0.1024,  ..., -0.0484,  0.1665,  0.0039],\n",
       "         ...,\n",
       "         [ 0.3459,  0.1885,  0.3340,  ...,  0.1039, -0.0782, -0.0128],\n",
       "         [ 0.0859, -0.0403,  0.0482,  ..., -0.0431,  0.1514,  0.0355],\n",
       "         [ 0.1876,  0.1115, -0.5215,  ..., -0.3174, -0.3076,  0.0912]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_1.bias': tensor([-0.1182, -0.0240, -0.1111,  ..., -0.0903,  0.0151, -0.2751],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_2.weight': tensor([[-0.0988, -0.2712,  0.0759,  ..., -0.0606,  0.0951,  0.0548],\n",
       "         [-0.0896,  0.0380, -0.1500,  ...,  0.1359,  0.1032, -0.2303],\n",
       "         [-0.2039,  0.2030, -0.0993,  ...,  0.0145, -0.0025,  0.0596],\n",
       "         ...,\n",
       "         [-0.2715,  0.0426,  0.1118,  ..., -0.2710,  0.0401,  0.3145],\n",
       "         [ 0.3484, -0.2305, -0.2507,  ...,  0.0446, -0.0930,  0.0582],\n",
       "         [ 0.0522,  0.2581,  0.1652,  ...,  0.1074, -0.0864,  0.0522]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.w_2.bias': tensor([-0.0361,  0.0535,  0.2190,  ..., -0.0262,  0.0795, -0.0141],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.layer_norm.weight': tensor([0.5527, 0.5947, 0.5669,  ..., 0.5171, 0.5190, 0.5498],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.5.feed_forward.layer_norm.bias': tensor([-0.0238,  0.1709,  0.0458,  ..., -0.1510, -0.0305, -0.0568],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_keys.weight': tensor([[ 0.0374,  0.2539,  0.0807,  ..., -0.2534, -0.1730,  0.1367],\n",
       "         [ 0.1406,  0.1671, -0.1053,  ..., -0.0083, -0.1061,  0.0356],\n",
       "         [ 0.1313,  0.2104,  0.0596,  ..., -0.2021,  0.1768,  0.1305],\n",
       "         ...,\n",
       "         [-0.0445,  0.3679,  0.3291,  ..., -0.1658,  0.0309,  0.0033],\n",
       "         [ 0.1257,  0.0351,  0.0739,  ..., -0.0812, -0.0751,  0.0815],\n",
       "         [-0.3774, -0.2363, -0.0306,  ...,  0.2869, -0.1887,  0.2236]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_keys.bias': tensor([-0.0245,  0.0265,  0.0033,  ...,  0.0219, -0.0003, -0.0004],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_values.weight': tensor([[ 0.1777,  0.1213, -0.0913,  ..., -0.0241, -0.2084,  0.0174],\n",
       "         [ 0.5625,  0.0407,  0.4060,  ...,  0.0525, -0.2460, -0.0887],\n",
       "         [-0.0046, -0.1355,  0.1956,  ..., -0.2605,  0.1372, -0.1455],\n",
       "         ...,\n",
       "         [ 0.3633, -0.1598,  0.4990,  ...,  0.0370, -0.4541,  0.3074],\n",
       "         [-0.6509,  0.4268,  0.5879,  ...,  0.2170, -0.2910,  0.5000],\n",
       "         [ 0.0174, -0.2291,  0.1272,  ...,  0.3635,  0.0128, -0.2561]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_values.bias': tensor([-0.0603,  0.0184,  0.1882,  ..., -0.0049,  0.0327, -0.1523],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_query.weight': tensor([[-0.0482, -0.3528, -0.1902,  ...,  0.0988,  0.0460,  0.0452],\n",
       "         [-0.0535, -0.1464,  0.1217,  ..., -0.1593, -0.1014,  0.0892],\n",
       "         [-0.0216, -0.0822,  0.0185,  ..., -0.0079,  0.3145,  0.1541],\n",
       "         ...,\n",
       "         [-0.1473,  0.0253, -0.0071,  ..., -0.0023, -0.0278, -0.0009],\n",
       "         [ 0.3037, -0.0680,  0.0512,  ..., -0.0131, -0.1829, -0.1847],\n",
       "         [-0.0150, -0.1372, -0.0367,  ...,  0.0043, -0.1564,  0.1874]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.linear_query.bias': tensor([-0.1130, -0.0684, -0.0753,  ..., -0.3828, -0.1595,  0.0504],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.final_linear.weight': tensor([[ 0.1996,  0.2776,  0.0723,  ...,  0.6182, -0.4133, -0.1593],\n",
       "         [-0.1759,  0.1315,  0.0181,  ...,  0.3464,  0.4951, -0.2612],\n",
       "         [-0.2367,  0.1771,  0.1803,  ..., -0.5269, -0.2527, -0.2202],\n",
       "         ...,\n",
       "         [ 0.0767, -0.0532, -0.1245,  ...,  0.1116,  0.5005, -0.0312],\n",
       "         [-0.0836,  0.0947,  0.0076,  ...,  0.2340, -0.0242, -0.0476],\n",
       "         [ 0.0997,  0.3879, -0.1774,  ...,  0.1447,  0.4998,  0.0815]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.self_attn.final_linear.bias': tensor([-0.2966,  0.2942, -0.3508,  ..., -0.3872,  0.0909,  0.3867],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_1.weight': tensor([0.3369, 0.3384, 0.3252,  ..., 0.2742, 0.3064, 0.2991],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_1.bias': tensor([ 0.0210,  0.0098,  0.0302,  ..., -0.0051,  0.0017, -0.0262],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_keys.weight': tensor([[ 0.3401,  0.1907,  0.0227,  ...,  0.1218, -0.2205, -0.1613],\n",
       "         [-0.1348,  0.0866,  0.0611,  ...,  0.0736,  0.0831, -0.0015],\n",
       "         [-0.2825,  0.1018,  0.0981,  ..., -0.0231,  0.2522, -0.1433],\n",
       "         ...,\n",
       "         [-0.0963,  0.3123, -0.3767,  ...,  0.2382, -0.0230,  0.0461],\n",
       "         [ 0.3325, -0.4280, -0.1127,  ..., -0.1572,  0.1757,  0.0476],\n",
       "         [ 0.1704,  0.1230, -0.1737,  ..., -0.1663, -0.2683, -0.0545]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_keys.bias': tensor([-0.0267, -0.0164,  0.0116,  ...,  0.0257, -0.0025,  0.0022],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_values.weight': tensor([[ 1.6235e-01, -8.6121e-02, -4.5074e-02,  ...,  1.9666e-01,\n",
       "          -3.8672e-01,  8.2092e-03],\n",
       "         [-2.8613e-01,  3.4271e-02, -4.3677e-01,  ..., -5.0964e-02,\n",
       "          -6.2012e-02,  7.8857e-02],\n",
       "         [-2.7466e-01, -2.5659e-01,  4.3921e-01,  ..., -4.0820e-01,\n",
       "          -3.2642e-01,  3.2349e-02],\n",
       "         ...,\n",
       "         [-4.6753e-02,  2.1582e-01,  1.4502e-01,  ...,  6.9336e-02,\n",
       "           6.7322e-02, -1.3863e-02],\n",
       "         [-7.0251e-02, -2.0645e-02, -1.1169e-01,  ...,  1.6626e-01,\n",
       "           8.9355e-02,  2.6276e-02],\n",
       "         [ 5.1416e-01, -5.3525e-05,  3.3600e-02,  ...,  2.0093e-01,\n",
       "           2.9614e-01,  3.6316e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_values.bias': tensor([-0.0952, -0.1188, -0.1442,  ..., -0.0037,  0.0580,  0.0503],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_query.weight': tensor([[ 0.2246, -0.0369, -0.0668,  ..., -0.2939, -0.1271,  0.0820],\n",
       "         [-0.2778, -0.0588,  0.1204,  ..., -0.2460,  0.1610, -0.0326],\n",
       "         [ 0.1885,  0.0735,  0.1874,  ..., -0.1624,  0.1464, -0.0825],\n",
       "         ...,\n",
       "         [-0.1677,  0.0193, -0.3943,  ...,  0.0600, -0.1323, -0.0068],\n",
       "         [-0.2080, -0.0361,  0.1622,  ..., -0.1429,  0.1573, -0.1770],\n",
       "         [-0.0502,  0.0901,  0.1974,  ...,  0.0373,  0.0597,  0.1471]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.linear_query.bias': tensor([-0.0816, -0.0087, -0.1379,  ...,  0.0420,  0.0195, -0.1461],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.final_linear.weight': tensor([[-0.0215, -0.2637, -0.1755,  ..., -0.4727, -0.0643,  0.0902],\n",
       "         [ 0.0960,  0.2106,  0.0665,  ...,  0.1514, -0.2832, -0.0386],\n",
       "         [ 0.2603, -0.0852,  0.4165,  ..., -0.0095, -0.2157, -0.1486],\n",
       "         ...,\n",
       "         [-0.0221,  0.1790, -0.2588,  ..., -0.1587, -0.1099, -0.0893],\n",
       "         [-0.1489,  0.0752,  0.2411,  ...,  0.0696, -0.1183, -0.0610],\n",
       "         [-0.1570, -0.2546, -0.0327,  ...,  0.0521, -0.1205,  0.4062]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.context_attn.final_linear.bias': tensor([ 0.4001,  0.2559,  0.4946,  ...,  0.2712, -0.3901, -0.4368],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_2.weight': tensor([0.1088, 0.1266, 0.1223,  ..., 0.0982, 0.0980, 0.0988],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.layer_norm_2.bias': tensor([-0.0053, -0.0124, -0.0187,  ..., -0.0555, -0.0078, -0.0295],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_1.weight': tensor([[-0.0851,  0.0754,  0.1345,  ...,  0.3159,  0.1464,  0.0422],\n",
       "         [ 0.2727,  0.1659, -0.0242,  ..., -0.1598, -0.0930,  0.0657],\n",
       "         [ 0.1584, -0.0405, -0.1112,  ..., -0.0997, -0.1469, -0.2573],\n",
       "         ...,\n",
       "         [ 0.2394, -0.2903, -0.0901,  ...,  0.3789,  0.2290, -0.3430],\n",
       "         [ 0.0126,  0.0057, -0.0182,  ...,  0.0438, -0.3665, -0.0600],\n",
       "         [-0.3196,  0.0820,  0.0243,  ...,  0.1395, -0.0446, -0.4631]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_1.bias': tensor([-0.1229, -0.1085, -0.0858,  ..., -0.3970, -0.1575,  0.0030],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_2.weight': tensor([[-0.1260, -0.0411, -0.0211,  ..., -0.1797,  0.1743,  0.2720],\n",
       "         [-0.2678,  0.2886,  0.2220,  ...,  0.0752,  0.0397,  0.1187],\n",
       "         [-0.2213, -0.2236, -0.0878,  ..., -0.0323, -0.0224, -0.0335],\n",
       "         ...,\n",
       "         [-0.1696,  0.0558,  0.2617,  ..., -0.2012, -0.1853, -0.0159],\n",
       "         [-0.1678, -0.0100, -0.1174,  ..., -0.1779,  0.0478,  0.1150],\n",
       "         [ 0.1125, -0.0822,  0.0068,  ..., -0.2668, -0.2499,  0.3943]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.w_2.bias': tensor([ 0.0576, -0.2017,  0.3735,  ..., -0.0267,  0.5044,  0.0363],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.layer_norm.weight': tensor([0.6333, 0.6772, 0.6577,  ..., 0.6431, 0.6191, 0.6387],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.6.feed_forward.layer_norm.bias': tensor([-0.0312,  0.2100,  0.0613,  ..., -0.2198, -0.0563,  0.0056],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_keys.weight': tensor([[-0.2045,  0.0935, -0.1895,  ..., -0.0121, -0.1221, -0.0599],\n",
       "         [-0.0090, -0.3213, -0.0044,  ..., -0.0103, -0.0870,  0.2140],\n",
       "         [-0.0508, -0.1552, -0.1685,  ..., -0.0257, -0.1137, -0.3550],\n",
       "         ...,\n",
       "         [ 0.0738,  0.0740, -0.0399,  ...,  0.0630,  0.0160, -0.0910],\n",
       "         [ 0.0360, -0.0048, -0.0846,  ..., -0.0117,  0.0858, -0.0630],\n",
       "         [-0.0284,  0.0037, -0.2744,  ..., -0.1581, -0.0492, -0.3699]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_keys.bias': tensor([ 0.0037,  0.0206,  0.0255,  ..., -0.0012, -0.0041, -0.0044],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_values.weight': tensor([[-0.0089,  0.4580,  0.1262,  ...,  0.0078,  0.3901, -0.1656],\n",
       "         [ 0.1880, -0.0881,  0.2271,  ..., -0.1149, -0.0731, -0.2908],\n",
       "         [-0.1429, -0.2030, -0.2288,  ..., -0.1512,  0.1527, -0.1395],\n",
       "         ...,\n",
       "         [ 0.1218,  0.2458, -0.0825,  ...,  0.2137,  0.2061, -0.0891],\n",
       "         [ 0.1573,  0.2622, -0.0113,  ...,  0.0221, -0.0740,  0.0135],\n",
       "         [-0.1108, -0.0303,  0.2396,  ..., -0.0332, -0.0999,  0.1989]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_values.bias': tensor([-0.0156,  0.0625,  0.0502,  ..., -0.3411,  0.2294,  0.1083],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_query.weight': tensor([[-0.1903, -0.0818,  0.0698,  ..., -0.1096, -0.1135, -0.2006],\n",
       "         [-0.1033,  0.3027,  0.1921,  ...,  0.1516, -0.0990,  0.0273],\n",
       "         [ 0.1155,  0.1646, -0.0541,  ..., -0.2522,  0.0373, -0.0517],\n",
       "         ...,\n",
       "         [-0.1730, -0.1442,  0.3608,  ...,  0.0540, -0.0877,  0.0861],\n",
       "         [ 0.1680,  0.1840, -0.1689,  ...,  0.0338,  0.0041,  0.0251],\n",
       "         [ 0.0446,  0.1721, -0.0281,  ...,  0.0358,  0.1898,  0.2507]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.linear_query.bias': tensor([ 0.0382, -0.0410, -0.0156,  ..., -0.2959, -0.1064, -0.0396],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.final_linear.weight': tensor([[-0.1278, -0.2954, -0.0012,  ...,  0.0865, -0.0617,  0.0590],\n",
       "         [-0.0119,  0.1688,  0.1304,  ...,  0.3594,  0.0177, -0.3987],\n",
       "         [-0.4302,  0.1376,  0.2698,  ...,  0.2532,  0.1486,  0.0579],\n",
       "         ...,\n",
       "         [ 0.1769,  0.1301,  0.2328,  ...,  0.0317, -0.1260, -0.1396],\n",
       "         [ 0.1765,  0.1703,  0.3884,  ...,  0.1753, -0.0198,  0.1588],\n",
       "         [-0.3267, -0.1447, -0.5879,  ..., -0.1171,  0.1121,  0.1244]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.self_attn.final_linear.bias': tensor([-0.1833,  0.3335, -0.2705,  ..., -0.1660, -0.0508,  0.5049],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_1.weight': tensor([0.3381, 0.3489, 0.3391,  ..., 0.2952, 0.3115, 0.3103],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_1.bias': tensor([ 0.0134,  0.0132,  0.0375,  ..., -0.0148,  0.0051, -0.0371],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_keys.weight': tensor([[-0.3711, -0.0614,  0.0996,  ..., -0.1182,  0.0873, -0.0322],\n",
       "         [-0.2235,  0.3223,  0.1847,  ..., -0.1969, -0.2405,  0.1166],\n",
       "         [-0.2136,  0.0717, -0.1069,  ...,  0.2681,  0.1412,  0.0034],\n",
       "         ...,\n",
       "         [-0.2046, -0.1971, -0.0922,  ..., -0.1748,  0.0704, -0.0338],\n",
       "         [-0.2839,  0.0338, -0.0923,  ..., -0.1671, -0.1193, -0.1566],\n",
       "         [ 0.1528,  0.1070,  0.4490,  ..., -0.1133,  0.0535, -0.0446]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_keys.bias': tensor([-0.0200, -0.0157, -0.0066,  ..., -0.0196,  0.0060, -0.0199],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_values.weight': tensor([[ 0.1058, -0.1161, -0.4517,  ..., -0.2382,  0.5146,  0.0323],\n",
       "         [-0.3267, -0.0266, -0.2542,  ...,  0.1765,  0.0455,  0.0431],\n",
       "         [-0.0636, -0.2844, -0.0081,  ...,  0.1559,  0.4092, -0.1288],\n",
       "         ...,\n",
       "         [ 0.1447,  0.1050,  0.2108,  ..., -0.6055,  0.3354, -0.0129],\n",
       "         [ 0.3230,  0.1869,  0.1417,  ...,  0.0695, -0.3398, -0.0172],\n",
       "         [ 0.1238, -0.2754,  0.4731,  ..., -0.1932, -0.1099, -0.0350]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_values.bias': tensor([-0.1930, -0.0421,  0.1481,  ..., -0.1722, -0.0246,  0.0468],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_query.weight': tensor([[-0.4705, -0.0850, -0.0084,  ..., -0.3408,  0.0473,  0.0865],\n",
       "         [ 0.1898,  0.0959,  0.1753,  ...,  0.1469, -0.1388,  0.1073],\n",
       "         [ 0.1635,  0.0573, -0.0794,  ..., -0.0566, -0.0975, -0.1176],\n",
       "         ...,\n",
       "         [ 0.0769, -0.1356, -0.0036,  ..., -0.0539,  0.0759, -0.1608],\n",
       "         [ 0.1654, -0.2303,  0.0085,  ..., -0.2002, -0.1268, -0.1071],\n",
       "         [-0.1133, -0.1595, -0.2695,  ..., -0.3528,  0.2029,  0.0522]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.linear_query.bias': tensor([-0.0659,  0.3047,  0.0176,  ..., -0.0298, -0.1838,  0.0766],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.final_linear.weight': tensor([[ 0.1005, -0.2866,  0.0150,  ...,  0.0687,  0.0201,  0.1119],\n",
       "         [-0.3127,  0.0046, -0.4910,  ...,  0.1282, -0.5044, -0.1580],\n",
       "         [-0.0880,  0.1805, -0.3584,  ...,  0.2240, -0.0374, -0.4968],\n",
       "         ...,\n",
       "         [-0.4656,  0.1459, -0.1335,  ..., -0.4026, -0.0428, -0.1377],\n",
       "         [ 0.1560,  0.2075,  0.0927,  ..., -0.0337,  0.0627,  0.0725],\n",
       "         [-0.0769,  0.4978,  0.0244,  ...,  0.6108, -0.0981,  0.1642]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.context_attn.final_linear.bias': tensor([ 0.1737,  0.0965,  0.4023,  ..., -0.2581, -0.4963, -0.3105],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_2.weight': tensor([0.1185, 0.1268, 0.1243,  ..., 0.0994, 0.1035, 0.1086],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.layer_norm_2.bias': tensor([-0.0175, -0.0222, -0.0108,  ..., -0.0543, -0.0084, -0.0273],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_1.weight': tensor([[ 0.0210, -0.0683,  0.2157,  ...,  0.0250,  0.3140,  0.4192],\n",
       "         [ 0.2238,  0.2529,  0.1068,  ...,  0.2678,  0.0637,  0.1896],\n",
       "         [ 0.4622,  0.0760,  0.2435,  ...,  0.1342,  0.2158, -0.1066],\n",
       "         ...,\n",
       "         [-0.0657,  0.0519, -0.1526,  ...,  0.2031,  0.1222, -0.0950],\n",
       "         [ 0.3167,  0.2002,  0.4006,  ...,  0.2532,  0.0899,  0.1620],\n",
       "         [ 0.0201, -0.0225, -0.0485,  ...,  0.0050, -0.2136, -0.0174]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_1.bias': tensor([-0.1454,  0.0207, -0.2444,  ..., -0.2520, -0.2686, -0.0136],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_2.weight': tensor([[ 0.0240,  0.0366, -0.3574,  ..., -0.0224, -0.1803, -0.0250],\n",
       "         [-0.1412, -0.0702, -0.0832,  ...,  0.1190,  0.1544, -0.0342],\n",
       "         [ 0.1305, -0.0353, -0.0725,  ..., -0.1155,  0.4028, -0.3269],\n",
       "         ...,\n",
       "         [-0.0705, -0.2150,  0.0446,  ...,  0.0066,  0.0831,  0.1426],\n",
       "         [-0.1654,  0.1814, -0.2573,  ..., -0.2487,  0.2815, -0.0829],\n",
       "         [-0.1708,  0.1843,  0.0834,  ...,  0.1592,  0.1464, -0.4170]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.w_2.bias': tensor([ 0.3928, -0.1920,  0.4954,  ..., -0.3877,  0.5059,  0.1106],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.layer_norm.weight': tensor([0.7974, 0.8071, 0.7432,  ..., 0.8247, 0.7603, 0.7881],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.7.feed_forward.layer_norm.bias': tensor([-0.1459,  0.1334,  0.0034,  ..., -0.1862, -0.0635, -0.1029],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_keys.weight': tensor([[-0.1423,  0.0493, -0.0364,  ..., -0.2412, -0.0038, -0.1906],\n",
       "         [-0.1034,  0.0400, -0.0563,  ...,  0.0095,  0.1847,  0.1011],\n",
       "         [ 0.0593, -0.0185, -0.1671,  ...,  0.0114, -0.2832, -0.0166],\n",
       "         ...,\n",
       "         [-0.0690, -0.1224,  0.2441,  ..., -0.0893,  0.0546,  0.2991],\n",
       "         [-0.0170, -0.0854,  0.1444,  ..., -0.0768,  0.1268,  0.1306],\n",
       "         [ 0.1249,  0.1434,  0.1725,  ..., -0.2191, -0.0253, -0.0129]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_keys.bias': tensor([-0.0060,  0.0152,  0.0233,  ..., -0.0166,  0.0221, -0.0134],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_values.weight': tensor([[ 0.1410,  0.1727, -0.0191,  ..., -0.1436,  0.0425,  0.3655],\n",
       "         [ 0.2812, -0.0403,  0.1802,  ..., -0.1816, -0.2754, -0.1415],\n",
       "         [ 0.1836,  0.2639, -0.3894,  ..., -0.3167,  0.1504, -0.4910],\n",
       "         ...,\n",
       "         [ 0.2883, -0.0306, -0.3403,  ...,  0.0630, -0.2426, -0.0954],\n",
       "         [-0.0223,  0.1888, -0.0462,  ..., -0.0820,  0.1877, -0.0966],\n",
       "         [-0.1565, -0.0103,  0.1691,  ..., -0.1262, -0.2935,  0.1974]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_values.bias': tensor([ 0.0117,  0.1648,  0.0165,  ..., -0.2168,  0.2529, -0.0457],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_query.weight': tensor([[ 0.0427, -0.1158, -0.1973,  ..., -0.0760,  0.0096,  0.0612],\n",
       "         [ 0.0319, -0.3293,  0.0804,  ...,  0.0157,  0.0489,  0.0158],\n",
       "         [ 0.1538,  0.0602,  0.1025,  ...,  0.0074, -0.0712, -0.3633],\n",
       "         ...,\n",
       "         [-0.0150, -0.0189,  0.0870,  ...,  0.0556,  0.0825,  0.0517],\n",
       "         [ 0.0912, -0.2279, -0.0597,  ...,  0.1247, -0.0776, -0.0311],\n",
       "         [ 0.0519,  0.0293, -0.0393,  ...,  0.1355,  0.0712, -0.2561]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.linear_query.bias': tensor([-0.1656, -0.0432, -0.0004,  ...,  0.0256, -0.1768, -0.0460],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.final_linear.weight': tensor([[ 0.4148,  0.2620,  0.1461,  ..., -0.2103, -0.0971, -0.0137],\n",
       "         [ 0.0315,  0.1788, -0.1793,  ...,  0.2517, -0.2411, -0.2437],\n",
       "         [ 0.2203, -0.0828, -0.3955,  ...,  0.0433, -0.3066, -0.2430],\n",
       "         ...,\n",
       "         [ 0.2292,  0.0508, -0.0446,  ..., -0.0126,  0.1786, -0.0538],\n",
       "         [-0.1774, -0.1196, -0.0755,  ...,  0.2372, -0.1290,  0.0710],\n",
       "         [-0.3435,  0.0744,  0.2435,  ...,  0.1345, -0.1583, -0.0632]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.self_attn.final_linear.bias': tensor([ 0.1243,  0.2539, -0.2976,  ...,  0.2218,  0.1137,  0.5005],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_1.weight': tensor([0.4102, 0.3804, 0.3806,  ..., 0.3447, 0.3757, 0.3708],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_1.bias': tensor([ 0.0182,  0.0095,  0.0290,  ..., -0.0136,  0.0106, -0.0280],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_keys.weight': tensor([[-0.1570, -0.1323,  0.1772,  ...,  0.0469, -0.0352,  0.0019],\n",
       "         [ 0.1349, -0.2822,  0.0867,  ...,  0.0389,  0.1478, -0.0174],\n",
       "         [ 0.3291,  0.3396, -0.0086,  ...,  0.1729, -0.1600, -0.0617],\n",
       "         ...,\n",
       "         [ 0.0868, -0.1453,  0.1772,  ...,  0.0400,  0.0132,  0.0280],\n",
       "         [ 0.2019, -0.1984, -0.2167,  ..., -0.0485,  0.0724,  0.0322],\n",
       "         [-0.0590, -0.1819,  0.2715,  ..., -0.0208,  0.1816,  0.0951]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_keys.bias': tensor([-0.0289,  0.0023, -0.0247,  ..., -0.0080, -0.0143, -0.0205],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_values.weight': tensor([[ 0.1135,  0.0676,  0.0016,  ...,  0.1982,  0.0425, -0.0825],\n",
       "         [ 0.2925, -0.0800, -0.0367,  ...,  0.3589,  0.2947,  0.0084],\n",
       "         [ 0.2712, -0.0820,  0.3889,  ..., -0.0808, -0.3374, -0.0158],\n",
       "         ...,\n",
       "         [ 0.2910,  0.1021, -0.0634,  ..., -0.1815,  0.0561,  0.0302],\n",
       "         [-0.0091,  0.0112,  0.0781,  ...,  0.1381, -0.3035, -0.0421],\n",
       "         [ 0.1682, -0.0823, -0.3062,  ..., -0.4304,  0.1691, -0.1249]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_values.bias': tensor([ 0.0173, -0.0172,  0.1008,  ..., -0.0360,  0.2008,  0.3875],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_query.weight': tensor([[-0.1891, -0.1931, -0.1881,  ..., -0.2788, -0.0663, -0.0147],\n",
       "         [ 0.1151, -0.2732, -0.0383,  ..., -0.3081, -0.1140,  0.0378],\n",
       "         [ 0.0862,  0.1174,  0.1058,  ...,  0.0028,  0.0516,  0.1337],\n",
       "         ...,\n",
       "         [ 0.1978, -0.2303,  0.2014,  ...,  0.0764, -0.0551, -0.0450],\n",
       "         [-0.0210,  0.0884,  0.1086,  ...,  0.0174, -0.0796,  0.1521],\n",
       "         [ 0.0110, -0.0436, -0.0723,  ..., -0.0287, -0.0842, -0.0739]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.linear_query.bias': tensor([ 0.0989,  0.0967, -0.0564,  ..., -0.0964, -0.0172,  0.1020],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.final_linear.weight': tensor([[-0.1542,  0.2229, -0.0826,  ..., -0.1195, -0.4167,  0.3042],\n",
       "         [ 0.1630, -0.0679,  0.4854,  ..., -0.0095,  0.1709,  0.2983],\n",
       "         [ 0.0172,  0.0249, -0.0252,  ..., -0.3215,  0.0625,  0.4380],\n",
       "         ...,\n",
       "         [-0.0400, -0.0425,  0.1798,  ...,  0.2079,  0.4265, -0.1339],\n",
       "         [-0.0088,  0.0418, -0.2290,  ..., -0.1038, -0.1912,  0.1637],\n",
       "         [-0.0147,  0.0756,  0.0246,  ..., -0.1266, -0.1960,  0.1256]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.context_attn.final_linear.bias': tensor([-0.3616,  0.0895, -0.0173,  ...,  0.2443, -0.3513, -0.4993],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_2.weight': tensor([0.1331, 0.1266, 0.1376,  ..., 0.1132, 0.1064, 0.1123],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.layer_norm_2.bias': tensor([-0.0070, -0.0088, -0.0046,  ..., -0.0548, -0.0182, -0.0306],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_1.weight': tensor([[-0.4417, -0.2146,  0.1429,  ..., -0.1768, -0.0359,  0.2349],\n",
       "         [-0.0397, -0.4207,  0.0406,  ...,  0.1848, -0.0008, -0.0076],\n",
       "         [ 0.1375, -0.1194,  0.0920,  ..., -0.1770,  0.4021, -0.0606],\n",
       "         ...,\n",
       "         [-0.0806, -0.1650,  0.2084,  ...,  0.1735,  0.2954, -0.1643],\n",
       "         [ 0.5210, -0.0171,  0.2417,  ...,  0.1959, -0.0807, -0.0129],\n",
       "         [-0.1121,  0.0619, -0.0764,  ..., -0.1229, -0.0679, -0.0245]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_1.bias': tensor([-0.1028, -0.3286, -0.2461,  ..., -0.3433, -0.4426, -0.0970],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_2.weight': tensor([[ 0.0093,  0.0911, -0.0565,  ..., -0.0317, -0.2344, -0.0305],\n",
       "         [-0.1876,  0.0094,  0.1968,  ..., -0.0558, -0.0459,  0.0405],\n",
       "         [ 0.0945, -0.0292,  0.0138,  ..., -0.2668,  0.0869,  0.0090],\n",
       "         ...,\n",
       "         [-0.2488,  0.2688,  0.2932,  ...,  0.2343, -0.2141, -0.0137],\n",
       "         [ 0.0183,  0.1749, -0.2096,  ...,  0.0723,  0.1492,  0.2289],\n",
       "         [ 0.0099, -0.0686,  0.1202,  ...,  0.0895,  0.4971,  0.1537]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.w_2.bias': tensor([ 0.5020, -0.3313,  0.4246,  ..., -0.5049,  0.5127, -0.2952],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.layer_norm.weight': tensor([1.0195, 1.0068, 0.9004,  ..., 1.0664, 0.9517, 1.0547],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.8.feed_forward.layer_norm.bias': tensor([-0.0638,  0.1104, -0.0249,  ..., -0.1152, -0.0183, -0.0844],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_keys.weight': tensor([[ 0.0412,  0.0670, -0.1750,  ...,  0.0121,  0.0238, -0.1610],\n",
       "         [-0.0029, -0.0763, -0.0480,  ..., -0.0039, -0.0032, -0.0043],\n",
       "         [-0.1422, -0.0167, -0.0263,  ..., -0.0453,  0.0587,  0.0488],\n",
       "         ...,\n",
       "         [-0.0135, -0.2300, -0.1558,  ...,  0.0684, -0.0237, -0.0024],\n",
       "         [ 0.0916, -0.0360,  0.0775,  ...,  0.0323,  0.3794,  0.0118],\n",
       "         [ 0.0227, -0.2444, -0.0505,  ...,  0.1031,  0.0501, -0.0388]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_keys.bias': tensor([ 0.0125, -0.0178, -0.0150,  ...,  0.0234, -0.0055, -0.0001],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_values.weight': tensor([[ 0.0773, -0.0530,  0.0605,  ..., -0.1372,  0.0030,  0.0672],\n",
       "         [ 0.2700,  0.0829, -0.3567,  ...,  0.2375, -0.0533,  0.0267],\n",
       "         [ 0.0301,  0.2338,  0.0894,  ..., -0.2131, -0.3374,  0.2045],\n",
       "         ...,\n",
       "         [-0.2666, -0.2839, -0.1636,  ...,  0.3601,  0.0040, -0.3984],\n",
       "         [-0.0587,  0.0031, -0.1780,  ...,  0.2126,  0.2250,  0.1445],\n",
       "         [-0.2861,  0.4861,  0.2120,  ..., -0.1197,  0.0020, -0.3445]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_values.bias': tensor([ 0.2822,  0.0126,  0.1081,  ..., -0.1305, -0.0354, -0.1240],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_query.weight': tensor([[ 0.0190,  0.2964, -0.2443,  ..., -0.0494,  0.1162, -0.1262],\n",
       "         [-0.0831,  0.1069, -0.2057,  ...,  0.0015, -0.0763, -0.0235],\n",
       "         [-0.0543, -0.1862, -0.0384,  ...,  0.0033,  0.2153,  0.0687],\n",
       "         ...,\n",
       "         [ 0.1157,  0.0988,  0.0569,  ...,  0.2520,  0.2612, -0.1421],\n",
       "         [ 0.1771, -0.0110, -0.0386,  ...,  0.0368, -0.1282,  0.1573],\n",
       "         [ 0.0934, -0.0471,  0.1450,  ...,  0.0489, -0.0100, -0.0621]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.linear_query.bias': tensor([ 0.0312, -0.0041,  0.0637,  ...,  0.0500,  0.0525, -0.0266],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.final_linear.weight': tensor([[ 0.0059,  0.2668,  0.2118,  ..., -0.2654, -0.0499,  0.2559],\n",
       "         [-0.2656,  0.0468, -0.2856,  ...,  0.0208, -0.1278, -0.0139],\n",
       "         [ 0.3335, -0.2891,  0.0821,  ...,  0.1823, -0.1914,  0.5107],\n",
       "         ...,\n",
       "         [ 0.3220, -0.3181,  0.3914,  ..., -0.2502, -0.1149, -0.1750],\n",
       "         [ 0.0428,  0.4807, -0.2045,  ..., -0.2837,  0.4756,  0.1137],\n",
       "         [ 0.2433,  0.1946,  0.1001,  ..., -0.3577,  0.1799,  0.0641]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.self_attn.final_linear.bias': tensor([ 0.1238, -0.4033, -0.2258,  ...,  0.2472,  0.3831,  0.5000],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_1.weight': tensor([0.4631, 0.4277, 0.4272,  ..., 0.4153, 0.4421, 0.4478],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_1.bias': tensor([ 0.0149,  0.0303,  0.0506,  ..., -0.0093,  0.0063, -0.0349],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_keys.weight': tensor([[ 0.0770,  0.0722,  0.1160,  ...,  0.3164,  0.0057, -0.0553],\n",
       "         [ 0.3330, -0.0047,  0.2705,  ..., -0.0791,  0.2482,  0.0441],\n",
       "         [-0.3704, -0.2062, -0.1801,  ..., -0.1881, -0.1003,  0.1001],\n",
       "         ...,\n",
       "         [-0.1610, -0.0007,  0.0804,  ..., -0.1913,  0.0624, -0.0886],\n",
       "         [ 0.3018,  0.2052, -0.0257,  ..., -0.0631,  0.1400,  0.0320],\n",
       "         [ 0.1862,  0.1296,  0.1224,  ..., -0.0197, -0.2944, -0.0590]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_keys.bias': tensor([-0.0226, -0.0145,  0.0011,  ...,  0.0308, -0.0099,  0.0002],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_values.weight': tensor([[-0.3394,  0.0433, -0.1200,  ...,  0.0173, -0.2808, -0.0782],\n",
       "         [-0.0045,  0.4124,  0.1859,  ..., -0.4805,  0.1549,  0.0018],\n",
       "         [-0.4233,  0.1075,  0.4949,  ...,  0.1077,  0.1019, -0.0264],\n",
       "         ...,\n",
       "         [ 0.2230, -0.0882, -0.2074,  ...,  0.0633,  0.1359, -0.0247],\n",
       "         [-0.5117,  0.3386,  0.1121,  ..., -0.0284, -0.0029, -0.0371],\n",
       "         [ 0.0726,  0.0780,  0.4983,  ...,  0.0255, -0.1683, -0.0468]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_values.bias': tensor([ 0.3779, -0.3152,  0.2307,  ...,  0.1636,  0.0676,  0.1646],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_query.weight': tensor([[ 0.2583,  0.1307,  0.1001,  ..., -0.1404,  0.1581, -0.2004],\n",
       "         [-0.3770,  0.1218, -0.2306,  ..., -0.0723, -0.1956, -0.0639],\n",
       "         [-0.0841, -0.5142, -0.1659,  ..., -0.0734, -0.1177,  0.3169],\n",
       "         ...,\n",
       "         [-0.2815,  0.1479,  0.0992,  ..., -0.1552, -0.0829, -0.0184],\n",
       "         [-0.2330, -0.3279,  0.1219,  ..., -0.0037,  0.1787, -0.1523],\n",
       "         [-0.0017,  0.0161,  0.3259,  ..., -0.0775,  0.1696,  0.1904]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.linear_query.bias': tensor([ 0.0332,  0.0112, -0.0296,  ...,  0.0381, -0.1301,  0.1093],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.final_linear.weight': tensor([[ 0.1061, -0.4470, -0.2705,  ...,  0.2384,  0.1384, -0.0640],\n",
       "         [-0.0952,  0.2932,  0.1537,  ..., -0.0050,  0.5049,  0.0322],\n",
       "         [-0.0566,  0.2688,  0.1437,  ...,  0.0014, -0.3093, -0.1046],\n",
       "         ...,\n",
       "         [ 0.1476, -0.1459,  0.0959,  ...,  0.0439,  0.0358,  0.0531],\n",
       "         [-0.2729,  0.0743, -0.1349,  ..., -0.3132, -0.3823,  0.0961],\n",
       "         [-0.0887,  0.0021,  0.0411,  ...,  0.0129,  0.2395, -0.0094]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.context_attn.final_linear.bias': tensor([-0.2170, -0.0152,  0.1914,  ...,  0.2715, -0.2610,  0.1967],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_2.weight': tensor([0.1378, 0.1429, 0.1512,  ..., 0.1249, 0.1181, 0.1212],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.layer_norm_2.bias': tensor([-0.0044, -0.0116, -0.0141,  ..., -0.0624, -0.0088, -0.0331],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_1.weight': tensor([[-0.1227, -0.1321,  0.0471,  ..., -0.0699,  0.3000,  0.0210],\n",
       "         [ 0.0005, -0.0152,  0.2771,  ...,  0.0279,  0.3499,  0.0677],\n",
       "         [ 0.1163, -0.1272,  0.0693,  ..., -0.0362, -0.1906, -0.1945],\n",
       "         ...,\n",
       "         [ 0.0235,  0.0792, -0.1301,  ..., -0.2754,  0.1683,  0.1143],\n",
       "         [ 0.2629,  0.1120,  0.1351,  ..., -0.4358,  0.3750,  0.1439],\n",
       "         [-0.0416, -0.0441, -0.0393,  ...,  0.2874, -0.1884, -0.1794]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_1.bias': tensor([-0.1962,  0.0445, -0.2059,  ..., -0.0576, -0.1960, -0.2871],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_2.weight': tensor([[ 8.3008e-02, -5.6122e-02, -7.4219e-02,  ...,  1.0742e-01,\n",
       "           1.8079e-01,  3.5797e-02],\n",
       "         [ 6.8481e-02, -3.7988e-01,  6.8176e-02,  ..., -1.2708e-01,\n",
       "          -2.2437e-01, -1.4900e-02],\n",
       "         [ 6.8115e-02,  1.5976e-02, -5.3986e-02,  ...,  9.3079e-03,\n",
       "          -7.8064e-02, -2.0206e-04],\n",
       "         ...,\n",
       "         [ 1.0767e-01, -2.2559e-01,  6.6956e-02,  ...,  1.7554e-01,\n",
       "          -1.1255e-01, -1.7712e-01],\n",
       "         [ 1.7139e-01, -2.7878e-02,  2.8882e-01,  ..., -3.6530e-02,\n",
       "           3.8892e-01, -3.6774e-02],\n",
       "         [ 1.1041e-01,  1.1151e-01,  4.4946e-01,  ...,  2.5220e-01,\n",
       "          -1.1469e-01,  2.3083e-01]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.w_2.bias': tensor([ 0.4521, -0.3462,  0.2539,  ..., -0.4795,  0.3608, -0.4741],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.layer_norm.weight': tensor([1.1299, 1.1377, 1.1543,  ..., 1.1816, 1.1719, 1.1152],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.9.feed_forward.layer_norm.bias': tensor([-0.0729,  0.0707,  0.0654,  ..., -0.0680, -0.0355, -0.0500],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_keys.weight': tensor([[-0.0400,  0.3137,  0.2144,  ..., -0.0206, -0.0992,  0.0430],\n",
       "         [ 0.0554, -0.1588, -0.0986,  ...,  0.0203,  0.0802,  0.0438],\n",
       "         [ 0.0055,  0.3245,  0.2040,  ...,  0.0994,  0.1707, -0.0129],\n",
       "         ...,\n",
       "         [ 0.2585,  0.1141, -0.0263,  ...,  0.3691, -0.1616,  0.1261],\n",
       "         [-0.1812, -0.1230, -0.0220,  ...,  0.2556,  0.0544, -0.1011],\n",
       "         [ 0.0005,  0.0013, -0.0595,  ...,  0.1917,  0.1915, -0.1076]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_keys.bias': tensor([-0.0079, -0.0251, -0.0022,  ...,  0.0141, -0.0074, -0.0267],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_values.weight': tensor([[ 0.0881, -0.0816, -0.3635,  ..., -0.1008,  0.2979, -0.1902],\n",
       "         [-0.4851,  0.2356, -0.1570,  ...,  0.4988,  0.2627, -0.2037],\n",
       "         [-0.4224,  0.0797, -0.1847,  ...,  0.1333,  0.2605,  0.1112],\n",
       "         ...,\n",
       "         [-0.1384,  0.1107,  0.3318,  ...,  0.0625, -0.3311,  0.2041],\n",
       "         [ 0.2361, -0.0741,  0.0787,  ...,  0.1681,  0.2666,  0.1646],\n",
       "         [ 0.0750,  0.3904,  0.2969,  ..., -0.0723,  0.3203,  0.2676]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_values.bias': tensor([ 0.0285,  0.0306, -0.0096,  ...,  0.1098, -0.0996,  0.0311],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_query.weight': tensor([[-0.0460, -0.0241, -0.1788,  ...,  0.0292,  0.1790,  0.0556],\n",
       "         [ 0.1548,  0.5137,  0.0047,  ...,  0.0356, -0.0297, -0.0916],\n",
       "         [ 0.2031,  0.1603,  0.0542,  ...,  0.1442, -0.1305, -0.3298],\n",
       "         ...,\n",
       "         [ 0.1368, -0.1372,  0.1624,  ..., -0.0352,  0.0616,  0.0765],\n",
       "         [-0.0724,  0.2190,  0.0684,  ...,  0.4541,  0.0286,  0.0825],\n",
       "         [ 0.0134,  0.2773, -0.0466,  ...,  0.0743, -0.0175,  0.0654]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.linear_query.bias': tensor([-0.1167,  0.1196,  0.5557,  ...,  0.0797,  0.0830, -0.0103],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.final_linear.weight': tensor([[ 0.1730, -0.1925,  0.2759,  ..., -0.1399,  0.3088, -0.1022],\n",
       "         [ 0.3936,  0.5000,  0.0141,  ..., -0.1937, -0.4775,  0.0814],\n",
       "         [ 0.2512, -0.1377, -0.1252,  ..., -0.0349, -0.4585, -0.1528],\n",
       "         ...,\n",
       "         [ 0.0133,  0.1696,  0.0926,  ..., -0.1819,  0.3171, -0.1846],\n",
       "         [ 0.3127,  0.3918,  0.3259,  ...,  0.1276,  0.2471, -0.1536],\n",
       "         [-0.2988, -0.4556,  0.1615,  ...,  0.1554,  0.1527,  0.1873]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.self_attn.final_linear.bias': tensor([-0.0384, -0.5000, -0.2482,  ...,  0.2445,  0.2729,  0.2881],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_1.weight': tensor([0.4563, 0.4343, 0.4404,  ..., 0.4568, 0.4783, 0.4636],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_1.bias': tensor([ 0.0194,  0.0422,  0.0615,  ..., -0.0120,  0.0118, -0.0328],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_keys.weight': tensor([[ 3.4149e-02, -5.1575e-02, -6.8474e-03,  ..., -2.6270e-01,\n",
       "          -1.0559e-01,  3.8544e-02],\n",
       "         [-1.1383e-02,  1.3562e-01,  5.2887e-02,  ..., -3.1143e-02,\n",
       "           4.0924e-02, -1.0577e-01],\n",
       "         [ 1.4014e-01, -5.2338e-02,  1.0590e-01,  ...,  8.5938e-02,\n",
       "          -1.3757e-01, -5.6519e-02],\n",
       "         ...,\n",
       "         [ 8.4595e-02,  1.6101e-01,  5.9387e-02,  ...,  2.5620e-02,\n",
       "           1.3062e-01,  8.1665e-02],\n",
       "         [-1.1390e-04,  1.9577e-02, -4.6783e-02,  ...,  6.4331e-02,\n",
       "           2.7808e-01,  7.2205e-02],\n",
       "         [ 1.6769e-02,  1.3708e-01,  1.8848e-01,  ...,  1.6357e-01,\n",
       "          -3.4241e-02,  4.7729e-02]], dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_keys.bias': tensor([-0.0041, -0.0047, -0.0187,  ..., -0.0097,  0.0097, -0.0026],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_values.weight': tensor([[-0.3379, -0.1038, -0.1940,  ...,  0.1746, -0.0856,  0.0266],\n",
       "         [-0.2671,  0.0333, -0.0767,  ...,  0.4155, -0.5005, -0.0095],\n",
       "         [ 0.3232, -0.4922, -0.1841,  ..., -0.3206, -0.0970, -0.0087],\n",
       "         ...,\n",
       "         [ 0.1046,  0.0024, -0.0066,  ...,  0.4270, -0.3845, -0.0042],\n",
       "         [-0.1265, -0.1398,  0.5059,  ..., -0.2610, -0.1061, -0.1057],\n",
       "         [-0.2502,  0.1376, -0.0500,  ...,  0.3198, -0.2014, -0.0424]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_values.bias': tensor([-0.1736, -0.1248, -0.0724,  ..., -0.0193,  0.0529, -0.0103],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_query.weight': tensor([[ 0.2465,  0.3572, -0.1578,  ...,  0.1051,  0.1056,  0.2705],\n",
       "         [ 0.1396,  0.0517,  0.1371,  ..., -0.1715,  0.2111,  0.0310],\n",
       "         [ 0.2795, -0.0452,  0.0254,  ...,  0.0745, -0.2004, -0.0875],\n",
       "         ...,\n",
       "         [ 0.2090,  0.1552,  0.0294,  ...,  0.0163,  0.1880, -0.0748],\n",
       "         [-0.0975,  0.2720, -0.0205,  ..., -0.2959,  0.0607, -0.1752],\n",
       "         [-0.0417,  0.0686,  0.0341,  ..., -0.0052, -0.0607,  0.1924]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.linear_query.bias': tensor([-0.0300, -0.0188,  0.1372,  ...,  0.0365,  0.1879, -0.0723],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.final_linear.weight': tensor([[-0.3167,  0.0122,  0.5063,  ..., -0.1279, -0.4751, -0.0692],\n",
       "         [ 0.3191, -0.3286, -0.1993,  ...,  0.2517, -0.3118,  0.1114],\n",
       "         [-0.2600, -0.3374,  0.1562,  ..., -0.0804, -0.0756,  0.4536],\n",
       "         ...,\n",
       "         [-0.4307,  0.0817, -0.2385,  ...,  0.0475, -0.0667, -0.0591],\n",
       "         [-0.3049, -0.0431, -0.3372,  ...,  0.0893, -0.2561, -0.6758],\n",
       "         [ 0.0142, -0.3330, -0.1852,  ...,  0.0263,  0.1252,  0.2230]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.context_attn.final_linear.bias': tensor([-0.4207,  0.3188, -0.1364,  ...,  0.4988,  0.1904,  0.2290],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_2.weight': tensor([0.1527, 0.1567, 0.1797,  ..., 0.1515, 0.1356, 0.1373],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.layer_norm_2.bias': tensor([ 0.0061, -0.0064, -0.0070,  ..., -0.0638, -0.0081, -0.0396],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_1.weight': tensor([[ 0.1241, -0.1385, -0.1334,  ..., -0.0159,  0.2927,  0.0763],\n",
       "         [ 0.0085,  0.0656,  0.0775,  ..., -0.0494, -0.1176,  0.4116],\n",
       "         [-0.4534,  0.1737,  0.0739,  ...,  0.1304,  0.3660, -0.1552],\n",
       "         ...,\n",
       "         [ 0.4180,  0.0042, -0.1140,  ..., -0.1505, -0.3511, -0.1108],\n",
       "         [-0.1115,  0.1649,  0.0151,  ...,  0.1686,  0.1980, -0.2250],\n",
       "         [ 0.4780,  0.0598, -0.0205,  ...,  0.0529,  0.2556, -0.0136]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_1.bias': tensor([ 0.0577, -0.0452, -0.0366,  ..., -0.1164, -0.1792, -0.0677],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_2.weight': tensor([[-0.0407, -0.1617,  0.1550,  ...,  0.1205, -0.5635,  0.1567],\n",
       "         [-0.4338,  0.2764, -0.1478,  ..., -0.0103, -0.0054,  0.1014],\n",
       "         [-0.3440, -0.4995, -0.1874,  ...,  0.0639, -0.1431, -0.2632],\n",
       "         ...,\n",
       "         [-0.0983,  0.1627,  0.1613,  ..., -0.0656, -0.2231,  0.2571],\n",
       "         [ 0.2744, -0.3892,  0.2253,  ..., -0.0503,  0.2094,  0.0518],\n",
       "         [ 0.1449, -0.2666,  0.1943,  ..., -0.1539, -0.0191, -0.0632]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.w_2.bias': tensor([ 0.2487, -0.1239, -0.1879,  ..., -0.2219, -0.0636, -0.2351],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.layer_norm.weight': tensor([1.2422, 1.2334, 1.1982,  ..., 1.0586, 1.2021, 1.0361],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.10.feed_forward.layer_norm.bias': tensor([-0.0576,  0.0120,  0.0236,  ..., -0.0124,  0.0219, -0.0676],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_keys.weight': tensor([[ 0.2886,  0.1121, -0.0573,  ...,  0.0407, -0.0726, -0.2524],\n",
       "         [-0.0529, -0.0389,  0.0386,  ..., -0.1946, -0.0904,  0.0975],\n",
       "         [ 0.0696, -0.2507,  0.1560,  ..., -0.0846, -0.1680,  0.0520],\n",
       "         ...,\n",
       "         [-0.1136,  0.1085,  0.0013,  ...,  0.1771,  0.0459,  0.0127],\n",
       "         [-0.0032, -0.1432,  0.0987,  ...,  0.0447, -0.1344, -0.1840],\n",
       "         [ 0.0046, -0.1639, -0.0983,  ...,  0.0025, -0.1478,  0.0221]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_keys.bias': tensor([-0.0265, -0.0275, -0.0131,  ..., -0.0024,  0.0249,  0.0030],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_values.weight': tensor([[-0.0421,  0.3135,  0.3291,  ...,  0.0999,  0.2000, -0.1260],\n",
       "         [ 0.4084, -0.0457,  0.0492,  ..., -0.3721,  0.1077, -0.1754],\n",
       "         [ 0.2480, -0.3030, -0.0977,  ..., -0.2354,  0.1797,  0.2527],\n",
       "         ...,\n",
       "         [-0.5186, -0.2668,  0.1226,  ..., -0.4153, -0.1384, -0.2952],\n",
       "         [ 0.1610, -0.0661,  0.2795,  ..., -0.1015,  0.3125,  0.0173],\n",
       "         [ 0.3323, -0.0244, -0.1360,  ...,  0.2456, -0.2400,  0.1328]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_values.bias': tensor([-0.1528,  0.0600,  0.0855,  ..., -0.1096,  0.1088,  0.2185],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_query.weight': tensor([[ 0.0587,  0.0670, -0.1146,  ..., -0.2434, -0.0790, -0.1637],\n",
       "         [ 0.0241,  0.0916,  0.1638,  ...,  0.0948,  0.0159, -0.2111],\n",
       "         [ 0.2725,  0.0554, -0.0481,  ...,  0.0247, -0.1354, -0.2389],\n",
       "         ...,\n",
       "         [-0.1547,  0.1963,  0.0953,  ...,  0.1492,  0.0555, -0.2155],\n",
       "         [-0.1432, -0.2502, -0.0406,  ...,  0.1307, -0.1010,  0.1482],\n",
       "         [ 0.0346,  0.0297,  0.2104,  ...,  0.0958,  0.0427,  0.0003]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.linear_query.bias': tensor([ 0.0385, -0.0245,  0.0283,  ..., -0.2791, -0.0375,  0.2209],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.final_linear.weight': tensor([[-0.0576,  0.1973,  0.3860,  ...,  0.0765, -0.0016, -0.0147],\n",
       "         [ 0.2068,  0.3779, -0.3418,  ..., -0.0335, -0.2578, -0.1578],\n",
       "         [ 0.1189,  0.2546, -0.0859,  ..., -0.3020, -0.1877, -0.3271],\n",
       "         ...,\n",
       "         [ 0.0778,  0.1593, -0.0295,  ...,  0.2583,  0.0644, -0.0288],\n",
       "         [ 0.1534,  0.1674,  0.3032,  ..., -0.2220, -0.2607, -0.3271],\n",
       "         [-0.0537,  0.2104,  0.3301,  ...,  0.2390, -0.0082,  0.1754]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.self_attn.final_linear.bias': tensor([ 0.1097, -0.2463, -0.2507,  ...,  0.0800,  0.3486, -0.2583],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_1.weight': tensor([0.4829, 0.4480, 0.4556,  ..., 0.5693, 0.4761, 0.5493],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_1.bias': tensor([ 0.0308,  0.0459,  0.0575,  ...,  0.0363,  0.0300, -0.0277],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_keys.weight': tensor([[ 0.0150, -0.1483,  0.0195,  ..., -0.0609,  0.2163, -0.0399],\n",
       "         [ 0.0737,  0.1042,  0.1449,  ..., -0.0804,  0.0560,  0.0888],\n",
       "         [ 0.0198, -0.0088, -0.1322,  ...,  0.1057, -0.1063,  0.0030],\n",
       "         ...,\n",
       "         [ 0.2419, -0.2389, -0.0453,  ...,  0.0304,  0.2489, -0.0426],\n",
       "         [-0.1217, -0.0621, -0.0611,  ..., -0.0334, -0.2382,  0.0494],\n",
       "         [ 0.1508,  0.0376, -0.2196,  ...,  0.0021, -0.0352,  0.0072]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_keys.bias': tensor([ 0.0108, -0.0240, -0.0222,  ..., -0.0309,  0.0018,  0.0179],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_values.weight': tensor([[ 0.0915, -0.2383,  0.2522,  ..., -0.1445,  0.1812, -0.0104],\n",
       "         [-0.0807, -0.5171,  0.2520,  ...,  0.1231, -0.4302, -0.0272],\n",
       "         [-0.3323, -0.1627, -0.3203,  ...,  0.1217,  0.1506, -0.0217],\n",
       "         ...,\n",
       "         [ 0.2469,  0.3311,  0.0141,  ...,  0.2886, -0.0831,  0.0104],\n",
       "         [-0.2668,  0.0880, -0.2100,  ...,  0.3708,  0.2345,  0.0215],\n",
       "         [-0.4988,  0.3843, -0.3296,  ..., -0.2578,  0.1772,  0.0237]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_values.bias': tensor([-0.0620, -0.0496, -0.1109,  ..., -0.0281, -0.0598, -0.0185],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_query.weight': tensor([[ 0.0280,  0.3601, -0.0068,  ..., -0.0675, -0.1942, -0.1337],\n",
       "         [ 0.0245, -0.2771,  0.0118,  ...,  0.1318,  0.0584, -0.0584],\n",
       "         [ 0.2629,  0.1715,  0.2456,  ..., -0.2177,  0.0575, -0.1232],\n",
       "         ...,\n",
       "         [ 0.1587,  0.0914, -0.1600,  ..., -0.0190,  0.1428,  0.0207],\n",
       "         [ 0.1343,  0.1017, -0.2053,  ..., -0.0431, -0.0784,  0.0717],\n",
       "         [ 0.4167,  0.2212,  0.1477,  ...,  0.2322,  0.1138,  0.1298]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.linear_query.bias': tensor([-0.0859,  0.0497, -0.0948,  ..., -0.1085,  0.3074,  0.0983],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.final_linear.weight': tensor([[ 0.1483, -0.3293,  0.1842,  ...,  0.1281,  0.3018,  0.0837],\n",
       "         [-0.2546, -0.1025,  0.0375,  ..., -0.1661,  0.2649, -0.0537],\n",
       "         [ 0.5557, -0.2404,  0.2537,  ...,  0.2489, -0.4336, -0.2517],\n",
       "         ...,\n",
       "         [ 0.1147, -0.0643,  0.2102,  ...,  0.0982,  0.2448,  0.1059],\n",
       "         [ 0.1241, -0.3018, -0.0366,  ...,  0.0471, -0.0987, -0.0247],\n",
       "         [-0.1238,  0.0363,  0.0179,  ..., -0.1735,  0.0165,  0.0449]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.context_attn.final_linear.bias': tensor([-0.4980, -0.1772, -0.2944,  ...,  0.3176,  0.3970, -0.3376],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_2.weight': tensor([0.2180, 0.2142, 0.2432,  ..., 0.2505, 0.1937, 0.5459],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.layer_norm_2.bias': tensor([ 0.0131, -0.0211, -0.0297,  ..., -0.0921, -0.0276, -0.1627],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_1.weight': tensor([[ 0.2133,  0.1367,  0.1583,  ...,  0.1154,  0.1157,  0.2507],\n",
       "         [ 0.5381,  0.2512,  0.0615,  ..., -0.1866,  0.0807, -0.4976],\n",
       "         [ 0.1731, -0.0155,  0.1274,  ..., -0.0911, -0.0814,  0.0748],\n",
       "         ...,\n",
       "         [-0.4023,  0.0764,  0.1492,  ...,  0.0858, -0.1229, -0.1460],\n",
       "         [ 0.3167, -0.4993, -0.1406,  ..., -0.0420, -0.0975, -0.1920],\n",
       "         [ 0.0118, -0.0053,  0.3694,  ..., -0.1689,  0.1758,  0.3420]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_1.bias': tensor([-0.0565, -0.1241,  0.1722,  ..., -0.1564, -0.1884, -0.1355],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_2.weight': tensor([[-0.2155,  0.0026, -0.0821,  ...,  0.2438,  0.4438, -0.1379],\n",
       "         [-0.0099,  0.0284,  0.1877,  ..., -0.3665, -0.3655, -0.4993],\n",
       "         [ 0.2686, -0.4487, -0.1062,  ..., -0.1671,  0.3542,  0.2520],\n",
       "         ...,\n",
       "         [-0.0320,  0.1042,  0.0439,  ...,  0.0439, -0.1384,  0.1189],\n",
       "         [-0.0164, -0.0094, -0.0580,  ..., -0.0873,  0.1727,  0.1772],\n",
       "         [-0.0598, -0.1796, -0.1490,  ...,  0.0716, -0.3953,  0.0061]],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.w_2.bias': tensor([ 0.1031,  0.1510, -0.1302,  ...,  0.2443, -0.0541, -0.2505],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.layer_norm.weight': tensor([1.0381, 1.0693, 1.0654,  ..., 1.0059, 1.0098, 1.0000],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.transformer_layers.11.feed_forward.layer_norm.bias': tensor([ 0.1394,  0.1179,  0.1831,  ..., -0.1677,  0.1306, -0.0412],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.layer_norm.weight': tensor([0.6274, 1.0703, 1.1914,  ..., 0.8398, 0.4060, 0.4321],\n",
       "        dtype=torch.float16),\n",
       " 'decoder.layer_norm.bias': tensor([ 0.0264,  0.0236,  0.0949,  ...,  0.3755, -0.0079, -0.0789],\n",
       "        dtype=torch.float16)}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omnt_checkpoint['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': tensor([[-0.0321,  0.0348,  0.0181,  ...,  0.0312, -0.0099, -0.0133],\n",
       "         [-0.0039,  0.0104, -0.0156,  ...,  0.0290, -0.0138, -0.0134],\n",
       "         [-0.0245, -0.0283, -0.0295,  ...,  0.9712, -0.0255, -0.0273],\n",
       "         ...,\n",
       "         [-0.0123, -0.0031, -0.0089,  ...,  0.0645, -0.0182, -0.0740],\n",
       "         [ 0.0085, -0.0088, -0.0091,  ...,  0.0571, -0.0035, -0.1298],\n",
       "         [-0.0076, -0.0107, -0.0051,  ...,  1.0264, -0.0338, -0.1175]],\n",
       "        dtype=torch.float16),\n",
       " 'bias': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.float16)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omnt_checkpoint['generator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From FB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['args', 'cfg', 'model', 'criterion', 'optimizer_history', 'task_state', 'extra_state', 'last_optimizer_state'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint = torch.load('checkpoint.pt', map_location=torch.device('cpu'))\n",
    "checkpoint.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_name', 'common', 'common_eval', 'distributed_training', 'dataset', 'optimization', 'checkpoint', 'bmuf', 'generation', 'eval_lm', 'interactive', 'model', 'task', 'criterion', 'optimizer', 'lr_scheduler', 'scoring', 'bpe', 'tokenizer', 'ema'])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['cfg'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config='', save_config=None, data={}, skip_empty_level='silent', save_data='', overwrite=False, n_sample=0, dump_transforms=False, src_vocab='', tgt_vocab='', share_vocab=True, src_feats_vocab=None, src_vocab_size=256206, tgt_vocab_size=256206, vocab_size_multiple=1, src_words_min_frequency=1, tgt_words_min_frequency=1, src_seq_length_trunc=None, tgt_seq_length_trunc=None, both_embeddings=None, src_embeddings=None, tgt_embeddings=None, embeddings_type=None, switchout_temperature=1.0, tokendrop_temperature=1.0, tokenmask_temperature=1.0, reversible_tokenization='joiner', prior_tokenization=False, src_subword_model='', tgt_subword_model='', src_subword_nbest=1, tgt_subword_nbest=1, src_subword_alpha=0.0, tgt_subword_alpha=0.0, src_subword_vocab='', tgt_subword_vocab='', src_vocab_threshold=0, tgt_vocab_threshold=0, src_subword_type='none', tgt_subword_type='none', src_onmttok_kwargs=\"{'mode': 'none'}\", tgt_onmttok_kwargs=\"{'mode': 'none'}\", src_seq_length=150, tgt_seq_length=150, src_prefix='', tgt_prefix='', permute_sent_ratio=0.0, rotate_ratio=0.0, insert_ratio=0.0, random_ratio=0.0, mask_ratio=0.0, mask_length='subword', poisson_lambda=3.0, replace_length=-1, src_word_vec_size=1024, tgt_word_vec_size=1024, word_vec_size=1024, share_decoder_embeddings=True, share_embeddings=True, position_encoding=True, position_encoding_type='SinusoidalConcat', update_vocab=False, feat_merge='concat', feat_vec_size=-1, feat_vec_exponent=0.7, model_task='seq2seq', model_type='text', model_dtype='fp16', encoder_type='transformer', decoder_type='transformer', freeze_encoder=False, freeze_decoder=False, layers=-1, enc_layers=12, dec_layers=12, hidden_size=1024, enc_hid_size=1024, dec_hid_size=1024, cnn_kernel_width=3, pos_ffn_activation_fn='relu', input_feed=1, bridge=False, rnn_type='LSTM', context_gate=None, bridge_extra_node=True, bidir_edges=True, state_dim=512, n_edge_types=2, n_node=2, n_steps=2, src_ggnn_size=0, global_attention='general', global_attention_function='softmax', self_attn_type='scaled-dot', max_relative_positions=0, heads=16, transformer_ff=4096, aan_useffn=False, add_qkvbias=True, lambda_align=0.0, alignment_layer=-3, alignment_heads=0, full_context_alignment=False, copy_attn=False, copy_attn_type='general', generator_function='softmax', copy_attn_force=False, reuse_copy_attn=False, copy_loss_by_seqlength=False, coverage_attn=False, lambda_coverage=0.0, lm_prior_model=None, lm_prior_lambda=0.0, lm_prior_tau=1.0, loss_scale=0, apex_opt_level='', data_type='text', save_model='nllb', save_checkpoint_steps=5000, keep_checkpoint=50, gpu_ranks=[0], world_size=1, gpu_backend='nccl', gpu_verbose_level=0, master_ip='localhost', master_port=10000, seed=1234, param_init=0.0, param_init_glorot=True, train_from='', reset_optim='none', pre_word_vecs_enc=None, pre_word_vecs_dec=None, freeze_word_vecs_enc=False, freeze_word_vecs_dec=False, num_workers=4, batch_size=8192, batch_size_multiple=1, batch_type='tokens', normalization='tokens', accum_count=[4], accum_steps=[0], valid_steps=5000, valid_batch_size=4096, train_steps=100000, single_pass=False, early_stopping=0, early_stopping_criteria=None, optim='', adagrad_accumulator_init=0, max_grad_norm=0.0, dropout=[0.1], attention_dropout=[0.1], dropout_steps=[0], truncated_decoder=0, adam_beta1=0.9, adam_beta2=0.98, label_smoothing=0.1, average_decay=0.0, average_every=1, learning_rate=5e-05, learning_rate_decay=0.5, start_decay_steps=50000, decay_steps=10000, decay_method='none', warmup_steps=4000, log_file='', log_file_level='0', verbose=False, train_eval_steps=200, train_metrics=[], valid_metrics=[], scoring_debug=False, dump_preds=None, report_every=100, exp_host='', exp='', tensorboard=False, tensorboard_log_dir='runs/onmt', bucket_size=262144, bucket_size_init=-1, bucket_size_increment=0, prefetch_factor=400, brnn=False, data_task='seq2seq', decoder_start_token='</s>', _all_transform={'filtertoolong'})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omnt_checkpoint['opt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to add opt to the FB Checkpoiint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint['opt'] = omnt_checkpoint['opt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['args', 'cfg', 'model', 'criterion', 'optimizer_history', 'task_state', 'extra_state', 'last_optimizer_state', 'opt'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, 'checkpoint_w_opt.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the ONMT Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"nllb-200-600M-onmt2.pt_step_600.pt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "It looks like the config file at 'nllb-200-600M-onmt2.pt_step_600.pt' is not a valid JSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\transformers\\configuration_utils.py:702\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_from_json_file(resolved_config_file)\n\u001b[0;32m    703\u001b[0m     config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m commit_hash\n",
      "File \u001b[1;32mc:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\transformers\\configuration_utils.py:793\u001b[0m, in \u001b[0;36mPretrainedConfig._dict_from_json_file\u001b[1;34m(cls, json_file)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(json_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m reader:\n\u001b[1;32m--> 793\u001b[0m     text \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mread()\n\u001b[0;32m    794\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mloads(text)\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 128: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mnllb-200-600M-onmt2.pt_step_600.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:461\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    459\u001b[0m     _ \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 461\u001b[0m config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m    462\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m    463\u001b[0m     return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    464\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[0;32m    465\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs,\n\u001b[0;32m    466\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    467\u001b[0m )\n\u001b[0;32m    469\u001b[0m \u001b[39m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m kwargs_orig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtorch_dtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:983\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[0;32m    982\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 983\u001b[0m config_dict, unused_kwargs \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    984\u001b[0m has_remote_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    985\u001b[0m has_local_code \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32mc:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\transformers\\configuration_utils.py:617\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    616\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 617\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    618\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[0;32m    619\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wong.kk\\udemyml_env\\Lib\\site-packages\\transformers\\configuration_utils.py:705\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    703\u001b[0m     config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m commit_hash\n\u001b[0;32m    704\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m):\n\u001b[1;32m--> 705\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    706\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIt looks like the config file at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mresolved_config_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a valid JSON file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m     )\n\u001b[0;32m    709\u001b[0m \u001b[39mif\u001b[39;00m is_local:\n\u001b[0;32m    710\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading configuration file \u001b[39m\u001b[39m{\u001b[39;00mresolved_config_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: It looks like the config file at 'nllb-200-600M-onmt2.pt_step_600.pt' is not a valid JSON file."
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"nllb-200-600M-onmt2.pt_step_600.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opennmt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopennmt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Find the pt checkpoint file.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'opennmt'"
     ]
    }
   ],
   "source": [
    "import opennmt\n",
    "import torch\n",
    "\n",
    "# Find the pt checkpoint file.\n",
    "checkpoint_file = \"nllb-200-600M-onmt2.pt_step_600.pt\"\n",
    "\n",
    "# Import the OpenNMT library and the torch library.\n",
    "from opennmt import Model\n",
    "\n",
    "# Create a model object and load the checkpoint file into it.\n",
    "model = Model.from_pretrained(checkpoint_file)\n",
    "\n",
    "# Use the model object to perform inference.\n",
    "translation = model.translate(\"This is a sentence.\")\n",
    "\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nllb-200-600M-onmt2.pt_step_600.pt, src_lang=\"ron_Latn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-moe-54b\")\n",
    "\n",
    "article = \"eful ONU spune c nu exist o soluie militar n Siria\"\n",
    "inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "\n",
    "translated_tokens = model.generate(\n",
    "    **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[\"deu_Latn\"], max_length=30\n",
    ")\n",
    "\t\n",
    "tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
